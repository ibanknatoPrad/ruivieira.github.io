<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="48x48" href="/favicons/favicon.ico">

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Notes on Optimising random forest hyperparamaters">
    <meta name="robots" content="index">
    <link rel="canonical" href="https://ruivieira.dev/optimising-random-forest-hyperparamaters.html">
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
          integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">

    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
            integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
            crossorigin="anonymous"></script>

    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
            integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>

    <script src="/assets/mark.min.js"></script>

    <link href="https://fonts.googleapis.com/css?family=Nunito:400,300i,800&display=swap" rel="stylesheet"/>
    <link href="/assets/style.css" rel="stylesheet">
    <link href="/assets/code.css" rel="stylesheet">
    <title>ruivieira.dev - Optimising random forest hyperparamaters</title>
    <script data-goatcounter="https://ruivieira-dev.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
    <style>
        #search_terms {
            font-size: 1rem;
            font-family: Nunito;
            width: 40%;
        }
        #search_terms::placeholder {
            color: #bbb;
        }
        #search_button {
            background-color: #eee;
            border: none;
            color: black;
            padding: 0.25rem 0.25rem;
            font-size: 1rem;
            font-family: Nunito;
            text-decoration: none;
            cursor: pointer;
            border-radius: 5px;
            width: 3rem;
        }
</style>
</head>
<body>
    <div id="grid">

        <div id="content">
            <h1 id="optimising-random-forest-hyperparameters">Optimising random forest hyperparameters</h1>
<p>Typically the hyper-parameters which will have the most significant impact on the behaviour of a random forest are the following:</p>
<ul>
<li><a href="/optimising-random-forest-hyperparamaters.html#Number of decision trees">The number of decision trees</a> in a random forest</li>
<li>The split criteria</li>
<li>Maximum depth of individual trees</li>
<li>Minimum samples per internal node</li>
<li>Maximum number of leaf nodes</li>
<li>Random features per split</li>
<li>Number of samples in bootstrap dataset</li>
</ul>
<p>We will look at each of these hyper-parameters individually with examples of how to select them.</p>
<h2 id="data">Data</h2>
<p>To understand how we can optimise the hyperparameters in a random forest model, we will use <a href="/scikit-learn.html">scikit-learn's</a> <code>RandomForestClassifier</code> and a subset of <em>Titanic</em><sup id="fnref:titanic"><a class="footnote-ref" href="#fn:titanic">1</a></sup> dataset.</p>
<p>First, we will import the features and labels using <a href="/pandas.html">Pandas</a>.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">train_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/svm-hyperparameters-train-features.csv&quot;</span><span class="p">)</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/svm-hyperparameters-train-label.csv&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Let's look at a random sample of entries from this dataset, both for features and labels.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_features</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>517</th>
      <td>3</td>
      <td>1</td>
      <td>30.0</td>
      <td>0</td>
      <td>0</td>
      <td>24.1500</td>
    </tr>
    <tr>
      <th>538</th>
      <td>3</td>
      <td>1</td>
      <td>30.0</td>
      <td>0</td>
      <td>0</td>
      <td>14.5000</td>
    </tr>
    <tr>
      <th>735</th>
      <td>3</td>
      <td>1</td>
      <td>28.5</td>
      <td>0</td>
      <td>0</td>
      <td>16.1000</td>
    </tr>
    <tr>
      <th>75</th>
      <td>3</td>
      <td>1</td>
      <td>25.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.6500</td>
    </tr>
    <tr>
      <th>395</th>
      <td>3</td>
      <td>1</td>
      <td>22.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.7958</td>
    </tr>
    <tr>
      <th>560</th>
      <td>3</td>
      <td>1</td>
      <td>30.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.7500</td>
    </tr>
    <tr>
      <th>875</th>
      <td>3</td>
      <td>0</td>
      <td>15.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.2250</td>
    </tr>
    <tr>
      <th>579</th>
      <td>3</td>
      <td>1</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
    </tr>
    <tr>
      <th>701</th>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>26.2875</td>
    </tr>
    <tr>
      <th>707</th>
      <td>1</td>
      <td>1</td>
      <td>42.0</td>
      <td>0</td>
      <td>0</td>
      <td>26.2875</td>
    </tr>
  </tbody>
</table>
</div>

<p>Some of the available features are:</p>
<ul>
<li><code>Pclass</code>, ticket class</li>
<li><code>Sex</code></li>
<li><code>Age</code>, age in years</li>
<li><code>Sibsp</code>, number of siblings/spouses aboard</li>
<li><code>Parch</code>, number of parents/children aboard</li>
<li><code>Fare</code>, passenger fare</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">train_label</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>342</th>
      <td>0</td>
    </tr>
    <tr>
      <th>436</th>
      <td>0</td>
    </tr>
    <tr>
      <th>414</th>
      <td>1</td>
    </tr>
    <tr>
      <th>379</th>
      <td>0</td>
    </tr>
    <tr>
      <th>847</th>
      <td>0</td>
    </tr>
    <tr>
      <th>397</th>
      <td>0</td>
    </tr>
    <tr>
      <th>82</th>
      <td>1</td>
    </tr>
    <tr>
      <th>671</th>
      <td>0</td>
    </tr>
    <tr>
      <th>317</th>
      <td>0</td>
    </tr>
    <tr>
      <th>681</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>The outcome label indicates whether a passenger survived the disaster.</p>
<p>As part of the typical initial steps for model training, we will prepare the data by splitting it into a training and testing subset.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">23</span><span class="p">)</span>
</code></pre></div>

<h2 id="naive-model">Naive model</h2>
<p>First we will train a "naive" model, that is a model using the defaults provided by <code>RandomForestClassifier</code><sup id="fnref:rf"><a class="footnote-ref" href="#fn:rf">2</a></sup>. These defaults are:</p>
<ul>
<li><code>n_estimators = 10</code></li>
<li><code>criterion=’gini’</code></li>
<li><code>max_depth=None</code></li>
<li><code>min_samples_split=2</code></li>
<li><code>min_samples_leaf=1</code></li>
<li><code>min_weight_fraction_leaf=0.0</code></li>
<li><code>max_features=’auto’</code></li>
<li><code>max_leaf_nodes=None</code></li>
<li><code>min_impurity_decrease=0.0</code></li>
<li><code>min_impurity_split=None</code></li>
<li><code>bootstrap=True</code></li>
<li><code>oob_score=False</code></li>
<li><code>n_jobs=1</code></li>
<li><code>random_state=None</code></li>
<li><code>verbose=0</code></li>
<li><code>warm_start=False</code></li>
<li><code>class_weight=None</code></li>
</ul>
<p>We will instantiate a random forest classifier:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</code></pre></div>

<p>And training it using the <code>X_train</code> and <code>y_train</code> subsets using the appropriate <code>fit</code> method<sup id="fnref:fit"><a class="footnote-ref" href="#fn:fit">3</a></sup>.</p>
<div class="highlight"><pre><span></span><code><span class="n">true_labels</span> <span class="o">=</span> <span class="n">train_label</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>RandomForestClassifier()
</code></pre></div>

<p>We can now evaluate trained naive model's score.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="mf">0.7592592592592593</span>
</code></pre></div>

<h2 id="hyperparameter-search">Hyperparameter search</h2>
<p>A simple example of a generic hyperparameter search using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code>GridSearchCV</code></a> method in <code>scikit-learn</code>. The score used to measure the "best" model is the <code>mean_test_score</code>, but other metrics could be used, such as the <a href="/oob-score-in-random-forests.html">Out-of-bag (OOB)</a> error.</p>
<div class="highlight"><pre><span></span><code><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">],</span>
    <span class="s2">&quot;max_depth&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="kc">None</span><span class="p">]</span>

<span class="p">}</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span><span class="n">parameters</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5, estimator=RandomForestClassifier(),
             param_grid={&#39;max_depth&#39;: [2, 4, 8, 16, 32, None],
                         &#39;n_estimators&#39;: [5, 10, 50, 100, 250]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Best parameters are: </span><span class="si">{</span><span class="n">results</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">mean_score</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
    <span class="n">std_score</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">mean</span><span class="p">,</span><span class="n">std</span><span class="p">,</span><span class="n">params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mean_score</span><span class="p">,</span><span class="n">std_score</span><span class="p">,</span><span class="n">params</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1"> + or -</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">std</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1"> for the </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">display</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="nv">Best</span> <span class="nv">parameters</span> <span class="nv">are</span>: {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}


<span class="mi">0</span>.<span class="mi">795</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">02</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">2</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">775</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">024</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">2</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">774</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">025</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">2</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">779</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">02</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">2</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">78</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">018</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">2</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
<span class="mi">0</span>.<span class="mi">814</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">024</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">4</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">81</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">028</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">4</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">807</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">022</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">4</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">804</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">018</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">4</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">817</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">025</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">4</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
<span class="mi">0</span>.<span class="mi">815</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">017</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">815</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">017</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">822</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">019</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">82</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">014</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">82</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">016</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">8</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
<span class="mi">0</span>.<span class="mi">807</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">028</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">16</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">812</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">028</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">16</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">814</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">028</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">16</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">807</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">028</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">16</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">812</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">026</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">16</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
<span class="mi">0</span>.<span class="mi">779</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">036</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">32</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">807</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">027</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">32</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">814</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">021</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">32</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">802</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">023</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">32</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">797</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">021</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="mi">32</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
<span class="mi">0</span>.<span class="mi">789</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">027</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="nv">None</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">5</span>}
<span class="mi">0</span>.<span class="mi">795</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">033</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="nv">None</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">10</span>}
<span class="mi">0</span>.<span class="mi">804</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">023</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="nv">None</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">50</span>}
<span class="mi">0</span>.<span class="mi">802</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">014</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="nv">None</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">100</span>}
<span class="mi">0</span>.<span class="mi">815</span> <span class="o">+</span> <span class="nv">or</span> <span class="o">-</span><span class="mi">0</span>.<span class="mi">021</span> <span class="k">for</span> <span class="nv">the</span> {<span class="s1">&#39;</span><span class="s">max_depth</span><span class="s1">&#39;</span>: <span class="nv">None</span>, <span class="s1">&#39;</span><span class="s">n_estimators</span><span class="s1">&#39;</span>: <span class="mi">250</span>}
</code></pre></div>

<h2 id="parameters">Parameters</h2>
<h3 id="number-of-decision-trees">Number of decision trees</h3>
<p>This is specified using the <code>n_estimators</code> hyper-parameter on the random forest initialisation.</p>
<p>Typically, a higher number of trees will lead to greater accuracy at the expense of model size and training time.</p>
<div class="highlight"><pre><span></span><code><span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5, estimator=RandomForestClassifier(),
             param_grid={&#39;n_estimators&#39;: [2, 4, 8, 16, 32, 64, 128, 256, 512]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n_estimators</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.766793</td>
      <td>0.016062</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>0.773515</td>
      <td>0.029848</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>0.796989</td>
      <td>0.034546</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16</td>
      <td>0.803669</td>
      <td>0.011729</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>0.800308</td>
      <td>0.030873</td>
    </tr>
    <tr>
      <th>5</th>
      <td>64</td>
      <td>0.807073</td>
      <td>0.021654</td>
    </tr>
    <tr>
      <th>6</th>
      <td>128</td>
      <td>0.805378</td>
      <td>0.018606</td>
    </tr>
    <tr>
      <th>7</th>
      <td>256</td>
      <td>0.812101</td>
      <td>0.022103</td>
    </tr>
    <tr>
      <th>8</th>
      <td>512</td>
      <td>0.807059</td>
      <td>0.020457</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>

<span class="p">(</span>
     <span class="n">ggplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_boxplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(n_estimators)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(n_estimators)&#39;</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;mean_score - std_score&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;mean_score + std_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">theme_classic</span><span class="p">()</span> <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s1">&#39;Number of trees&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s1">&#39;Mean score&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="images/optimising-random-forest-hyperparamaters-output_26_0.png" /></p>
<div class="highlight"><pre><span></span><code>&lt;ggplot: (358398967)&gt;
</code></pre></div>

<h3 id="the-split-criteria">The split criteria</h3>
<p>At each node, a random forest decides, according to a specific algorithm, which feature and value split the tree.
Therefore, the choice of splitting algorithm is crucial for the random forest's performance.</p>
<p>Since, in this example, we are dealing with a classification problem, the choices of split algorithm are, for instance:</p>
<ul>
<li>Gini</li>
<li>Entropy</li>
</ul>
<p>If we were dealing with a random forest for regression, other methods (such as <a href="/error-metrics.html">MSE</a>) would be a possible choice.
We will now compare both split algorithms as specified above, in training a random forest with our data:</p>
<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=256),
             param_grid={&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;criterion&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>criterion</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>gini</td>
      <td>0.802003</td>
      <td>0.023607</td>
    </tr>
    <tr>
      <th>1</th>
      <td>entropy</td>
      <td>0.812087</td>
      <td>0.013550</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="maximum-depth-of-individual-trees">Maximum depth of individual trees</h3>
<p>In theory, the "longer" the tree, the more splits it can have and better accommodate the data. However, at the tree level can this can lead to overfitting.
Although this is a problem for decision trees, it is not necessarily a problem for the ensemble, the random forest.
Although the key is to strike a balance between trees that aren't too large or too short, there's no universal heuristic to determine the size.
Let's try a few option for maximum depth:</p>
<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                           <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="kc">None</span><span class="p">]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(criterion=&#39;entropy&#39;,
                                              n_estimators=256),
             param_grid={&#39;max_depth&#39;: [2, 4, 8, 16, 32, None]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_depth</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.0</td>
      <td>0.770154</td>
      <td>0.018592</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.0</td>
      <td>0.817185</td>
      <td>0.022074</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8.0</td>
      <td>0.812087</td>
      <td>0.008403</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.0</td>
      <td>0.805378</td>
      <td>0.019350</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32.0</td>
      <td>0.813768</td>
      <td>0.018610</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>

<span class="p">(</span>
     <span class="n">ggplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_boxplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_depth)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">theme_classic</span><span class="p">()</span> <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s1">&#39;Max tree depth&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s1">&#39;Mean score&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="images/optimising-random-forest-hyperparamaters-output_35_0.png" /></p>
<div class="highlight"><pre><span></span><code>&lt;ggplot: (358468337)&gt;
</code></pre></div>

<h3 id="maximum-number-of-leaf-nodes">Maximum number of leaf nodes</h3>
<p>This hyperparameter can be of importance to other topics, such as <a href="/explainability.html">Explainability</a>.</p>
<p>It is specified in <code>scikit-learn</code> using the <code>max_leaf_nodes</code> parameter. Let's try a few different values:</p>
<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                           <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">,</span>
                            <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(criterion=&#39;entropy&#39;, max_depth=8,
                                              n_estimators=256),
             param_grid={&#39;max_leaf_nodes&#39;: [2, 4, 8, 16, 32, 64, 128]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_leaf_nodes</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.755014</td>
      <td>0.024759</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>0.773487</td>
      <td>0.024367</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>0.817185</td>
      <td>0.026706</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16</td>
      <td>0.812115</td>
      <td>0.014137</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>0.813782</td>
      <td>0.019204</td>
    </tr>
    <tr>
      <th>5</th>
      <td>64</td>
      <td>0.812073</td>
      <td>0.008712</td>
    </tr>
    <tr>
      <th>6</th>
      <td>128</td>
      <td>0.813754</td>
      <td>0.013498</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>

<span class="p">(</span>
     <span class="n">ggplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_boxplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_leaf_nodes)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_leaf_nodes)&#39;</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;mean_score - std_score&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;mean_score + std_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">theme_classic</span><span class="p">()</span> <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s1">&#39;Maximum leaf nodes&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s1">&#39;Mean score&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="images/optimising-random-forest-hyperparamaters-output_40_0.png" /></p>
<div class="highlight"><pre><span></span><code>&lt;ggplot: (358911004)&gt;
</code></pre></div>

<h3 id="random-features-per-split">Random features per split</h3>
<p>This is an important hyperparameter that will depend on how noisy the original data is.
Typically, if the data is not very noisy, the number of used random features can be kept low. Otherwise, it needs to be kept high.</p>
<p>An important consideration is also the following trade-off:</p>
<ul>
<li>A low number of random features decrease the forest's overall variance</li>
<li>A low number of random features increases the bias</li>
<li>A high number of random features increases computational time</li>
</ul>
<p>In <code>scikit-learn</code> this is specified with the <code>max_features</code> parameter. Assuming \(N_f\) is the total number of features,
some possible values for this parameter are:</p>
<ul>
<li><code>sqrt</code>, this will take the <code>max_features</code> as the rounded \(\sqrt{N_f}\)</li>
<li><code>log2</code>, as above, takes the \(\log_2(N_f)\)</li>
<li>The actual maximum number of features can be directly specified</li>
</ul>
<p>Let's try a simple benchmark, even though our data does not have many features to begin with:</p>
<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                             <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">,</span>
                             <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(criterion=&#39;entropy&#39;, max_depth=8,
                                              n_estimators=256),
             param_grid={&#39;max_features&#39;: [&#39;sqrt&#39;, &#39;log2&#39;, 1, 2, 3, 4, 5, 6]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;max_features&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_features</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>sqrt</td>
      <td>0.820476</td>
      <td>0.018793</td>
    </tr>
    <tr>
      <th>1</th>
      <td>log2</td>
      <td>0.810420</td>
      <td>0.015345</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0.820504</td>
      <td>0.017704</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>0.820490</td>
      <td>0.017064</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>0.815420</td>
      <td>0.009488</td>
    </tr>
    <tr>
      <th>5</th>
      <td>4</td>
      <td>0.823838</td>
      <td>0.011681</td>
    </tr>
    <tr>
      <th>6</th>
      <td>5</td>
      <td>0.828880</td>
      <td>0.016225</td>
    </tr>
    <tr>
      <th>7</th>
      <td>6</td>
      <td>0.828880</td>
      <td>0.013361</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>

<span class="p">(</span>
     <span class="n">ggplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_boxplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_features)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_features)&#39;</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;mean_score - std_score&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;mean_score + std_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">theme_classic</span><span class="p">()</span> <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s1">&#39;Maximum number of features&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s1">&#39;Mean score&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="images/optimising-random-forest-hyperparamaters-output_45_0.png" /></p>
<div class="highlight"><pre><span></span><code>&lt;ggplot: (358798611)&gt;
</code></pre></div>

<h3 id="bootstrap-dataset-size">Bootstrap dataset size</h3>
<p>This hyperparameter relates to the proportion of the training data to be used by decision trees.</p>
<p>It is specified in <code>scikit-learn</code> by <code>max_samples</code> and can take the value of either:</p>
<ul>
<li><code>None</code>, take the entirety of the samples</li>
<li>An integer, representing the actual number of samples</li>
<li>A float, representing a proportion between <code>0</code> and <code>1</code> or the samples to take.</li>
</ul>
<p>Let's try a hyperparameter search with some values:</p>
<div class="highlight"><pre><span></span><code><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                             <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">,</span>
                             <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                             <span class="n">max_features</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rfc</span><span class="p">,{</span><span class="s1">&#39;max_samples&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]},</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(criterion=&#39;entropy&#39;, max_depth=8,
                                              max_features=6,
                                              n_estimators=256),
             param_grid={&#39;max_samples&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,
                                         0.9]})
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;max_samples&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;max_samples&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]],</span>
             <span class="s2">&quot;mean_score&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]),</span>
             <span class="s2">&quot;std_score&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]})</span>
<span class="n">results</span>
</code></pre></div>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>max_samples</th>
      <th>mean_score</th>
      <th>std_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.1</td>
      <td>0.805434</td>
      <td>0.021459</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.2</td>
      <td>0.817171</td>
      <td>0.019534</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.3</td>
      <td>0.815448</td>
      <td>0.010392</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.4</td>
      <td>0.818796</td>
      <td>0.016416</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.5</td>
      <td>0.832227</td>
      <td>0.019042</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.6</td>
      <td>0.827199</td>
      <td>0.015364</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.7</td>
      <td>0.825518</td>
      <td>0.016115</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.8</td>
      <td>0.820490</td>
      <td>0.011031</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.9</td>
      <td>0.827199</td>
      <td>0.014415</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>

<span class="p">(</span>
     <span class="n">ggplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_boxplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_samples)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;factor(max_samples)&#39;</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;mean_score - std_score&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;mean_score + std_score&#39;</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">theme_classic</span><span class="p">()</span> <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s1">&#39;Proportion bootstrap samples&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s1">&#39;Mean score&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="images/optimising-random-forest-hyperparamaters-output_50_0.png" /></p>
<div class="highlight"><pre><span></span><code>&lt;ggplot: (358907088)&gt;
</code></pre></div>

<div class="highlight"><pre><span></span><code>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:titanic">
<p>Titanic Dataset - <a href="https://www.kaggle.com/c/titanic-dataset/data">https://www.kaggle.com/c/titanic-dataset/data</a>&#160;<a class="footnote-backref" href="#fnref:titanic" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:rf">
<p><a href="https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html">https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a>&#160;<a class="footnote-backref" href="#fnref:rf" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:fit">
<p><a href="https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit">https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit</a>&#160;<a class="footnote-backref" href="#fnref:fit" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
            <div class="footer">
                <span class="cc-symbol">&#127341;</span> 2020 CC BY Rui Vieira
            </div>
        </div>

        <div id="sidebar">
            <div id="sidebar-search">
                <input id="search_terms" type="search" placeholder="Search terms" />
                <button id="search_button" onclick="search()">?</button>
            </div>
            <div id="sidebar-home"><a href="/">Home</a></div>
            <div id="sidebar-all-pages"><a href="/content.html">All pages</a></div>
            <div id="sidebar-graph"><a href="/graph.html">Link network</a></div>

            <div id="sidebar-contents">
                <h3>Contents</h3>
                <div class="toc">
<ul>
<li><a href="#data">Data</a></li>
<li><a href="#naive-model">Naive model</a></li>
<li><a href="#hyperparameter-search">Hyperparameter search</a></li>
<li><a href="#parameters">Parameters</a><ul>
<li><a href="#number-of-decision-trees">Number of decision trees</a></li>
<li><a href="#the-split-criteria">The split criteria</a></li>
<li><a href="#maximum-depth-of-individual-trees">Maximum depth of individual trees</a></li>
<li><a href="#maximum-number-of-leaf-nodes">Maximum number of leaf nodes</a></li>
<li><a href="#random-features-per-split">Random features per split</a></li>
<li><a href="#bootstrap-dataset-size">Bootstrap dataset size</a></li>
</ul>
</li>
</ul>
</div>
    
                
                <h3>Backlinks</h3>
                    <ul>
                    
                        <li><a href="/scikit-learn.html">Scikit-learn</a><sup>&#5833</sup></li>
                    
                        <li><a href="/index.html">index</a><sup>&#5833</sup></li>
                    
                        <li><a href="/optimising-random-forest-hyperparamaters.html">Optimising random forest hyperparamaters</a><sup>&#5833</sup></li>
                    
                    </ul>
                
            </div>



            <div class="footer">
                modified 25 days ago
            </div>

        </div>
    <div>

<script>
const input = document.getElementById('search_terms');
const highlight = new URLSearchParams(document.location.search).get("h");

if (highlight!=null) {
    const markInstance = new Mark("#content");
    markInstance.mark(highlight);
}

input.addEventListener("keyup", function(event) {
            // Number 13 is the "Enter" key on the keyboard
            if (event.keyCode === 13) {
                // Cancel the default action, if needed
                event.preventDefault();
                // Trigger the button element with a click
                search_button.click();
            }
        });

let search = function() {
            const query = new URLSearchParams({"q": input.value});
            console.log(query.toString());
            window.location.href = "/search.html?" + query.toString();
}
</script>

</body>
</html>