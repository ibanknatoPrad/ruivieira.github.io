<!DOCTYPE html>
<html lang="en-uk">
<head>
  <script data-goatcounter="https://ruivieira-dev.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
  <link rel="preload" href="/lib/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/kbd.css" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Counterfactual Fairness | Rui Vieira</title>
  <link rel = 'canonical' href = 'https://ruivieira.dev/counterfactual-fairness.html'>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Counterfactual Fairness" />
<meta property="og:description" content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high `FYA`." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ruivieira.dev/counterfactual-fairness.html" /><meta property="article:section" content="posts" />

<meta property="article:modified_time" content="2021-12-07T21:49:31+00:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Counterfactual Fairness"/>
<meta name="twitter:description" content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high `FYA`."/>

  
  
    
  
  
  <link rel="stylesheet" href="https://ruivieira.dev/css/styles.11452b79971f363af7cee81005cd790dc0a7c965142f8adb59e36437063f2d447687b3711ada73b6a88b3b41a41508a42a384d9620740b48cefa0ea9f5e49459.css" integrity="sha512-EUUreZcfNjr3zugQBc15DcCnyWUUL4rbWeNkNwY/LUR2h7NxGtpztqiLO0GkFQikKjhNliB0C0jO&#43;g6p9eSUWQ=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://ruivieira.dev/images/favicon.ico" />

  
  
  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/map/">All pages</a></li>
         
        <li><a href="/search.html">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://ruivieira.dev/counterfactual-fairness-in-java.html" aria-label="Previous">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="https://ruivieira.dev/cookiecutter-data-science.html" aria-label="Next">
            <i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i>
          </a>
        </li>
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#" aria-label="Share">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label="Facebook">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label="Twitter">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="Linkedin">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label="Pinterest">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label="Email">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="Pocket">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="reddit">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20%60FYA%60." aria-label="Tumblr">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    
    
    <div id="toc">
      <h4>Contents</h4>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#building-counterfactually-fair-models">Building counterfactually fair models</a>
      <ul>
        <li><a href="#data">Data</a></li>
        <li><a href="#pre-processing">Pre-processing</a></li>
        <li><a href="#protected-attributes">Protected attributes</a></li>
        <li><a href="#training-and-testing-subsets">Training and testing subsets</a></li>
      </ul>
    </li>
    <li><a href="#models">Models</a>
      <ul>
        <li><a href="#unfair-model">Unfair model</a></li>
        <li><a href="#full-model">Full model</a></li>
        <li><a href="#fairness-through-unawareness--ftu">Fairness through unawareness (FTU)</a></li>
        <li><a href="#latent-variable-model">Latent variable model</a></li>
        <li><a href="#additive-error-model">Additive error model</a></li>
        <li><a href="#comparison">Comparison</a></li>
      </ul>
    </li>
    <li><a href="#measuring-counterfactual-fairness">Measuring counterfactual fairness</a>
      <ul>
        <li><a href="#statistical-parity-difference-disparate-impact">Statistical Parity Difference / Disparate Impact</a></li>
        <li><a href="#finding-sensitive-features">Finding sensitive features</a></li>
      </ul>
    </li>
  </ul>
</nav>
      
      <h4>Related</h4>
      
      <nav>
      <ul>
      
      
        <li class="header-post toc"><a href="https://ruivieira.dev/counterfactual-fairness-in-java.html">Counterfactual Fairness in Java</a></li>
      
      
        <li class="header-post toc"><a href="https://ruivieira.dev/explainability.html">Explainability</a></li>
      
      
      </ul>
    </nav>
    </div>
    
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Counterfactual Fairness
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          Updated <time datetime="2021-12-07 21:49:31 &#43;0000 GMT" itemprop="datePublished">2021-12-07</time>
          <span class="commit-hash">(186a405)</span>
        </div>
        
        
        
        
      </div>
    </header>

  
    
    <div class="content" itemprop="articleBody">
      <h2 id="building-counterfactually-fair-models">Building counterfactually fair models</h2>
<h3 id="data">Data</h3>
<p>To evaluate <em>counterfactual fairness</em> we will be using the &ldquo;law school&rdquo; dataset<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>The Law School Admission Council conducted a survey across 163 law schools in the United States.  It contains information on 21,790 law students such as their entrance exam scores (<code>LSAT</code>), their grade-point average (<code>GPA</code>) collected prior to law school, and their first year average grade (<code>FYA</code>).
Given this data, a school may wish to predict if an applicant will have a high `FYA`. The school would
also like to make sure these predictions are not biased by an individual’s race and sex.
However, the <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> scores, may be biased due to social factors.</p>
<p>We start by importing the data into a [Pandas]] <code>DataFrame</code>.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import warnings

warnings.filterwarnings(&quot;ignore&quot;)
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import pandas as pd

df = pd.read_csv(&quot;data/law_data.csv&quot;, index_col=0)
df.head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">       race  sex  LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0     White    1  39.0   3.1           GL -0.98      0.782738       1.0
1     White    1  36.0   3.0           GL  0.09      0.735714       1.0
2     White    2  30.0   3.1           MS -0.35      0.670238       1.0
5  Hispanic    2  39.0   2.2           NE  0.58      0.697024       1.0
6     White    1  37.0   3.4           GL -1.26      0.786310       1.0
</code></pre></div><h3 id="pre-processing">Pre-processing</h3>
<p>We now pre-process the data. We start by creating categorical &ldquo;dummy&rdquo; variables according to the <code>race</code> variable.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df = pd.get_dummies(df, columns=[&quot;race&quot;], prefix=&quot;&quot;, prefix_sep=&quot;&quot;)
df.iloc[:, : 7].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   sex  LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0    1  39.0   3.1           GL -0.98      0.782738       1.0
1    1  36.0   3.0           GL  0.09      0.735714       1.0
2    2  30.0   3.1           MS -0.35      0.670238       1.0
5    2  39.0   2.2           NE  0.58      0.697024       1.0
6    1  37.0   3.4           GL -1.26      0.786310       1.0
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df.iloc[:, 7 :].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   Amerindian  Asian  Black  Hispanic  Mexican  Other  Puertorican  White
0           0      0      0         0        0      0            0      1
1           0      0      0         0        0      0            0      1
2           0      0      0         0        0      0            0      1
5           0      0      0         1        0      0            0      0
6           0      0      0         0        0      0            0      1
</code></pre></div><p>We also want to expand the `sex` variable into `male`/`female` categorical variables and remove the original.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df[&quot;male&quot;] = df[&quot;sex&quot;].map(lambda x: 1 if x == 2 else 0)
df[&quot;female&quot;] = df[&quot;sex&quot;].map(lambda x: 1 if x == 1 else 0)
df = df.drop(axis=1, columns=[&quot;sex&quot;])
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df.iloc[:, 0:7].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   LSAT  UGPA region_first  ZFYA  sander_index  first_pf  Amerindian
0  39.0   3.1           GL -0.98      0.782738       1.0           0
1  36.0   3.0           GL  0.09      0.735714       1.0           0
2  30.0   3.1           MS -0.35      0.670238       1.0           0
5  39.0   2.2           NE  0.58      0.697024       1.0           0
6  37.0   3.4           GL -1.26      0.786310       1.0           0
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df.iloc[:, 7:].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   Asian  Black  Hispanic  Mexican  Other  Puertorican  White  male  female
0      0      0         0        0      0            0      1     0       1
1      0      0         0        0      0            0      1     0       1
2      0      0         0        0      0            0      1     1       0
5      0      0         1        0      0            0      0     1       0
6      0      0         0        0      0            0      1     0       1
</code></pre></div><p>We will also convert the entrance exam scores (<code>LSAT</code>) to a discrete variable.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df[&quot;LSAT&quot;] = df[&quot;LSAT&quot;].astype(int)
df.iloc[:, :6].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   LSAT  UGPA region_first  ZFYA  sander_index  first_pf
0    39   3.1           GL -0.98      0.782738       1.0
1    36   3.0           GL  0.09      0.735714       1.0
2    30   3.1           MS -0.35      0.670238       1.0
5    39   2.2           NE  0.58      0.697024       1.0
6    37   3.4           GL -1.26      0.786310       1.0
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df.iloc[:, 6:].head()
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">   Amerindian  Asian  Black  Hispanic  Mexican  Other  Puertorican  White  \
0           0      0      0         0        0      0            0      1
1           0      0      0         0        0      0            0      1
2           0      0      0         0        0      0            0      1
5           0      0      0         1        0      0            0      0
6           0      0      0         0        0      0            0      1

   male  female
0     0       1
1     0       1
2     1       0
5     1       0
6     0       1
</code></pre></div><h3 id="protected-attributes">Protected attributes</h3>
<p><em>Counterfactual fairness</em> enforces that a distribution over possible predictions for an individual should
remain unchanged in a world where an individual’s protected attributes \(A\) had been different in a causal sense.
Let&rsquo;s start by defining the <em>protected attributes</em>. Obvious candidates are the different categorical variables for ethnicity (<code>Asian</code>, <code>White</code>, <code>Black</code>, <em>etc</em>) and gender (<code>male</code>, <code>female</code>).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">A = [
    &quot;Amerindian&quot;,
    &quot;Asian&quot;,
    &quot;Black&quot;,
    &quot;Hispanic&quot;,
    &quot;Mexican&quot;,
    &quot;Other&quot;,
    &quot;Puertorican&quot;,
    &quot;White&quot;,
    &quot;male&quot;,
    &quot;female&quot;,
]
</code></pre><h3 id="training-and-testing-subsets">Training and testing subsets</h3>
<p>We will now divide the dataset into training and testing subsets.
We will use the same ratio as in <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, that is 20%.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df, random_state=23, test_size=0.2);
</code></pre><h2 id="models">Models</h2>
<h3 id="unfair-model">Unfair model</h3>
<p>As detailed in <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, the concept of counterfactual fairness holds
under three levels of assumptions of increasing strength.</p>
<p>The first of such levels is <strong>Level 1</strong>, where \(\hat{Y}\) is built using only the observable non-descendants of \(A\).
This only requires <strong>partial</strong> causal ordering and no further causal assumptions, but in many problems there will be few, if any,
observables which are not descendants of protected demographic factors.</p>
<p>For this dataset, since <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> are all biased by ethnicity and gender, we cannot use any observed
features to construct a Level 1 counterfactually fair predictor as described in Level 1.</p>
<p>Instead (and in order to compare the performance with Level 2 and 3 models) we will build two <em>unfair baselines</em>.</p>
<ul>
<li>A <strong>Full</strong> model, which will be trained with the totality of the variables</li>
<li>An <strong>Unaware</strong> model (FTU), which will be trained will all the variables, except the protected attributes \(A\).</li>
</ul>
<p>Let&rsquo;s proceed with calculating the <strong>Full</strong> model.</p>
<h3 id="full-model">Full model</h3>
<p>As mentioned previously, the full model will be a simple linear regression in order to predict <code>ZFYA</code> using all of the variables.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from sklearn.linear_model import LinearRegression

linreg_unfair = LinearRegression()
</code></pre><p>The inputs will then be the totality of the variabes (protected variables \(A\), as well as `UGPA` and `LSAT`).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import numpy as np

X = np.hstack(
    (
        df_train[A],
        np.array(df_train[&quot;UGPA&quot;]).reshape(-1, 1),
        np.array(df_train[&quot;LSAT&quot;]).reshape(-1, 1),
    )
)
print(X)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">[[ 0.   0.   0.  ...  1.   3.1 39. ]
 [ 0.   0.   0.  ...  1.   3.5 36. ]
 [ 0.   0.   0.  ...  1.   3.9 46. ]
 ...
 [ 0.   0.   0.  ...  1.   2.9 33. ]
 [ 0.   0.   0.  ...  0.   2.9 31. ]
 [ 0.   0.   0.  ...  0.   3.6 39. ]]
</code></pre></div><p>As for our target, we are trying to predict `ZFYA` (first year average grade).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">y = df_train[&quot;ZFYA&quot;]
y[:10]
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">10454    0.56
14108    0.60
20624   -0.14
8316     0.20
14250    0.02
18909   -1.47
8949     1.36
1658     0.39
23340    0.10
26884    0.48
Name: ZFYA, dtype: float64
</code></pre></div><p>We fit the model:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_unfair = linreg_unfair.fit(X, y)
</code></pre><p>And perform some predictions on the test subset.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X_test = np.hstack(
    (
        df_test[A],
        np.array(df_test[&quot;UGPA&quot;]).reshape(-1, 1),
        np.array(df_test[&quot;LSAT&quot;]).reshape(-1, 1),
    )
)
X_test
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[ 0. ,  0. ,  0. , ...,  0. ,  3.4, 32. ],
       [ 0. ,  0. ,  0. , ...,  1. ,  3.5, 41. ],
       [ 0. ,  0. ,  0. , ...,  1. ,  3.9, 42. ],
       ...,
       [ 0. ,  0. ,  0. , ...,  0. ,  2.3, 28. ],
       [ 0. ,  0. ,  0. , ...,  0. ,  3.3, 36. ],
       [ 0. ,  0. ,  0. , ...,  0. ,  2.9, 37. ]])
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">predictions_unfair = linreg_unfair.predict(X_test)
predictions_unfair
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([ 0.08676147,  0.34942627,  0.4609375 , ..., -0.25949097,
        0.19308472,  0.14471436])
</code></pre></div><p>We will also calculate the <em>unfair model</em> score for future use.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">score_unfair = linreg_unfair.score(X_test, df_test[&quot;ZFYA&quot;])
print(score_unfair)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.12701634112845117
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from sklearn.metrics import mean_squared_error

RMSE_unfair = np.sqrt(mean_squared_error(df_test[&quot;ZFYA&quot;], predictions_unfair))
print(RMSE_unfair)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.8666709890234552
</code></pre></div><h3 id="fairness-through-unawareness--ftu">Fairness through unawareness (FTU)</h3>
<p>As also mentioned in <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, the second baseline we will use is an <strong><strong>Unaware</strong></strong> model (FTU), which will be trained will all the variables, except the protected attributes \(A\).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_ftu = LinearRegression()
</code></pre><p>We will create the inputs as previously, but without using the protected attributes, \(A\).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X_ftu = np.hstack(
    (
        np.array(df_train[&quot;UGPA&quot;]).reshape(-1, 1),
        np.array(df_train[&quot;LSAT&quot;]).reshape(-1, 1),
    )
)
X_ftu
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[ 3.1, 39. ],
       [ 3.5, 36. ],
       [ 3.9, 46. ],
       ...,
       [ 2.9, 33. ],
       [ 2.9, 31. ],
       [ 3.6, 39. ]])
</code></pre></div><p>And we fit the model:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_ftu = linreg_ftu.fit(X_ftu, y)
</code></pre><p>Again, let&rsquo;s perform some predictions on the test subset.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X_ftu_test = np.hstack(
    (np.array(df_test[&quot;UGPA&quot;]).reshape(-1, 1), np.array(df_test[&quot;LSAT&quot;]).reshape(-1, 1))
)
X_ftu_test
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[ 3.4, 32. ],
       [ 3.5, 41. ],
       [ 3.9, 42. ],
       ...,
       [ 2.3, 28. ],
       [ 3.3, 36. ],
       [ 2.9, 37. ]])
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">predictions_ftu = linreg_ftu.predict(X_ftu_test)
predictions_ftu
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([-0.06909331,  0.35516229,  0.50304555, ..., -0.53109868,
        0.08204563,  0.0226846 ])
</code></pre></div><p>As previously, let&rsquo;s calculate this model&rsquo;s score.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">ftu_score = linreg_ftu.score(X_ftu_test, df_test[&quot;ZFYA&quot;])
print(ftu_score)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.0917442226187073
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">RMSE_ftu = np.sqrt(mean_squared_error(df_test[&quot;ZFYA&quot;], predictions_ftu))
print(RMSE_ftu)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.8840061503773576
</code></pre></div><h3 id="latent-variable-model">Latent variable model</h3>
<p>Still according to <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, a <strong><strong>Level 2</strong></strong> approach will model latent ‘fair’ variables which are parents of observed variables.</p>
<p>If we consider a predictor parameterised by \(\theta\), such as:</p>
<p>\[
\hat{Y} \equiv g_\theta (U, X_{\nsucc A})
\]</p>
<p>with \(X_{\nsucc A} \subseteq X\) are non-descendants of \(A\).
Assuming a loss function \(l(\cdot,\cdot)\) and training data \(\mathcal{D}\equiv\{(A^{(i), X^{(i)}, Y^{(i)}})\}\), for \(i=1,2\dots,n\), the empirical loss is defined as</p>
<p>\[
L(\theta)\equiv \sum_{i=1}^n \mathbb{E}[l(y^{(i)},g_\theta(U^{(i)}, x^{(i)}_{\nsucc A}))]/n
\]</p>
<p>which has to be minimised in order to \(\theta\). Each \(n\) expectation is with respect to random variable \(U^{(i)}\) such that</p>
<p>\[
U^{(i)}\sim P_{\mathcal{M}}(U|x^{(i)}, a^{(i)})
\]</p>
<p>where \(P_{\mathcal{M}}(U|x,a)\) is the conditional distribution of the background variables as given by a causal model M that is available by assumption.</p>
<p>If this expectation cannot be calculated analytically, Markov chain Monte Carlo (MCMC) can be used to approximate it as in the following algorithm.</p>
<p>We will follow the model specified in the original paper, where the latent variable considered is \(K\), which represents a student&rsquo;s <strong><strong>knowledge</strong></strong>.
\(K\) will affect `GPA`, `LSAT` and the outcome, `FYA`.
The model can be defined by:</p>
<p>\begin{aligned}
GPA &amp;\sim \mathcal{N}(GPA_0 + w_{GPA}^KK + w_{GPA}^RR + w_{GPA}^SS, \sigma_{GPA}) \\
LSAT &amp;\sim \text{Po}(\exp(LSAT_0 + w_{LSAT}^KK + w_{LSAT}^RR + w_L^SS)) \\
FYA &amp;\sim \mathcal{N}(w_{FYA}^KK + w_{FYA}^RR + w_{FYA}^SS, 1) \\
K &amp;\sim \mathcal{N}(0,1)
\end{aligned}</p>
<p>The priors used will be:</p>
<p>\begin{aligned}
GPA_0 &amp;\sim \mathcal{N}(0, 1) \\
LSAT_0 &amp;\sim \mathcal{N}(0, 1) \\
GPA_0 &amp;\sim \mathcal{N}(0, 1)
\end{aligned}</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import pymc3 as pm

K = len(A)


def MCMC(data, samples=1000):

    N = len(data)
    a = np.array(data[A])

    model = pm.Model()

    with model:
        # Priors
        k = pm.Normal(&quot;k&quot;, mu=0, sigma=1, shape=(1, N))
        gpa0 = pm.Normal(&quot;gpa0&quot;, mu=0, sigma=1)
        lsat0 = pm.Normal(&quot;lsat0&quot;, mu=0, sigma=1)
        w_k_gpa = pm.Normal(&quot;w_k_gpa&quot;, mu=0, sigma=1)
        w_k_lsat = pm.Normal(&quot;w_k_lsat&quot;, mu=0, sigma=1)
        w_k_zfya = pm.Normal(&quot;w_k_zfya&quot;, mu=0, sigma=1)

        w_a_gpa = pm.Normal(&quot;w_a_gpa&quot;, mu=np.zeros(K), sigma=np.ones(K), shape=K)
        w_a_lsat = pm.Normal(&quot;w_a_lsat&quot;, mu=np.zeros(K), sigma=np.ones(K), shape=K)
        w_a_zfya = pm.Normal(&quot;w_a_zfya&quot;, mu=np.zeros(K), sigma=np.ones(K), shape=K)

        sigma_gpa_2 = pm.InverseGamma(&quot;sigma_gpa_2&quot;, alpha=1, beta=1)

        mu = gpa0 + (w_k_gpa * k) + pm.math.dot(a, w_a_gpa)

        # Observed data
        gpa = pm.Normal(
            &quot;gpa&quot;,
            mu=mu,
            sigma=pm.math.sqrt(sigma_gpa_2),
            observed=list(data[&quot;UGPA&quot;]),
            shape=(1, N),
        )
        lsat = pm.Poisson(
            &quot;lsat&quot;,
            pm.math.exp(lsat0 + w_k_lsat * k + pm.math.dot(a, w_a_lsat)),
            observed=list(data[&quot;LSAT&quot;]),
            shape=(1, N),
        )
        zfya = pm.Normal(
            &quot;zfya&quot;,
            mu=w_k_zfya * k + pm.math.dot(a, w_a_zfya),
            sigma=1,
            observed=list(data[&quot;ZFYA&quot;]),
            shape=(1, N),
        )

        step = pm.Metropolis()
        trace = pm.sample(samples, step, progressbar = False)

    return trace
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">train_estimates = MCMC(df_train)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Metropolis: [sigma_gpa_2]
&gt;Metropolis: [w_a_zfya]
&gt;Metropolis: [w_a_lsat]
&gt;Metropolis: [w_a_gpa]
&gt;Metropolis: [w_k_zfya]
&gt;Metropolis: [w_k_lsat]
&gt;Metropolis: [w_k_gpa]
&gt;Metropolis: [lsat0]
&gt;Metropolis: [gpa0]
&gt;Metropolis: [k]
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 77 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.
</code></pre></div><p>Let&rsquo;s plot a single trace for \(k^{(i)}\).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import matplotlib.pyplot as plt
import seaborn as sns
from plotutils import *

# Thin the samples before plotting
k_trace = train_estimates[&quot;k&quot;][:, 0].reshape(-1, 1)[0::100]
plt.subplot(1, 2, 1)
plt.hist(k_trace, color=colours[0], bins=100)
plt.subplot(1, 2, 2)
plt.scatter(range(len(k_trace)), k_trace, s=1, c=colours[0])
plt.show()
</code></pre><figure><img src="/ox-hugo/70405364f6b478b4fb212a0c3f658be9738e8156.png"/>
</figure>

<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">train_k = np.mean(train_estimates[&quot;k&quot;], axis=0).reshape(-1, 1)
train_k
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[-0.00531227],
       [-0.13776645],
       [-0.02434896],
       ...,
       [ 0.02273157],
       [-0.2767904 ],
       [-0.15568193]])
</code></pre></div><p>We can now estimate \(k\) using the test data:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">test_map_estimates = MCMC(df_test)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Metropolis: [sigma_gpa_2]
&gt;Metropolis: [w_a_zfya]
&gt;Metropolis: [w_a_lsat]
&gt;Metropolis: [w_a_gpa]
&gt;Metropolis: [w_k_zfya]
&gt;Metropolis: [w_k_lsat]
&gt;Metropolis: [w_k_gpa]
&gt;Metropolis: [lsat0]
&gt;Metropolis: [gpa0]
&gt;Metropolis: [k]
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
/Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp
  &#34;accept&#34;: np.exp(accept),
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 59 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.
</code></pre></div><p>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 35 seconds.
The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.
The estimated number of effective samples is smaller than 200 for some parameters.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">test_k = np.mean(test_map_estimates[&quot;k&quot;], axis=0).reshape(-1, 1)
test_k
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[ 0.36632736],
       [ 0.09415253],
       [ 0.03452081],
       ...,
       [ 0.00471526],
       [-0.09991792],
       [ 0.19771541]])
</code></pre></div><p>We now build the Level 2 predictor, using \(k\) as the input.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_latent = LinearRegression()
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_latent = linreg_latent.fit(train_k, df_train[&quot;ZFYA&quot;])
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">predictions_latent = linreg_latent.predict(test_k)
predictions_latent
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([0.18043648, 0.1160878 , 0.10198943, ..., 0.09494268, 0.07020488,
       0.14057256])
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">latent_score = linreg_latent.score(test_k, df_test[&quot;ZFYA&quot;])
print(latent_score)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.0027649341873033917
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">RMSE_latent = np.sqrt(mean_squared_error(df_test[&quot;ZFYA&quot;], predictions_latent))
print(RMSE_latent)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.9262963924423802
</code></pre></div><h3 id="additive-error-model">Additive error model</h3>
<p>Finally, in <strong><strong>Level 3</strong></strong>, we model `GPA`, `LSAT`, and `FYA` as continuous variables with additive error terms
independent of race and sex<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>This corresponds to</p>
<p>\begin{aligned}
GPA &amp;= b_G + w^R_{GPA}R + w^S_{GPA}S + \epsilon_{GPA}, \epsilon_{GPA} \sim p(\epsilon_{GPA}) \\
LSAT &amp;= b_L + w^R_{LSAT}R + w^S_{LSAT}S + \epsilon_{LSAT}, \epsilon_{LSAT} \sim p(\epsilon_{LSAT}) \\
FYA &amp;= b_{FYA} + w^R_{FYA}R + w^S_{FYA}S + \epsilon_{FYA} , \epsilon_{FYA} \sim p(\epsilon_{FYA})
\end{aligned}</p>
<p>We estimate the error terms \(\epsilon_{GPA}, \epsilon_{LSAT}\) by first fitting two models that each use race and sex to individually
predict `GPA` and `LSAT`. We then compute the residuals of each model (_e.g._, \(\epsilon_{GPA} =GPA−\hat{Y}_{GPA}(R, S)\)).
We use these residual estimates of \(\epsilon_{GPA}, \epsilon_{LSAT}\) to predict \(FYA\). In [^Kusner2017] this is called <!-- raw HTML omitted -->Fair Add<!-- raw HTML omitted -->.</p>
<p>Since the process is similar for the individual predictions for `GPA` and `LSAT`, we will write a method to avoid repetion.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">def calculate_epsilon(data, var_name, protected_attr):
    X = data[protected_attr]
    y = data[var_name]

    linreg = LinearRegression()
    linreg = linreg.fit(X, y)

    predictions = linreg.predict(X)

    return data[var_name] - predictions
</code></pre><p>Let&rsquo;s apply it to each variable, individually.
First we calculate \(\epsilon_{GPA}\):</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">epsilons_gpa = calculate_epsilon(df, &quot;UGPA&quot;, A)
epsilons_gpa
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0       -0.242
1       -0.342
2       -0.100
5       -0.873
6        0.058
         ...
27472    0.800
27473    0.358
27474    0.658
27475   -0.300
27476   -0.100
Name: UGPA, Length: 21791, dtype: float64
</code></pre></div><p>Next, we calculate \(\epsilon_{LSAT}\):</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">epsilons_LSAT = calculate_epsilon(df, &quot;LSAT&quot;, A)
epsilons_LSAT
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0        1.789
1       -1.211
2       -7.689
5        5.055
6       -0.211
         ...
27472   -4.689
27473    0.789
27474   -1.211
27475   -6.689
27476   -9.689
Name: LSAT, Length: 21791, dtype: float64
</code></pre></div><p>Let&rsquo;s visualise the \(\epsilon\) distribution quickly:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import matplotlib.pyplot as plt
import seaborn as sns

plt.subplot(1, 2, 1)
plt.hist(epsilons_gpa, color=colours[0], bins=100)
plt.title(&quot;$\epsilon_{GPA}$&quot;)
plt.xlabel(&quot;$\epsilon_{GPA}$&quot;)

plt.subplot(1, 2, 2)
plt.hist(epsilons_LSAT, color=colours[1], bins=100)
plt.title(&quot;$\epsilon_{LSAT}$&quot;)
plt.xlabel(&quot;$\epsilon_{LSAT}$&quot;)
plt.show()
</code></pre><figure><img src="/ox-hugo/1fbff0daab700f9804c68166ea84bef906ac3f93.png"/>
</figure>

<p>We finally use the calculated \(\epsilon\) to train a model in order to predict `FYA`.
We start by getting the subset of the \(\epsilon\) which match the training indices.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X = np.hstack(
    (
        np.array(epsilons_gpa[df_train.index]).reshape(-1, 1),
        np.array(epsilons_LSAT[df_train.index]).reshape(-1, 1),
    )
)
X
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[-0.24179687,  1.7890625 ],
       [ 0.15820312, -1.2109375 ],
       [ 0.55820312,  8.7890625 ],
       ...,
       [-0.44179688, -4.2109375 ],
       [-0.25087891, -4.7265625 ],
       [ 0.39980469,  1.31054688]])
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">linreg_fair_add = LinearRegression()

linreg_fair_add = linreg_fair_add.fit(
    X,
    df_train[&quot;ZFYA&quot;],
)
</code></pre><p>We now use this model to calculate the predictions</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X_test = np.hstack(
    (
        np.array(epsilons_gpa[df_test.index]).reshape(-1, 1),
        np.array(epsilons_LSAT[df_test.index]).reshape(-1, 1),
    )
)

predictions_fair_add = linreg_fair_add.predict(X_test)
predictions_fair_add
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([-0.04394693,  0.24454891,  0.35558793, ..., -0.38844376,
        0.06136776,  0.01295201])
</code></pre></div><p>And as previously, we calculate the model&rsquo;s score:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">fair_add_score = linreg_fair_add.score(X_test, df_test[&quot;ZFYA&quot;])
print(fair_add_score)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.04475841449183948
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">RMSE_fair_add = np.sqrt(mean_squared_error(df_test[&quot;ZFYA&quot;], predictions_fair_add))
print(RMSE_fair_add)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.9065835039365202
</code></pre></div><h3 id="comparison">Comparison</h3>
<p>The scores, so far, are:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">print(f&quot;Unfair score:\t{score_unfair}&quot;)
print(f&quot;FTU score:\t{ftu_score}&quot;)
print(f&quot;L2 score:\t{latent_score}&quot;)
print(f&quot;Fair add score:\t{fair_add_score}&quot;)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Unfair score:	0.12701634112845117
FTU score:	0.0917442226187073
L2 score:	0.0027649341873033917
Fair add score:	0.04475841449183948
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">print(f&quot;Unfair RMSE:\t{RMSE_unfair}&quot;)
print(f&quot;FTU RMSE:\t{RMSE_ftu}&quot;)
print(f&quot;L2 RMSE:\t{RMSE_latent}&quot;)
print(f&quot;Fair add RMSE:\t{RMSE_fair_add}&quot;)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Unfair RMSE:	0.8666709890234552
FTU RMSE:	0.8840061503773576
L2 RMSE:	0.9262963924423802
Fair add RMSE:	0.9065835039365202
</code></pre></div><h2 id="measuring-counterfactual-fairness">Measuring counterfactual fairness</h2>
<p>First, we will measure two quantities, the <strong><strong>Statistical Parity Difference</strong></strong> (SPD)<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> and <strong><strong>Disparate impact</strong></strong> (DI)<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<h3 id="statistical-parity-difference-disparate-impact">Statistical Parity Difference / Disparate Impact</h3>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio

parities = []
impacts = []

for a in A:
    parity = demographic_parity_difference(df_train[&quot;ZFYA&quot;], df_train[&quot;ZFYA&quot;],
                                                sensitive_features = df_train[a])
    di = demographic_parity_ratio(df_train[&quot;ZFYA&quot;], df_train[&quot;ZFYA&quot;],
                                                sensitive_features = df_train[a])
    parities.append(parity)
    impacts.append(di)
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">df_parities = pd.DataFrame({'protected':A,'parity':parities,'impact':impacts})
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import matplotlib.pyplot as plt
from plotutils import *

fig = plt.figure()

ax = fig.add_subplot(111)
ax2 = ax.twinx()

fig.suptitle('Statistical Parity Difference and Disparate Impact')

width = 0.4
df_parities.plot(x ='protected', y = 'parity', kind = 'bar', ax = ax, width = width,
       position=1, color=colours[0], legend=False)

df_parities.plot(x ='protected', y = 'impact', kind = 'bar', ax = ax2, width = width,
       position = 0, color = colours[1], legend = False)

ax.axhline(y = 0.1, linestyle = 'dashed', alpha = 0.7, color = colours[0])
ax2.axhline(y = 0.55, linestyle = 'dashed', alpha = 0.7, color = colours[1])


patches, labels = ax.get_legend_handles_labels()
ax.legend(patches, ['Stat Parity Diff'], loc = 'upper left')

patches, labels = ax2.get_legend_handles_labels()
ax2.legend(patches, ['Disparate Impact'], loc = 'upper right')



labels = [item.get_text() for item in ax.get_xticklabels()]

for i in range(len(A)):
    labels[i] = A[i]

ax.set_xticklabels(labels)
ax.set_xlabel('Protected Features')

ax.set_ylabel('Statistical Parity Difference')
ax2.set_ylabel('Disparate Impact')

plt.show()
</code></pre><figure><img src="/ox-hugo/938fda75bc5f941252060110b289058e5d383f09.png"/>
</figure>

<h3 id="finding-sensitive-features">Finding sensitive features</h3>
<p>Typically a \(SPD &gt; 0.1\) and a \(DI &lt; 0.9\) might indicate discrimination on those features.
All <!-- raw HTML omitted -->protected attributes<!-- raw HTML omitted --> fail the SPD test and, in our dataset, we have two features (`Hispanic` and `Mexican`) which clearly fail the DI test.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">for a in [&quot;Mexican&quot;, &quot;Hispanic&quot;]:
    spd = demographic_parity_difference(y_true=df_train[&quot;ZFYA&quot;],
                                        y_pred=df_train[&quot;ZFYA&quot;],
                                        sensitive_features = df_train[a])
    print(f&quot;SPD({a}) = {spd}&quot;)
    di = demographic_parity_ratio(y_true=df_train[&quot;ZFYA&quot;],
                                  y_pred=df_train[&quot;ZFYA&quot;],
                                  sensitive_features = df_train[a])
    print(f&quot;DI({a}) = {di}&quot;)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">SPD(Mexican) = 0.0014017257538768636
DI(Mexican) = 0.5556529360210342
SPD(Hispanic) = 0.003272247102713093
DI(Hispanic) = 0.34227833235466826
</code></pre></div><section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>: McIntyre, Frank, and Michael Simkovic. &ldquo;Are law degrees as valuable to minorities?.&rdquo; International Review of Law and Economics 53 (2018): 23-37.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>: Kusner, Matt J., Joshua Loftus, Chris Russell, and Ricardo Silva. &ldquo;Counterfactual fairness.&rdquo; In Advances in neural information processing systems, pp. 4066-4076. 2017.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>: That may in turn be correlated with one-another.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>: See {ref}`fairness:demographic-parity-difference`.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>: See {ref}`fairness:disparate-impact`.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </div>
  </article>



  
  






  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/map/">All pages</a></li>
         
          <li><a href="/search.html">Search</a></li>
        
      </ul>
    </div>

    
    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#building-counterfactually-fair-models">Building counterfactually fair models</a>
      <ul>
        <li><a href="#data">Data</a></li>
        <li><a href="#pre-processing">Pre-processing</a></li>
        <li><a href="#protected-attributes">Protected attributes</a></li>
        <li><a href="#training-and-testing-subsets">Training and testing subsets</a></li>
      </ul>
    </li>
    <li><a href="#models">Models</a>
      <ul>
        <li><a href="#unfair-model">Unfair model</a></li>
        <li><a href="#full-model">Full model</a></li>
        <li><a href="#fairness-through-unawareness--ftu">Fairness through unawareness (FTU)</a></li>
        <li><a href="#latent-variable-model">Latent variable model</a></li>
        <li><a href="#additive-error-model">Additive error model</a></li>
        <li><a href="#comparison">Comparison</a></li>
      </ul>
    </li>
    <li><a href="#measuring-counterfactual-fairness">Measuring counterfactual fairness</a>
      <ul>
        <li><a href="#statistical-parity-difference-disparate-impact">Statistical Parity Difference / Disparate Impact</a></li>
        <li><a href="#finding-sensitive-features">Finding sensitive features</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
    

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label="Facebook">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label="Twitter">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="Linkedin">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label="Pinterest">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html" aria-label="Email">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="Pocket">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label="reddit">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20%60FYA%60." aria-label="Tumblr">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu-toggle" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;" aria-label="Menu">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
        <a id="toc-toggle" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;" aria-label="TOC">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share-toggle" class="icon" href="#" onclick="$('#share-footer').toggle();return false;" aria-label="Share">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2021  Rui Vieira 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/map/">All pages</a></li>
         
        <li><a href="/search.html">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/css/fa.min.css>
<script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/main.js></script>



  


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</html>
