<!doctype html><html lang=en-uk><head><script data-goatcounter=https://ruivieira-dev.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script type=module src=./js/deeplinks/deeplinks.js></script>
<link rel=preload href=./lib/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=./lib/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=./lib/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=./lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=./css/kbd.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Counterfactual Fairness · Rui Vieira</title><link rel=canonical href=/counterfactual-fairness.html><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Counterfactual Fairness"><meta property="og:description" content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high FYA."><meta property="og:type" content="article"><meta property="og:url" content="/counterfactual-fairness.html"><meta property="article:section" content="posts"><meta property="article:modified_time" content="2022-06-26T17:32:50+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Counterfactual Fairness"><meta name=twitter:description content="Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the &ldquo;law school&rdquo; dataset1.
The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high FYA."><link rel=stylesheet href=./css/styles.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=images/favicon.ico></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-eye fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick="$('html, body').animate({scrollTop:0},'fast')" style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=./>Home</a></li><li><a href=./map/>All pages</a></li><li><a href=./search.html>Search</a></li></ul></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=%2fcounterfactual-fairness.html" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: %2fcounterfactual-fairness.html" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20FYA." aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><h4>Contents</h4><nav id=TableOfContents><ul><li><a href=#building-counterfactually-fair-models>Building counterfactually fair models</a><ul><li><a href=#data>Data</a></li><li><a href=#pre-processing>Pre-processing</a></li><li><a href=#protected-attributes>Protected attributes</a></li><li><a href=#training-and-testing-subsets>Training and testing subsets</a></li></ul></li><li><a href=#models>Models</a><ul><li><a href=#unfair-model>Unfair model</a></li><li><a href=#full-model>Full model</a></li><li><a href=#fairness-through-unawareness-ftu>Fairness through unawareness (FTU)</a></li><li><a href=#latent-variable-model>Latent variable model</a></li></ul></li></ul></nav><h4>Related</h4><nav><ul><li class="header-post toc"><span class=backlink-count>3</span>
<a href=./counterfactual-fairness-in-java.html>Counterfactual Fairness in Java</a></li><li class="header-post toc"><span class=backlink-count>1</span>
<a href=./explainability.html>Explainability</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Counterfactual Fairness</h1><div class=meta><div class=postdate>Updated <time datetime="2022-06-26 17:32:50 +0100 BST" itemprop=datePublished>2022-06-26</time>
<span class=commit-hash>(55a05f2)</span></div></div></header><div class=content itemprop=articleBody><h2 id=building-counterfactually-fair-models>Building counterfactually fair models</h2><h3 id=data>Data</h3><p>To evaluate <em>counterfactual fairness</em> we will be using the &ldquo;law school&rdquo; dataset<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>The Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (<code>LSAT</code>), their grade-point average (<code>GPA</code>) collected prior to law school, and their first year average grade (<code>FYA</code>).
Given this data, a school may wish to predict if an applicant will have a high <code>FYA</code>. The school would
also like to make sure these predictions are not biased by an individual’s race and sex.
However, the <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> scores, may be biased due to social factors.</p><p>We start by importing the data into a [Pandas]] <code>DataFrame</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>warnings</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>warnings<span style=font-weight:700>.</span>filterwarnings(<span style=color:#b84>&#34;ignore&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>pandas</span> <span style=font-weight:700>as</span> <span style=color:#555>pd</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>read_csv(<span style=color:#b84>&#34;data/law_data.csv&#34;</span>, index_col<span style=font-weight:700>=</span><span style=color:#099>0</span>)
</span></span><span style=display:flex><span>df<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><h3 id=pre-processing>Pre-processing</h3><p>We now pre-process the data. We start by creating categorical &ldquo;dummy&rdquo; variables according to the <code>race</code> variable.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=font-weight:700>=</span> pd<span style=font-weight:700>.</span>get_dummies(df, columns<span style=font-weight:700>=</span>[<span style=color:#b84>&#34;race&#34;</span>], prefix<span style=font-weight:700>=</span><span style=color:#b84>&#34;&#34;</span>, prefix_sep<span style=font-weight:700>=</span><span style=color:#b84>&#34;&#34;</span>)
</span></span><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, : <span style=color:#099>7</span>]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>7</span> :]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><p>We also want to expand the <code>sex</code> variable into <code>male</code> / <code>female</code> categorical variables and remove the original.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df[<span style=color:#b84>&#34;male&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;sex&#34;</span>]<span style=font-weight:700>.</span>map(<span style=font-weight:700>lambda</span> x: <span style=color:#099>1</span> <span style=font-weight:700>if</span> x <span style=font-weight:700>==</span> <span style=color:#099>2</span> <span style=font-weight:700>else</span> <span style=color:#099>0</span>)
</span></span><span style=display:flex><span>df[<span style=color:#b84>&#34;female&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;sex&#34;</span>]<span style=font-weight:700>.</span>map(<span style=font-weight:700>lambda</span> x: <span style=color:#099>1</span> <span style=font-weight:700>if</span> x <span style=font-weight:700>==</span> <span style=color:#099>1</span> <span style=font-weight:700>else</span> <span style=color:#099>0</span>)
</span></span><span style=display:flex><span>df <span style=font-weight:700>=</span> df<span style=font-weight:700>.</span>drop(axis<span style=font-weight:700>=</span><span style=color:#099>1</span>, columns<span style=font-weight:700>=</span>[<span style=color:#b84>&#34;sex&#34;</span>])
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>0</span>:<span style=color:#099>7</span>]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>7</span>:]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><p>We will also convert the entrance exam scores (<code>LSAT</code>) to a discrete variable.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df[<span style=color:#b84>&#34;LSAT&#34;</span>] <span style=font-weight:700>=</span> df[<span style=color:#b84>&#34;LSAT&#34;</span>]<span style=font-weight:700>.</span>astype(<span style=color:#999>int</span>)
</span></span><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, :<span style=color:#099>6</span>]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=font-weight:700>.</span>iloc[:, <span style=color:#099>6</span>:]<span style=font-weight:700>.</span>head()
</span></span></code></pre></div><h3 id=protected-attributes>Protected attributes</h3><p><em>Counterfactual fairness</em> enforces that a distribution over possible predictions for an individual should
remain unchanged in a world where an individual’s protected attributes $A$ had been different in a causal sense.
Let&rsquo;s start by defining the /protected attributes/. Obvious candidates are the different categorical variables for ethnicity (<code>Asian</code>, <code>White</code>, <code>Black</code>, <em>etc</em>) and gender (<code>male</code>, <code>female</code>).</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>A <span style=font-weight:700>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Amerindian&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Asian&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Black&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Hispanic&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Mexican&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Other&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;Puertorican&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;White&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;male&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b84>&#34;female&#34;</span>,
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><h3 id=training-and-testing-subsets>Training and testing subsets</h3><p>We will now divide the dataset into training and testing subsets.
We will use the same ratio as in <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, that is 20%.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.model_selection</span> <span style=font-weight:700>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df_train, df_test <span style=font-weight:700>=</span> train_test_split(df, random_state<span style=font-weight:700>=</span><span style=color:#099>23</span>, test_size<span style=font-weight:700>=</span><span style=color:#099>0.2</span>);
</span></span></code></pre></div><h2 id=models>Models</h2><h3 id=unfair-model>Unfair model</h3><p>As detailed in <sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, the concept of counterfactual fairness holds
under three levels of assumptions of increasing strength.</p><p>The first of such levels is <em>Level 1</em>, where $\hat{Y}$ is built using only the observable non-descendants of $A$.
This only requires <em>partial</em> causal ordering and no further causal assumptions, but in many problems there will be few, if any,
observables which are not descendants of protected demographic factors.</p><p>For this dataset, since <code>LSAT</code>, <code>GPA</code>, and <code>FYA</code> are all biased by ethnicity and gender, we cannot use any observed
features to construct a Level 1 counterfactually fair predictor as described in Level 1.</p><p>Instead (and in order to compare the performance with Level 2 and 3 models) we will build two <em>unfair baselines</em>.</p><ul><li>A <em>Full</em> model, which will be trained with the totality of the variables</li><li>An <em>Unaware</em> model (FTU), which will be trained will all the variables, except the protected attributes $A$.</li></ul><p>Let&rsquo;s proceed with calculating the <em>Full</em> model.</p><h3 id=full-model>Full model</h3><p>As mentioned previously, the full model will be a simple linear regression in order to predict <code>ZFYA</code> using all of the variables.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.linear_model</span> <span style=font-weight:700>import</span> LinearRegression
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>linreg_unfair <span style=font-weight:700>=</span> LinearRegression()
</span></span></code></pre></div><p>The inputs will then be the totality of the variabes (protected variables $A$, as well as <code>UGPA</code> and <code>LSAT</code>).</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
</span></span><span style=display:flex><span>    (
</span></span><span style=display:flex><span>        df_train[A],
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#999>print</span>(X)
</span></span></code></pre></div><p>As for our target, we are trying to predict ~ZFYA~ (first year average grade).</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y <span style=font-weight:700>=</span> df_train[<span style=color:#b84>&#34;ZFYA&#34;</span>]
</span></span><span style=display:flex><span>y[:<span style=color:#099>10</span>]
</span></span></code></pre></div><p>We fit the model:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>linreg_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>fit(X, y)
</span></span></code></pre></div><p>And perform some predictions on the test subset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_test <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
</span></span><span style=display:flex><span>    (
</span></span><span style=display:flex><span>        df_test[A],
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X_test
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>predictions_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>predict(X_test)
</span></span><span style=display:flex><span>predictions_unfair
</span></span></code></pre></div><p>We will also calculate the /unfair model/ score for future use.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>score_unfair <span style=font-weight:700>=</span> linreg_unfair<span style=font-weight:700>.</span>score(X_test, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
</span></span><span style=display:flex><span><span style=color:#999>print</span>(score_unfair)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>from</span> <span style=color:#555>sklearn.metrics</span> <span style=font-weight:700>import</span> mean_squared_error
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RMSE_unfair <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_unfair))
</span></span><span style=display:flex><span><span style=color:#999>print</span>(RMSE_unfair)
</span></span></code></pre></div><h3 id=fairness-through-unawareness-ftu>Fairness through unawareness (FTU)</h3><p>As also mentioned in <sup id=fnref2:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, the second baseline we will use is an <strong>Unaware</strong> model (FTU), which will be trained will all the variables, except the protected attributes $A$.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>linreg_ftu <span style=font-weight:700>=</span> LinearRegression()
</span></span></code></pre></div><p>We will create the inputs as previously, but without using the protected attributes, $A$.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_ftu <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
</span></span><span style=display:flex><span>    (
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>        np<span style=font-weight:700>.</span>array(df_train[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>),
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X_ftu
</span></span></code></pre></div><p>And we fit the model:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>linreg_ftu <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>fit(X_ftu, y)
</span></span></code></pre></div><p>Again, let&rsquo;s perform some predictions on the test subset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>X_ftu_test <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>hstack(
</span></span><span style=display:flex><span>    (np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;UGPA&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>), np<span style=font-weight:700>.</span>array(df_test[<span style=color:#b84>&#34;LSAT&#34;</span>])<span style=font-weight:700>.</span>reshape(<span style=font-weight:700>-</span><span style=color:#099>1</span>, <span style=color:#099>1</span>))
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X_ftu_test
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>predictions_ftu <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>predict(X_ftu_test)
</span></span><span style=display:flex><span>predictions_ftu
</span></span></code></pre></div><p>As previously, let&rsquo;s calculate this model&rsquo;s score.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>ftu_score <span style=font-weight:700>=</span> linreg_ftu<span style=font-weight:700>.</span>score(X_ftu_test, df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>])
</span></span><span style=display:flex><span><span style=color:#999>print</span>(ftu_score)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>RMSE_ftu <span style=font-weight:700>=</span> np<span style=font-weight:700>.</span>sqrt(mean_squared_error(df_test[<span style=color:#b84>&#34;ZFYA&#34;</span>], predictions_ftu))
</span></span><span style=display:flex><span><span style=color:#999>print</span>(RMSE_ftu)
</span></span></code></pre></div><h3 id=latent-variable-model>Latent variable model</h3><p>Still according to <sup id=fnref3:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, a <strong>Level 2</strong> approach will model latent ‘fair’ variables which are parents of observed variables.</p><p>If we consider a predictor parameterised by $\theta$, such as:</p><p>$$
\hat{Y} \equiv g_\theta (U, X_{\nsucc A})
$$</p><p>with $X_{\nsucc A} \subseteq X$ are non-descendants of $A$.
Assuming a loss function $l(</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>McIntyre, Frank, and Michael Simkovic. &ldquo;Are law degrees as valuable to minorities?.&rdquo; International Review of Law and Economics 53 (2018): 23-37.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Kusner, Matt J., Joshua Loftus, Chris Russell, and Ricardo Silva. &ldquo;Counterfactual fairness.&rdquo; In Advances in neural information processing systems, pp. 4066-4076. 2017.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref3:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=./>Home</a></li><li><a href=./map/>All pages</a></li><li><a href=./search.html>Search</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#building-counterfactually-fair-models>Building counterfactually fair models</a><ul><li><a href=#data>Data</a></li><li><a href=#pre-processing>Pre-processing</a></li><li><a href=#protected-attributes>Protected attributes</a></li><li><a href=#training-and-testing-subsets>Training and testing subsets</a></li></ul></li><li><a href=#models>Models</a><ul><li><a href=#unfair-model>Unfair model</a></li><li><a href=#full-model>Full model</a></li><li><a href=#fairness-through-unawareness-ftu>Fairness through unawareness (FTU)</a></li><li><a href=#latent-variable-model>Latent variable model</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=%2fcounterfactual-fairness.html" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=%2fcounterfactual-fairness.html&text=Counterfactual%20Fairness" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=%2fcounterfactual-fairness.html&is_video=false&description=Counterfactual%20Fairness" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Counterfactual%20Fairness&body=Check out this article: %2fcounterfactual-fairness.html" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=%2fcounterfactual-fairness.html&title=Counterfactual%20Fairness" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=%2fcounterfactual-fairness.html&name=Counterfactual%20Fairness&description=Building%20counterfactually%20fair%20models%20Data%20To%20evaluate%20counterfactual%20fairness%20we%20will%20be%20using%20the%20%26ldquo%3blaw%20school%26rdquo%3b%20dataset1.%0aThe%20Law%20School%20Admission%20Council%20conducted%20a%20survey%20across%20163%20law%20schools%20in%20the%20United%20States.%20It%20contains%20information%20on%2021%2c790%20law%20students%20such%20as%20their%20entrance%20exam%20scores%20%28LSAT%29%2c%20their%20grade-point%20average%20%28GPA%29%20collected%20prior%20to%20law%20school%2c%20and%20their%20first%20year%20average%20grade%20%28FYA%29.%20Given%20this%20data%2c%20a%20school%20may%20wish%20to%20predict%20if%20an%20applicant%20will%20have%20a%20high%20FYA." aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=%2fcounterfactual-fairness.html&t=Counterfactual%20Fairness" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick="return $('#nav-footer').toggle(),!1" aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick="return $('#toc-footer').toggle(),!1" aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick="return $('#share-footer').toggle(),!1" aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast')" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2022 Rui Vieira</div><div class=footer-right><nav><ul><li><a href=./>Home</a></li><li><a href=./map/>All pages</a></li><li><a href=./search.html>Search</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=./css/fa.min.css><script src=./js/jquery-3.6.0.min.js></script>
<script src=./js/mark.min.js></script>
<script src=./js/main.js></script>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>