<!DOCTYPE html>
<html lang="en-uk">
<head>
  <script data-goatcounter="https://ruivieira-dev.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
  <script type="module" src="/js/deeplinks/deeplinks.js"></script>
  <link rel="preload" href="/lib/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/kbd.css" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Dunn index | Rui Vieira</title>
  <link rel = 'canonical' href = 'https://ruivieira.dev/dunn-index.html'>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Dunn index" />
<meta property="og:description" content="There are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the Dunn index, Davis-Bouldin index and Silhoutte index.
But before we start, let&rsquo;s introduce some concepts.
We are interested in clustering algorithms for a dataset \(\mathcal{D}\) with \(N\) elements in a $n$-dimensional real space, that is:
\[ \mathcal{D} = {x_1, x_2, \ldots, x_N} \in \mathbb{R}^p \]
The clustering algorithm will create a set \(C\) of \(K\) distinct disjoint groups from \(\mathcal{D}\) \(C={c_1, c_2, \ldots, c_k}\), such that:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ruivieira.dev/dunn-index.html" /><meta property="article:section" content="posts" />

<meta property="article:modified_time" content="2021-12-07T21:49:31+00:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Dunn index"/>
<meta name="twitter:description" content="There are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the Dunn index, Davis-Bouldin index and Silhoutte index.
But before we start, let&rsquo;s introduce some concepts.
We are interested in clustering algorithms for a dataset \(\mathcal{D}\) with \(N\) elements in a $n$-dimensional real space, that is:
\[ \mathcal{D} = {x_1, x_2, \ldots, x_N} \in \mathbb{R}^p \]
The clustering algorithm will create a set \(C\) of \(K\) distinct disjoint groups from \(\mathcal{D}\) \(C={c_1, c_2, \ldots, c_k}\), such that:"/>

  
  
    
  
  
  <link rel="stylesheet" href="https://ruivieira.dev/css/styles.a79457dee09605722c187170e1f001057207e2c93fc96404bb2a6c4cb05cd5f21213b095a3d9073117560bf616c0b96c897a1b862847d6a669e830262706cc68.css" integrity="sha512-p5RX3uCWBXIsGHFw4fABBXIH4sk/yWQEuypsTLBc1fISE7CVo9kHMRdWC/YWwLlsiXobhihH1qZp6DAmJwbMaA=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://ruivieira.dev/images/favicon.ico" />

  
  
  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/map/">All pages</a></li>
         
        <li><a href="/search.html">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://ruivieira.dev/elisp.html" aria-label="Previous">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="https://ruivieira.dev/doom-emacs.html" aria-label="Next">
            <i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i>
          </a>
        </li>
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#" aria-label="Share">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fdunn-index.html" aria-label="Facebook">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&text=Dunn%20index" aria-label="Twitter">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="Linkedin">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&is_video=false&description=Dunn%20index" aria-label="Pinterest">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Dunn%20index&body=Check out this article: https%3a%2f%2fruivieira.dev%2fdunn-index.html" aria-label="Email">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="Pocket">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="reddit">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&name=Dunn%20index&description=There%20are%20several%20ways%20to%20measure%20the%20robustness%20of%20a%20clustering%20algorithm.%20Three%20commonly%20used%20metrics%20are%20the%20Dunn%20index%2c%20Davis-Bouldin%20index%20and%20Silhoutte%20index.%0aBut%20before%20we%20start%2c%20let%26rsquo%3bs%20introduce%20some%20concepts.%0aWe%20are%20interested%20in%20clustering%20algorithms%20for%20a%20dataset%20%5c%28%5cmathcal%7bD%7d%5c%29%20with%20%5c%28N%5c%29%20elements%20in%20a%20%24n%24-dimensional%20real%20space%2c%20that%20is%3a%0a%5c%5b%20%5cmathcal%7bD%7d%20%3d%20%7bx_1%2c%20x_2%2c%20%5cldots%2c%20x_N%7d%20%5cin%20%5cmathbb%7bR%7d%5ep%20%5c%5d%0aThe%20clustering%20algorithm%20will%20create%20a%20set%20%5c%28C%5c%29%20of%20%5c%28K%5c%29%20distinct%20disjoint%20groups%20from%20%5c%28%5cmathcal%7bD%7d%5c%29%20%5c%28C%3d%7bc_1%2c%20c_2%2c%20%5cldots%2c%20c_k%7d%5c%29%2c%20such%20that%3a" aria-label="Tumblr">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fdunn-index.html&t=Dunn%20index" aria-label="Hacker News">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    
    
    <div id="toc">
      <h4>Contents</h4>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#dunn-index">Dunn index</a></li>
  </ul>
</nav>
      
      <h4>Related</h4>
      
      <nav>
      <ul>
      
      
        <li class="header-post toc"><a href="https://ruivieira.dev/distance-metrics.html">Distance metrics</a></li>
      
      
      </ul>
    </nav>
    </div>
    
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Dunn index
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          Updated <time datetime="2021-12-07 21:49:31 &#43;0000 GMT" itemprop="datePublished">2021-12-07</time>
          <span class="commit-hash">(186a405)</span>
        </div>
        
        
        
        
      </div>
    </header>

  
    
    <div class="content" itemprop="articleBody">
      <p>There are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the <strong><strong>Dunn index</strong></strong>, <strong><strong>Davis-Bouldin index</strong></strong> and <strong><strong>Silhoutte index</strong></strong>.</p>
<p>But before we start, let&rsquo;s introduce some concepts.</p>
<p>We are interested in clustering algorithms for a dataset \(\mathcal{D}\) with \(N\) elements in a $n$-dimensional real space, that is:</p>
<p>\[
\mathcal{D} = {x_1, x_2, \ldots, x_N} \in \mathbb{R}^p
\]</p>
<p>The clustering algorithm will create a set \(C\) of \(K\) distinct disjoint groups from \(\mathcal{D}\) \(C={c_1, c_2, \ldots, c_k}\), such that:</p>
<p>\[
\cup_{c_k\in C}c_k=\mathcal{D} \\
c_k \cap c_l \neq \emptyset \forall k\neq l
\]</p>
<p>Each group (or cluster) \(c_k\), will have a <strong><strong>centroid</strong></strong>, \(\bar{c}_k\), which is the mean vector of its elements such that:</p>
<p>\[
\bar{c}_k=\frac{1}{|c_k|}\sum_{x_i \in c_k}x_i
\]</p>
<p>We will also make use of the dataset&rsquo;s mean vector, \(\bar{\mathcal{D}}\), defined as:</p>
<p>\[
\bar{\mathcal{D}}=\frac{1}{N}\sum_{x_i \in X}x_i
\]</p>
<h2 id="dunn-index">Dunn index</h2>
<p>The <strong><strong>Dunn index</strong></strong> aims at quantifying the compactness and variance of the clustering.
A cluster is considered <strong><strong>compact</strong></strong> if there is small variance between members of the cluster.
This can be calculated using \(\Delta(c_k)\), where</p>
<p>\[
\Delta(c_k) = \max_{x_i, x_j \in c_k}{d_e(x_i, x_j)}
\]</p>
<p>and \(d_e\) is the <a href="/distance-metrics.html">Euclidean distance</a> defined as:</p>
<p>\[
d_e=\sqrt{\sum_{j=1}^p (x_{ij}-x_{kj})^2}.
\]</p>
<p>A cluster is considered <strong>well separated</strong> if the cluster are far-apart. This can quantified using</p>
<p>\[
\delta(c_k, c_l) = \min_{x_i \in c_k}\min_{x_j\in c_l}{d_e(x_i, x_j)}.
\]</p>
<p>Given these quantities, the <strong>Dunn index</strong> for a set of clusters \(C\), \(DI( C)\), is then defined by:</p>
<p>\[
DI( C)=\frac{\min_{c_k \in C}{\delta(c_k, c_l)}}{\max_{c_k\in C}\Delta(c_k)}
\]</p>
<p>A higher <strong>Dunn Index</strong> will indicate compact, well-separated clusters, while a lower index will indicate less compact or less well-separated clusters.</p>
<p>We can now try to calculate the metric for the dataset we&rsquo;ve created previously.
Let&rsquo;s simulate some data and apply the Dunn index from scratch.
First, we will create a compact and well-separated dataset using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make%5C%5Fblobs.html">make_blobs</a> method in <code>scikit-learn</code>.
We will create a dataset of \(\mathbb{R}^2\) data (for easier plotting), with three clusters.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from sklearn.datasets import make_blobs

X, y = make_blobs(n_samples=1000,
                  centers=3,
                  n_features=2,
                  random_state=23)
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import pandas as pd
from plotnine import *
from plotnine.data import *
from plotutils import *

data = pd.DataFrame(X, columns=[&quot;x1&quot;, &quot;x2&quot;])
data[&quot;y&quot;] = y
data[&quot;y&quot;] = data.y.astype('category')

ggplot(data=data) + \
    geom_point(mapping=aes(x=&quot;x1&quot;, y=&quot;x2&quot;, colour=&quot;y&quot;)) + \
    scale_color_manual(values=[colours[0], colours[1], colours[2]]) + \
    theme_classic()
</code></pre><p>We now cluster the data[^2] and we will have, as expected three distinct clusters, plotted below.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">from sklearn import cluster

k_means = cluster.KMeans(n_clusters=3)
k_means.fit(data)
y_pred = k_means.predict(data)

prediction = pd.concat([data, pd.DataFrame(y_pred, columns=['pred'])], axis = 1)

clus0 = prediction.loc[prediction.pred == 0]
clus1 = prediction.loc[prediction.pred == 1]
clus2 = prediction.loc[prediction.pred == 2]
k_list = [clus0.values, clus1.values,clus2.values]
</code></pre><p>Let&rsquo;s focus now on two of these cluster, let&rsquo;s call them \(c_k\) and \(c_l\).</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">ck = k_list[0]
cl = k_list[1]
</code></pre><p>We know we have to calculate the distance between the points in \(c_k\) and \(c_l\). We know that the `len(ck)=len(cl)=333` we create</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import numpy as np

values = np.ones([len(ck), len(cl)])
values
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       ...,
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]])
</code></pre></div><p>For each pair of points, we then get the norm of \(x_i-x_j\). For instance, for \(i=0\in c_k\) and \(i=1\in c_l\), we would have:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">values[0, 1] = np.linalg.norm(ck[0]-cl[1])
print(ck[0], cl[1])
print(values[0, 1])
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">[-5.37039106  3.47555168  2.          0.        ] [ 5.46312794 -3.08938807  1.          1.        ]
12.746119711608184
</code></pre></div><p>The calculation of \(\delta(c_k, c_l)\) between two clusters \(c_k\) and \(c_l\) will be defined as follows:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">import numpy as np

def δ(ck, cl):
    values = np.ones([len(ck), len(cl)])
    for i in range(0, len(ck)):
        for j in range(0, len(cl)):
            values[i, j] = np.linalg.norm(ck[i]-cl[j])
    return np.min(values)
</code></pre><p>So, for our two clusters above, \(\delta(c_k, c_l)\) will be:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">δ(ck, cl)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">8.13474311744193
</code></pre></div><p>Within a single cluster \(c_k\), we can calculate \(\Delta(c_k)\) similarly as:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">def Δ(ci):
    values = np.zeros([len(ci), len(ci)])
    for i in range(0, len(ci)):
        for j in range(0, len(ci)):
            values[i, j] = np.linalg.norm(ci[i]-ci[j])
    return np.max(values)
</code></pre><p>So, for instance, for our \(c_k\) and \(c_l\) we would have:</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">print(Δ(ck))
print(Δ(cl))
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">6.726025773561468
6.173844284636552
</code></pre></div><p>We can now define the <strong>Dunn index</strong> as</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">def dunn(k_list):
    δs = np.ones([len(k_list), len(k_list)])
    Δs = np.zeros([len(k_list), 1])
    l_range = list(range(0, len(k_list)))
    for k in l_range:
        for l in (l_range[0:k]+l_range[k+1:]):
            δs[k, l] = δ(k_list[k], k_list[l])
            Δs[k] = Δ(k_list[k])
            di = np.min(δs)/np.max(Δs)
    return di
</code></pre><p>and calculate the <strong>Dunn index</strong> for our clustered values list as</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">dunn(k_list)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.14867620697065728
</code></pre></div><p>Intuitively, we can expect a dataset with less well-defined clusters to have a lower <strong>Dunn index</strong>. Let&rsquo;s try it.
We first generate the new dataset.</p>
<pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">X, y = make_blobs(n_samples=1000,
                  centers=3,
                  n_features=2,
                  cluster_std=10.0,
                  random_state=24)

df = pd.DataFrame(X, columns=['A', 'B'])

k_means = cluster.KMeans(n_clusters=3)
k_means.fit(df)

#K-means training
y_pred = k_means.predict(df)

prediction = pd.concat([df,pd.DataFrame(y_pred, columns=['pred'])], axis = 1)
prediction[&quot;pred&quot;] = prediction.pred.astype('category')
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">ggplot(data=prediction) +\
geom_point(mapping=aes(x=&quot;A&quot;, y=&quot;B&quot;, colour=&quot;pred&quot;)) + \
scale_color_manual(values=[colours[0], colours[1], colours[2]]) + theme_classic()
</code></pre><figure><img src="./.ob-jupyter/144ccb9ee25c619a88afebae6bb845a962b06eae.png"/>
</figure>

<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">&lt;ggplot: (317671277)&gt;
</code></pre></div><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">clus0 = prediction.loc[prediction.pred == 0]
clus1 = prediction.loc[prediction.pred == 1]
clus2 = prediction.loc[prediction.pred == 2]
k_list = [clus0.values, clus1.values,clus2.values]
</code></pre><pre tabindex="0"><code class="language-jupyter-python" data-lang="jupyter-python">dunn(k_list)
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">0.019563892388205984
</code></pre></div>
    </div>
  </article>



  
  






  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/map/">All pages</a></li>
         
          <li><a href="/search.html">Search</a></li>
        
      </ul>
    </div>

    
    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#dunn-index">Dunn index</a></li>
  </ul>
</nav>
    </div>
    

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fruivieira.dev%2fdunn-index.html" aria-label="Facebook">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&text=Dunn%20index" aria-label="Twitter">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="Linkedin">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&is_video=false&description=Dunn%20index" aria-label="Pinterest">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Dunn%20index&body=Check out this article: https%3a%2f%2fruivieira.dev%2fdunn-index.html" aria-label="Email">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="Pocket">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&title=Dunn%20index" aria-label="reddit">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fruivieira.dev%2fdunn-index.html&name=Dunn%20index&description=There%20are%20several%20ways%20to%20measure%20the%20robustness%20of%20a%20clustering%20algorithm.%20Three%20commonly%20used%20metrics%20are%20the%20Dunn%20index%2c%20Davis-Bouldin%20index%20and%20Silhoutte%20index.%0aBut%20before%20we%20start%2c%20let%26rsquo%3bs%20introduce%20some%20concepts.%0aWe%20are%20interested%20in%20clustering%20algorithms%20for%20a%20dataset%20%5c%28%5cmathcal%7bD%7d%5c%29%20with%20%5c%28N%5c%29%20elements%20in%20a%20%24n%24-dimensional%20real%20space%2c%20that%20is%3a%0a%5c%5b%20%5cmathcal%7bD%7d%20%3d%20%7bx_1%2c%20x_2%2c%20%5cldots%2c%20x_N%7d%20%5cin%20%5cmathbb%7bR%7d%5ep%20%5c%5d%0aThe%20clustering%20algorithm%20will%20create%20a%20set%20%5c%28C%5c%29%20of%20%5c%28K%5c%29%20distinct%20disjoint%20groups%20from%20%5c%28%5cmathcal%7bD%7d%5c%29%20%5c%28C%3d%7bc_1%2c%20c_2%2c%20%5cldots%2c%20c_k%7d%5c%29%2c%20such%20that%3a" aria-label="Tumblr">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fruivieira.dev%2fdunn-index.html&t=Dunn%20index" aria-label="Hacker News">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu-toggle" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;" aria-label="Menu">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
        <a id="toc-toggle" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;" aria-label="TOC">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share-toggle" class="icon" href="#" onclick="$('#share-footer').toggle();return false;" aria-label="Share">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2021  Rui Vieira 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/map/">All pages</a></li>
         
        <li><a href="/search.html">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/css/fa.min.css>
<script src=/js/jquery-3.6.0.min.js></script>
<script src=/js/main.js></script>



  


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</html>
