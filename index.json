[{"categories":null,"contents":"I\u0026rsquo;ve been using a minimalist blog setup for some time now.\nI was having something of a framework fatigue after switching between a few static site generators. Each new generator I decided to try implied usually either learning a new programming language (Python, Ruby, Go) to perform basic setup and a new template engine syntax1. Typically I wasn\u0026rsquo;t using the vast majority of the features available for each generator. And finally, most of the generators I tried over the years rely on heavy configuration if I want to maintain the site organisation and look.\nI\u0026rsquo;ve discussed with some friends and colleagues why it\u0026rsquo;s my opinion that a plain HTML blog is still superior to other solutions (such as Markdown coupled with some generator framework). I\u0026rsquo;ll leave my arguments to a future post.\nHowever, I am still using some form of a generator. The blog writing process at the moment is the following:\n I write the content of the post to an HTML fragment (no HEAD, for instance). All files are HTML and in the same folder. I have a shell script to walk through the files in the input folder and add a common header, footer and process all code blocks with syntax highlighting. Save the \u0026ldquo;processed\u0026rdquo; files to an output folder Upload (currently to Github to be served via Github pages).  The HTML fragments are minimal, for instance:\n\u0026lt;h1\u0026gt;A post-modern title\u0026lt;/h1\u0026gt;  \u0026lt;p\u0026gt;Yes, this could be an entire blog post.\u0026lt;/p\u0026gt; The point is, where do we draw the line on what a static generator is? For this post, I won\u0026rsquo;t consider a loose collection of specialised scripts to be a static generator. There is no configuration, no convention, no theming abilityÂ 2. You can argue that this is what many generators do, but I think that\u0026rsquo;s beyond the scope of this short post.\nSince my static blog is straightforward, with minimal markup, why not create something equally simple for RSS generation? To do so, I\u0026rsquo;ve decided to go the way of \u0026ldquo;handcrafted\u0026rdquo; HTML.\nHowever, I was accustomed to a static site generator to generate some goodies, such as syndication feeds automatically.\nI\u0026rsquo;ve decided to add an RSS feed to the site, using minimal dependencies (only shell scripting and a couple of universal user-land tools such as grep and cat). This approach has the added benefit that it is applicable to expose other types of data as an RSS feed, such as server and periodic job logs.\nWe start by adding the feed header to the index.xml:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;rss version=\u0026#34;2.0\u0026#34;\u0026gt;  \u0026lt;channel\u0026gt;   \u0026lt;title\u0026gt;Rui Vieira\u0026#39;s blog\u0026lt;/title\u0026gt; \u0026lt;description\u0026gt;Rui Vieira\u0026#39;s personal blog\u0026lt;/description\u0026gt;  \u0026lt;link\u0026gt;https://ruivieira.dev/\u0026lt;/link\u0026gt;  \u0026lt;lastBuildDate\u0026gt;$(date)\u0026lt;/lastBuildDate\u0026gt; EOF The RSS 2.0 specification is quite simple in terms of the minimum requirements for a valid feed. The mandatory \u0026ldquo;header\u0026rdquo; fields are:\n title, the name of the channel. link, the URL to the HTML website corresponding to the channel. description, phrase or sentence describing the channel.  In terms of feed items, according to the specification, at least one of title or description must be present, and all remaining elements are optional.\nWe use the following in this feed:\n title, the title of the item. link, the URL of the item. pubDate indicates when the item was published.  pubDate needs to conform with RFC 822.\n Just as interesting tidbit, RFC 822 (which defines Internet Text Message formats) is one of the core email RFCs. It predates ISO 8601 by six years (1982) and it\u0026rsquo;s itself based on 1977\u0026rsquo;s RFC 733.\n We then loop over all the input files to build the RSS entries.\nFILES=input/*.html for FILE in $FILES do  FILENAME=\u0026#34;${FILE##*/}\u0026#34;  FILENAME=\u0026#34;${FILENAME%.*}\u0026#34;  # extract title ...  # write entry to index.xml done Using Bash First, extract the title. The actual title is not inside the \u0026lt;title\u0026gt; tag, but on the first header \u0026lt;h1\u0026gt;.\ncat output/nb-estimation.html | grep -E \u0026#34;\u0026lt;h1.*\u0026gt;(.*?)\u0026lt;/h1\u0026gt;\u0026#34; | sed \u0026#39;s/.*\u0026lt;h1.*\u0026gt;\\(.*\\)\u0026lt;\\/h1\u0026gt;.*/\\1/\u0026#39; The first produces:\n\u0026lt;div id=\u0026#34;main\u0026#34;\u0026gt;  \u0026lt;h1 id=\u0026#34;negative-binomial-estimation\u0026#34;\u0026gt;Negative Binomial estimation\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; While the second produces:\nNegative Binomial estimations Now, what happens if we have more than one \u0026lt;h1\u0026gt; header? UNIX pipelines to the rescue. We simple retrieve the first line of the matching grep, by inserting a head -1.\nTo get the modified date of $FILE we can use:\ndate -r $FILE.html The final RSS feed build is:\ncat \u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;rss version=\u0026#34;2.0\u0026#34;\u0026gt; \u0026lt;channel\u0026gt; \u0026lt;title\u0026gt;Rui Vieira\u0026#39;s blog\u0026lt;/title\u0026gt; \u0026lt;description\u0026gt;Rui Vieira\u0026#39;s personal blog\u0026lt;/description\u0026gt; \u0026lt;link\u0026gt;https://ruivieira.dev/\u0026lt;/link\u0026gt; \u0026lt;lastBuildDate\u0026gt;$(date)\u0026lt;/lastBuildDate\u0026gt; EOF  FILES=input/*.html for FILE in $FILES do  FILENAME=\u0026#34;${FILE##*/}\u0026#34;  FILENAME=\u0026#34;${FILENAME%.*}\u0026#34;  TITLE=$(cat output/$FILENAME.html | grep -E \u0026#34;\u0026lt;h1.*\u0026gt;(.*?)\u0026lt;/h1\u0026gt;\u0026#34; | head -1 | sed \u0026#39;s/.*\u0026lt;h1.*\u0026gt;\\(.*\\)\u0026lt;\\/h1\u0026gt;.*/\\1/\u0026#39;)  cat \u0026gt;\u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;item\u0026gt; \u0026lt;title\u0026gt;$TITLE\u0026lt;/title\u0026gt; \u0026lt;link\u0026gt;https://ruivieira.dev/$FILENAME.html\u0026lt;/link\u0026gt; \u0026lt;pubDate\u0026gt;$(date -r output/$FILENAME.html)\u0026lt;/pubDate\u0026gt; \u0026lt;/item\u0026gt; EOF done  cat \u0026gt;\u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;/channel\u0026gt; \u0026lt;/rss\u0026gt; EOF Using Python Another possibility is to use a specialised tool to extract an RSS item from an HTML file. To do so, we need to parse the necessary data and replace the extraction part of the loop. This is, after all, along the lines of the Unix philosophy: create specialised tools with a focus on modularity and reusability.\nTo do, we create a simple script called post_title.py. It uses the Beautiful Soup library, which you can install using:\n$ pip install beautifulsoup4 The script reads an HTML file, extract the title and return:\nfrom bs4 import BeautifulSoup import sys  with open(sys.argv[1], \u0026#39;r\u0026#39;) as file:  data = file.read()  soup = BeautifulSoup(data, features=\u0026#34;html.parser\u0026#34;)  print(soup.h1.string) This script can now be used to replace the title extraction:\ncat \u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;rss version=\u0026#34;2.0\u0026#34;\u0026gt; \u0026lt;channel\u0026gt; \u0026lt;title\u0026gt;Rui Vieira\u0026#39;s blog\u0026lt;/title\u0026gt; \u0026lt;description\u0026gt;Rui Vieira\u0026#39;s personal blog\u0026lt;/description\u0026gt; \u0026lt;link\u0026gt;https://ruivieira.dev/\u0026lt;/link\u0026gt; \u0026lt;lastBuildDate\u0026gt;$(date)\u0026lt;/lastBuildDate\u0026gt; EOF  FILES=input/*.html for FILE in $FILES do  FILENAME=\u0026#34;${FILE##*/}\u0026#34;  FILENAME=\u0026#34;${FILENAME%.*}\u0026#34;  cat \u0026gt;\u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;item\u0026gt; \u0026lt;title\u0026gt;$(post_title.py $FILENAME.html)\u0026lt;/title\u0026gt; \u0026lt;link\u0026gt;https://ruivieira.dev/$FILENAME.html\u0026lt;/link\u0026gt; \u0026lt;pubDate\u0026gt;$(date -r output/$FILENAME.html)\u0026lt;/pubDate\u0026gt; \u0026lt;/item\u0026gt; EOF done  cat \u0026gt;\u0026gt;output/index.xml \u0026lt;\u0026lt;EOF \u0026lt;/channel\u0026gt; \u0026lt;/rss\u0026gt; EOF The reason why the whole RSS feed is not generated in Python is to have the title extraction as a \u0026ldquo;function\u0026rdquo; which can map to whichever logic the shell script is using.\nHope this could be useful to you. Happy coding!\n  As it turns out \u0026hellip; I reverted to using a static site generator. More information can be found in the page site details.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Apart from plain CSS theming, that is.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/semi-handcrafted-rss.html","tags":null,"title":"(Semi) handcrafted RSS"},{"categories":null,"contents":"The original page seems to have disappeared from the Internet1 (see: link rot), so the original contents are kept here.\nWhen making this website, I wanted a simple, reasonable way to make it look good on most displays. Not counting any minimization techniques, the following 58 bytes worked well for me:\nmain {  max-width: 38rem;  padding: 2rem;  margin: auto; } Let\u0026rsquo;s break this down.\n  max-width: 38rem It appears that the default font size for most browsers is 16px, so 38rem is 608px. Supporting 600px displays at a minimum seems reasonable.\n  padding: 2rem If the display\u0026rsquo;s width goes under 38rem, then this padding keeps things looking pretty good until around 256px. While this may seem optional, it actually hits two birds with one stone - the padding also provides sorely-needed top and bottom whitespace.\n  margin: auto This is really all that is needed to center the page, because main is a block element under semantic html5.\n  A key insight: it took me a surprising number of iterations to arrive at this point. Perhaps that speaks to the fact that I know nothing about \u0026ldquo;modern\u0026rdquo; web development, or, as i\u0026rsquo;m more inclined to believe, just how hard it is to keep it simple in a world of complication.\nUpdate: following some discussion (see footer), I\u0026rsquo;ve since changed the padding to 1.5rem for a happier compromise between mobile and desktop displays.\nUpdate 2: the ch unit was brought to my attention here, and I quite like it! I\u0026rsquo;ve since changed to 70ch / 2ch, which looks nearly the same with 2 less bytes, except that the padding is a little bit smaller (a good thing for mobile).\n  A cached version can still be seen, hopefully, at http://web.archive.org/web/20210318102514/https://jrl.ninja/etc/1/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/58-bytes-of-css-to-look-great-nearly-everywhere.html","tags":null,"title":"58 bytes of CSS to look great nearly everywhere"},{"categories":null,"contents":"Recently, I\u0026rsquo;ve been following with interest the development of the Crystal language.\nCrystal is a statically type language with a syntax resembling Ruby\u0026rsquo;s. The main features which drawn me to it were its simple boilerplate-free syntax (which is ideal for quick prototyping), tied with the ability to compile directly to native code along with a dead simple way of creating bindings to existing C code.\nThese features make it quite attractive, in my opinion, for scientific computing. To test it against more popular languages, I\u0026rsquo;ve decided to run the Gibbs sampling examples created in Darren Wilkinson\u0026rsquo;s blog.\nI recommend reading this post, and in fact, if you are interested in Mathematics and scientific computing in general, I strongly recommend you follow the blog.\nAs explained in the linked post, I will make a Gibbs sampler for\n\\[ f\\left(x,y\\right)=kx^2\\exp\\left\\lbrace-xy^2-y^2+2y-4x\\right\\rbrace \\]\nwith\n\\begin{aligned} x|y \u0026amp;\\sim Ga\\left(3,y^2+4\\right) \\\\\\\\ y|x \u0026amp;\\sim N\\left(\\frac{1}{1+x},\\frac{1}{2\\left(1+x\\right)}\\right) \\end{aligned}\nThe original examples were ran again, without any code alterations. I\u0026rsquo;ve just added the Crystal version.\nThis implementation uses a very simple wrapper I wrote to the famous GNU Scientific Language (GSL).\nrequire \u0026#34;../libs/gsl/statistics.cr\u0026#34;  require \u0026#34;math\u0026#34;  def gibbs(n : Int = 50000, thin : Int = 1000)  \tx = 0.0 \ty = 0.0  \tputs \u0026#34;Iter x y\u0026#34;  \t(0..n).each do |i| \t(0..thin).each do |j| \tx = Statistics::Gamma.sample(3.0, y\\*y+4.0) \ty = Statistics::Normal.sample(1.0/(x+1.0), 1.0/Math.sqrt(2.0\\*x+2.0)) \tend  \tputs \u0026#34;#{i}#{x}#{y}\u0026#34;  \tend  end  gibbs (As you can see, the Crystal code is quite similar to the Python one).\nTo make sure it\u0026rsquo;s a fair comparison, I ran it in compiled (and optimised) mode build using\n$ crystal build gibbs.cr --release $ time ./gibbs \u0026gt; gibbs_crystal.csv Looking at the results, you can see that they are consistent with the other implementations:\n The timings for each of the different versions (ran in a 1.7 GHz Intel Core i7 Macbook Air) were\n   Language Time (s)     R 364.8   Python 144.0   Scala 9.896   Crystal 5.171   C 5.038    So there you have it. A Ruby-like language which can easily compete with C performance-wise.\nI sincerely hope that Crystal gets some traction in the scientific community.\nThat of course won\u0026rsquo;t depend solely on its merits but rather on an active community along with a strong library ecosystem.\nThis is lacking at the moment, simply because it is relatively new language with the specs and standard library still being finalised.\n","permalink":"https://ruivieira.dev/a-gibbs-sampler-in-crystal.html","tags":null,"title":"A Gibbs Sampler in Crystal"},{"categories":null,"contents":"Recently when discussing the Crystal language and specifically the Gibbs sample blog post with a colleague, he mentioned that the Python benchmark numbers looked a bit off and not consistent with his experience of numerical programming in Python.\nTo recall, the numbers were:\n   Language Time(s)     \u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;-   R 364.8   Python 144.0   Scala 9.896   Crystal 5.171   C 5.038    To have a better understanding of what is happening, I\u0026rsquo;ve decided to profile and benchmark that code (running on Python 3.6).\nThe code is the following:\nimport random, math  def gibbs(N=50000, thin=1000):  \tx = 0 \ty = 0 \tprint(\u0026#34;Iter x y\u0026#34;) \tfor i in range(N): \tfor j in range(thin): \tx = random.gammavariate(3, 1.0 / (y y + 4)) \ty = random.gauss(1.0 / (x + 1), 1.0 / math.sqrt(2 x + 2)) \tprint(i,x,y)    if __name__ == \u0026#34;main\u0026#34;: \tgibbs() Profiling this code with cProfile gives the following results:\n   Name Call count Time (ms) Percentage     \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;-   gammavariate 50000000 141267 52.1%   gauss 50000000 65689 24.2%   `` 116628436 18825 6.9%   `\u0026lt;method \u0026lsquo;random\u0026rsquo; of \u0026lsquo;_random.Random\u0026rsquo; objects\u0026gt;` 170239973 17155 6.3%   `` 125000000 12352 4.6%   `` 60119980 7276 2.7%   `` 25000000 3338 1.2%   `` 25000000 3336 1.2%   `` 50001 1030 0.4%   gibbs.py 1 271396 100.0%    The results look different than the original ones on account of being performed on a different machine. However, we will just look into the relative code performance between different implementations and whether the code itself has room for optimisation.\nSurprisingly, the console I/O took a much smaller proportion of the execution time than I expected (0.4%).\nOn the other hand, as expected, the bulk of the execution time is spent on the gammavariate and gauss methods.\nThese methods, however, are provided by the Python\u0026rsquo;s standard library random, which underneath makes heavy usage of C code (mainly by usage of the random() function).\nFor the second run of the code, I\u0026rsquo;ve decided to use numpy to sample from the Gamma and Normal distributions. The new code, gibbs_np.py, is provided below.\nimport numpy as np import math  def gibbs(N=50000, thin=1000): \tx = 0 \ty = 0 \tprint(\u0026#34;Iter x y\u0026#34;) \tfor i in range(N): \tfor j in range(thin): \tx = np.random.gamma(3, 1.0 / (y y + 4)) \ty = np.random.normal(1.0 / (x + 1), 1.0 / math.sqrt(2 x + 2)) \tprint(i,x,y)  if __name__ == \u0026#34;main\u0026#34;: \tgibbs() We can see from the plots below that the results from both modules are identical.\n The profiling results for the numpy version were:\n   Name Call count Time (ms) Percentage     \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;-   \u0026lt;method 'gamma' of 'mtrand.RandomState' objects\u0026gt; 50000000 121211 45.8%   \u0026lt;method 'normal' of 'mtrand.RandomState' objects\u0026gt; 50000000 83092 31.4%   \u0026lt;built-in method math.sqrt\u0026gt; 50000000 6127 2.3%   \u0026lt;built-in method builtins.print\u0026gt; 50001 920 0.3%   gibbs_np.py 1 264420 100.0%    A few interesting results from this benchmark were the fact that using numpy or random didn\u0026rsquo;t make much difference overall (264.4 and 271.3 seconds, respectively).\nThis is despite the fact that, apparently, the Gamma sampling seems to perform better in numpy but the Normal sampling seems to be faster in the random library.\nYou will notice that we\u0026rsquo;ve still used Python\u0026rsquo;s built-in math.sqrt since it is known that for scalar usage it out-performs numpy\u0026rsquo;s equivalent.\nUnfortunately, in my view, we are just witnessing a fact of life: Python is not the best language for number crunching.\nSince the bulk of the computational time, as we\u0026rsquo;ve seen, is due to the sampling of the Normal and Gamma distributions, it is clear that in our code there is little room for optimisation except the sampling methods themselves.\nA few possible solutions would be to:\n Convert the code to Cython Use FFI to call a highly optimised native library which provides Gamma and Normal distributions (such as GSL)  Nevertheless, personally I still find Python a great language for quick prototyping of algorithms and with an excellent scientific computing libraries ecosystem. Keep on Pythoning.\n","permalink":"https://ruivieira.dev/a-simple-python-benchmark-exercise.html","tags":null,"title":"A simple Python benchmark exercise"},{"categories":null,"contents":"In this blog post I would like to talk a little bit about recommendation engines in general and how to build a streaming recommendation engine on top of Apache Spark.\nI will start by introducing the concept of collaborative filterig, and focus in two variants: batch and streaming Alternating Least Squares (ALS). I will look at the principles of a streaming distributed recommendation engine on Spark and finally, I\u0026rsquo;ll talk about practical issues when using these methods.\nRecommendation engines So what are \u0026ldquo;recommendation engines\u0026rdquo;?\nRecommendation engines are a popular method to match users, products and historical data on user behaviour.\nCollaborative filtering In the majority of cases, we assume there\u0026rsquo;s a unique mapping between a user \\(x\\), a product \\(y\\) and rating \\(\\mathsf{R}_{x,y}\\).\n\\[ \\left(x,y\\right) \\mapsto \\mathsf{R}_{x,y} \\]\nThe \u0026ldquo;collaborative\u0026rdquo; aspect refers to the fact that we are using collective information from a group of users and \u0026ldquo;filtering\u0026rdquo; is simply a synonym for \u0026ldquo;prediction\u0026rdquo;.\nSo, we use collaborative filtering quite frequently in our daily life and it really seems like common sense.\nThe main principle is that if a group of people tend to collectively have similar tastes, it is more likely that they agree on an unknown product.\nLet\u0026rsquo;s imagine that you have a number of friends with whom you share a very similar musical taste, let\u0026rsquo;s call it A and another group, B, compared to which you have very different musical tastes.\nIf group A and group B both recommend you a new album which they regard highly, which one would you pick?\nYou will probably pick the album from group A, right? So that\u0026rsquo;s collaborative filtering in a nutshell.\n Bonus question: what if an album is considered really bad by group B? Does it mean you\u0026rsquo;ll like it?\nIt\u0026rsquo;s difficult to tell. Because group A has relevance to you, it\u0026rsquo;s easy to match.\nBecause B is too dissimilar, a low rating is not very informative.\nAlternating Least Squares (ALS) One of the most popular collaborative filtering methods is Alternating Least Squares (ALS).\nIn ALS we assume that the available rating data can be represented in a sparse matrix form, that is, we will assume a sequential ordering of both users and products. Each entry of the matrix will then represent the rating for a unique pair of user and products.\nIf we then consider ratings data as a matrix, let\u0026rsquo;s call it \\(\\mathsf{R}\\), the user and product ids will represent coordinates in a ratings matrix and the actual rating will be the value for that particular entry. To keep the notation consistent with the above we simply call the entry \\((x,y)\\) as \\(\\mathsf{R}_{x,y}\\). This will look something like the matrix represented in the figure below.\n The idea behind ALS is to factorise the ratings matrix \\(\\mathsf{R}_{x,y}\\) into two matrices \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\), which in turn, when multiplied back, will return an approximation of the original ratings matrix, that is:\n\\[ \\mathsf{R} \\approx \\hat{\\mathsf{R}} = \\mathsf{U}^T \\mathsf{P} \\]\nTo \u0026ldquo;predict\u0026rdquo; a missing rating for a user \\(x\\) and product \\(y\\), we can simply multiply two vectors, namely the \\(x\\) row from the user latent factors and the \\(y\\) column from the product latent factors, \\(\\hat{\\mathsf{R}}_{x,y}\\), that is:\n\\[ \\hat{\\mathsf{R}}_{x,y} = \\mathsf{U}_x^T \\mathsf{P}_y \\]\nThere are several ways to tackle this factorisation problem and we will cover two of them in here. We will first look at a batch method, which aims at factorising using the whole of the ratings matrix and a stochastic gradient descent method, which uses a single observation at a time.\nBatch ALS This factorisation is performed by first defining an (objective) loss function (here called \\(\\ell\\)).\nA general form is represented below where, as before, \\(\\mathsf{R}_{x,y}\\) is the true rating and \\(\\hat{\\mathsf{R}}_{x,y}\\) is the predicted rating, calculated as seen previously. The remaining terms are simply regularisation terms to help prevent overfitting.\n\\[ \\ell = \\sum c_{x,y} \\left(\\mathsf{R}_{x,y} - \\underbrace{\\mathsf{U}_x^T \\mathsf{P}_y}_{\\hat{\\mathsf{R}}_{x,t}}\\right)^2 + \\lambda\\left(\\left\\lVert \\mathsf{U} \\right\\rVert^2 + \\left\\lVert \\mathsf{P} \\right\\rVert^2\\right) \\]\nThe value of \\((c_{x,y})\\) constitutes a penalisation function and will depend on whether we are considering explicit or implicit feedback. If we consider the known ratings as our training dataset \\(\\mathcal{T}\\), then, in the case of explicit feedback we have\n\\[ c_{x,y} = \\begin{cases} 0,\\qquad\\text{if}\\ \\left(x,y\\right) \\notin \\mathcal{T} \\\\\\\\ 1,\\qquad\\text{if}\\ \\left(x,y\\right) \\in \\mathcal{T} \\end{cases} \\]\nConstraining our loss function to only include known ratings. The implicit feedback case is different (and a possible future topic) and for the remainder of this post we will only consider the explicit feedback case. Given the above, we can then simplify our loss function, in the explicit feedback case, to\n\\[ \\ell = \\sum_{x,y \\in \\mathcal{T}} \\left(\\mathsf{R}_{x,y} -\\hat{\\mathsf{R}}_{x,y}\\right)^2 + \\lambda\\left(\\left\\lVert \\mathsf{U} \\right\\rVert^2 + \\left\\lVert \\mathsf{P} \\right\\rVert^2\\right) \\]\nMinimizing \\(\\ell\\) is however an NP-hard problem, due to its non-convexity. However, if we treat \\(\\mathsf{U}\\) as constant, then \\(\\ell\\) is a convex in relation to \\(\\mathsf{P}\\) and if we treat \\(\\mathsf{P}\\) as constant, \\(\\ell\\) is convex in relation to \\(\\mathsf{U}\\). We can then alternate between fixing \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\), changing the values such that the loss function \\(\\ell\\) (above) is minimized. This procedure is then repeated until we reach convergence.\nThe way that ALS works is, in simplified terms, to find the factors \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\), which when multiplied together provide an approximation of our ratings matrix \\(\\mathsf{R}\\), as we\u0026rsquo;ve seen previously.\n Once we have the factors \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\), we can then predict the missing values in \\(\\mathsf{R}\\) by using the approximation \\(\\hat{\\mathsf{R}}\\).\nIt is clear that in a real world scenario we would have many missing ratings, simply due to the assumption that no user rates all products (if they did, the case for a recommendation engine will be significantly weaker). ALS is designed to deal with sparse matrices and to fill the blanks using predicted values. After factorization, our approximated ratings matrix will look something like this:\n As mentioned previously, the first step is then to minimise the loss function. In this case we take the partial derivatives and set them to zero and fortunately this has a closed form solution. We get a system of linear equations which we can easily implement. The system will correspond to the solution of\n\\[ \\frac{\\partial \\ell}{\\partial \\mathsf{U}_x}=0, \\qquad \\frac{\\partial \\ell}{\\partial \\mathsf{P}_y}=0. \\]\nWe start by solving the user latent factor minimisation using:\n\\begin{align} \\frac{1}{2}\\frac{\\partial \\ell}{\\partial \\mathsf{U}_x}\u0026amp;=0 \\\\\\\\ \\frac{1}{2}\\frac{\\partial}{\\partial \\mathsf{U}_x} \\sum_{x,y \\in \\mathcal{T}} \\left(\\mathsf{R}_{x,y} - \\mathsf{U}_x^T \\mathsf{P}_y\\right)^2 + \\lambda\\left(\\left\\lVert \\mathsf{U} \\right\\rVert^2 + \\left\\lVert \\mathsf{P} \\right\\rVert^2\\right)\u0026amp;=0 \\\\\\\\ -\\sum_{x,y \\in \\mathcal{T}} \\left(\\mathsf{R}_{x,y} - \\mathsf{U}_x^T \\mathsf{P}_y\\right)\\mathsf{P}_y^T + \\lambda \\mathsf{U}\\_x^T\u0026amp;=0\\\\\\\\ -\\left(\\mathsf{R}_x -\\mathsf{U}_x^T \\mathsf{P}^T\\right)\\mathsf{P} + \\lambda \\mathsf{U}_x^T\u0026amp;=0\\\\\\\\ \\mathsf{U}_x^T\\left(\\mathsf{P}^T \\mathsf{P} + \\lambda \\boldsymbol{\\mathsf{I}}\\right) \u0026amp;= \\mathsf{R}_x \\mathsf{P} \\\\\\\\ \\mathsf{U}_x^T \u0026amp;= \\mathsf{R}_x \\mathsf{P} \\left(\\mathsf{P}^T \\mathsf{P} + \\lambda \\boldsymbol{\\mathsf{I}}\\right)^{-1}. \\end{align}\nSimilarly, we can solve for the product latent factor by using:\n\\begin{align} \\frac{1}{2}\\frac{\\partial \\ell}{\\partial \\mathsf{P}_y}\u0026amp;=0 \\\\\\\\ -\\sum_{x,y \\in \\mathcal{T}} \\left(\\mathsf{R}\\_{x,y} - \\mathsf{P}\\_y^T \\mathsf{U}_x\\right)\\mathsf{U}_x^T + \\lambda \\mathsf{P}_y^T\u0026amp;=0\\\\\\\\ -\\left(\\mathsf{R}_y - \\mathsf{P}_y^T \\mathsf{U}^T\\right)\\mathsf{U} + \\lambda \\mathsf{P}_y^T\u0026amp;=0\\\\\\\\ \\mathsf{P}_y^T\\left(\\mathsf{U}^T \\mathsf{U} + \\lambda \\boldsymbol{\\mathsf{I}}\\right) \u0026amp;= \\mathsf{R}_y \\mathsf{U} \\\\\\\\ \\mathsf{P}_y^T \u0026amp;= \\mathsf{R}_y \\mathsf{U} \\left(\\mathsf{U}^T \\mathsf{U} + \\lambda \\boldsymbol{\\mathsf{I}}\\right)^{-1}. \\end{align}\nWe can then calculate each factor iteratively, by fixing the other one and solving the estimator. While this process is alternated, an error measure (usually the Root Mean Squared Error), or \\(RMSE\\) is calculated (as below) between the rating matrix approximation given by the latent factors and the ratings which we have, \\(\\mathcal{T}\\). This method is guaranteed to converge and when we consider out approximation to be good enough, or after a set number of iterations we can then stop the refinement.\n\\[ RMSE = \\sqrt{\\frac{1}{n}\\sum_{x,y \\in \\mathcal{T}}\\lvert \\hat{\\mathsf{R}}_{x,y} - \\mathsf{R}_{x,y}\\rvert} \\]\nAfter the latent factors are estimated, we can then use them to try to recreate the original ratings matrix with the approximation as we\u0026rsquo;ve seen. The missing ratings in the original matrix will now be filled by values which minimize the least squares recursion and these are taken as the ratings \u0026ldquo;predictions\u0026rdquo;.\nTo illustrate the working of ALS, let\u0026rsquo;s assume we have a very quirky shop that only ever sells 300 products and has exactly 300 customers. On top of that, users are allowed to use 8 bit number to rate the products. We will also assume in this unusual shop that every user has rated every product.\nNow we\u0026rsquo;re humans, and we visualise patterns in colour more easily than in numbers. We will assign a palette to the ratings, so that each rating corresponds to a colour.\n I think you know where this is going \u0026hellip; we make up this final ratings matrix so now we can visualise the ALS progress.\n So how do we perform this factorisation? The initial step is to fill the latent factors \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\)) with random values. Since at this point, we assume we don\u0026rsquo;t have any ratings, having random factors will lead to an initial random guess of the ratings matrix.\n We then proceed to calculate each factor matrix, as we\u0026rsquo;ve seen, by calculating one using the estimator while keeping the other one constant and then alternating. We can see by the movie below that at each iteration the approximation to the original ratings gets better, stabilising after a few steps.\nThis is to be expected, in this case, since this would be the simplest implementation of ALS: a batch ALS on a single machine where we know all the ratings.\nYour browser does not support the video tag.  So a fair question that arises is: why can\u0026rsquo;t we update this model and perform recommendations in a streaming fashion using this method?\nAfter all, if users add product ratings, we can simply update the predictions by recalculating the factors!\nThe problem is that when a new rating is added, or when new users and new products are added, we need to recalculate the entirety of the \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\) matrices, and to do so, we need to have access to all of the data, \\(\\mathsf{R}\\).\nStreaming ALS Ideally, we want a method that would allow us to update \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\) using one observation, \\(\\mathsf{R}_{x,y}\\) at a time\nIt turns out that the Stochastic Gradient Descent (or SGD)1 method allows us to do precisely that. We\u0026rsquo;ll look at the specific variant of SGD we\u0026rsquo;ve used which is called Bias-Stochastic Gradient Descent (B-SGD).\nIt is important to keep in mind, under a certain point of view, both methods aim at the same thing.\n They both try to factorise the ratings matrix as latent factors, which would then be used to perform predictions. The main differences are of course, how the data is used (batch or one observation at the time) and how the factorisation is calculated.\nIn the SGD case we use the concept of biases in both users and items. The bias is a measure of how consistently a product is rated by different users. The bias of rating \\((x,y)\\), that is the rating given by user \\(x\\) to product \\(y\\), can be calculated as the sum of \\(\\mu\\), an overall average rating and the observed deviations of user \\(x\\), which we call \\(b_x\\), and the observed deviations of product \\(y\\), called \\(b_y\\), that is:\n\\[ b_{x,y} = \\mu + b_x + b_y \\]\nThis bias information is now incorporated in the rating prediction. We can see that the SGD prediction is simply the batch prediction plus the corresponding bias term\n\\[ \\hat{\\mathsf{R}}_{x,y} = b_{x,y} + \\underbrace{\\mathsf{U}^T_x \\cdot \\mathsf{P}_y}_{batch} \\]\nIf we take the loss function definition for the batch method (and still considering the explicit feedback case), we can then replace the predicted rating formulation with our new one. We have, as before, some regularisation terms, but now also include a new regularisation term for the bias components,\nbut we don\u0026rsquo;t need to go into that.\n\\[ \\ell_{SGD} = \\sum_{x,y \\in \\mathcal{T}} \\left(\\mathsf{R}_{x,y} - b_{x,y} - \\hat{\\mathsf{R}}_{x,y}\\right)^2 + \\lambda\\left(\\left\\lVert \\mathsf{U} \\right\\rVert^2 + \\left\\lVert \\mathsf{P} \\right\\rVert^2 + b_x^2 + b_y^2\\right) \\]\nSince calculating the full gradient is computationally very expensive, we calculate it for a single observation. As we can see, the SGD method allows us to update the user and product specific bias as well as a single user and product latent factor row given a single rating.\nProvided we have a single rating, the rating of user \\(x\\) for product \\(y\\), we can update the biases as well as the latent vectors for user \\(x\\) and for product \\(y\\), that is, we no longer need to update the entire matrices \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\), while still maintaining a convergence property.\nProvided with a learning rate \\(\\gamma\\) and defining our prediction error as\n\\[ \\epsilon_{x,y}=\\mathsf{R}_{x,y}-\\hat{\\mathsf{R}}_{x,y}, \\]\nthe biases and latent factors can now be updated in the opposite direction of the calculated gradient, proportionally to the learning rate, such that\n\\begin{aligned} b_x \u0026amp;\\leftarrow b_x + \\gamma \\left(\\epsilon_{x,y}-\\lambda_x b_x\\right) \\\\\\\\ b_y \u0026amp;\\leftarrow b_y + \\gamma \\left(\\epsilon_{x,y}-\\lambda_y b_y\\right) \\\\\\\\ \\mathsf{U}_x \u0026amp;\\leftarrow \\mathsf{U}_x + \\gamma \\left(\\epsilon_{x,y}\\mathsf{P}_y - \\lambda^\\prime_x \\mathsf{U}_x\\right) \\\\\\\\ \\mathsf{P}_y \u0026amp;\\leftarrow \\mathsf{P}_y + \\gamma \\left(\\epsilon_{x,y}\\mathsf{U}_x - \\lambda^\\prime_y \\mathsf{P}_y\\right) \\end{aligned}\nSo the practical difference, in terms of streaming data is evident now. Given that, in both methods, the objective is to estimate the latent factors, given the ratings: with batch ALS, whenever we get a new rating, we need to fully recalculate the factors iteratively until we reach convergence. Conversely, with an SGD based factorisation, whenever we have a new rating, we can simply estimate the relevant row and column in the latent factors, by calculating the gradients and adjusting its values.\n Next we show the previous manufactured ratings matrix being factorised using B-SGD. We now simply recalculate the biases and a single latent factor vector, one observation at the time. We can see that, as expected, the convergence is slower (we are using a single observation at each step) but in the end, it produces a similar result.\nYour browser does not support the video tag.  Now, this works fine for a single machine implementing streaming ALS. But we are interested in scaling this to something larger than this example so we will use a distributed implementation of ALS. And this is were it can start to get tricky. As it is the case with distributed algorithms, there are some pitfalls which we need to avoid in order to have a performant implementation. We will look at a few of these by looking at the Apache Spark\u0026rsquo;s and its default ALS implementation.\nApache Spark As probably most of you are familiar with, Spark is an Apache community project which aims at providing a modern platform for distributed computations. Spark provides several core data structures, such as RDDs (Resilient Distributed Datasets), Dataframes and Datasets.\nThe RDD is an immutable, distributed typed collection of objects. The RDD is partitioned across the cluster. This allows the spark operations, such as function mapping, to be applied to each subset of the RDD in parallel at each partition.\n For the streaming ALS application we will use RDDs to implement the algorithm. Spark\u0026rsquo;s MLlib provides a collaborative filtering implementation based on the distributed batch ALS which we\u0026rsquo;ve covered previously. The API is quite simple and to train a model we need:\nval model = ALS.train(ratings, rank, iterations, lambda)  case class Rating(int user, int product, double rating)  val ratings: RDD[Rating] val rank: int val iterations: int val lambda: Double  An RDD containing the ratings. The RDD has elements of the class Rating, which is basically a wrapper around a tuple of user id, product id and rating. This RDD corresponds to all the entries in our ratings matrix used previously. The rank which corresponds to the number of elements in our latent factor vectors (this would be the number of columns or rows in our \\(\\mathsf{U}\\) and \\(\\mathsf{P}\\) matrices). A stopping criteria in terms of iterations for the ALS. And finally, we set the lambda parameter, a regularisation parameter, which we\u0026rsquo;ve shown to be a part of the loss function\u0026rsquo;s regularisation.  Since we have the data, the question is then how to choose the parameters. A typical method is to split the original ratings data into two random sets, one for training and one for validation. We then proceed to train the model to several different parameters, usually according to a grid search, and calculate some error measure between the predicted and validation ratings, choosing the parameters which minimise the error.\nOnce the model is trained, we get a MatrixFactorizationModel instance, which is basically a wrapper for the latent factors as RDDs.\nval model = ALS.train(ratings, rank, iterations, lambda)  model: MatrixFactorizationModel  class MatrixFactorizationModel {  \tval userFeatures: RDD[(Int, Array[Double])] \tval productFeatures: RDD[(Int, Array[Double])]  } One we have the trained model, we can now perform predictions.\nStreaming data We now want to build a streaming recommender system. For this scenario, we will assume that the observations take the form of a Spark\u0026rsquo;s Discretised Stream or DStream. With DStreams we consume the stream as mini-batches of RDDs over a certain interval window.\n We can for instance, use the first mini-batch to initialise the model and the following batches to continuously train the model.\nOne immediate advantage of using observations as a stream is that we no longer need to keep the entirety of the data in memory or read it from storage. If we consider the batch implementation with a very large dataset if we had a single new observation and wanted to retrain the model, we would have to, for instance, read several million ratings from a database. With a streaming variant we can use that single observation to update the latent factors.\nWe will try to recreate Spark\u0026rsquo;s batch ALS API by allowing model training using a ratings `RDD`, however this time, we consume each `RDD` from the stream mini-batch and will incrementally train the model as observations trickle in.\n First, we start by establishing the quantities and data structures needed to implement streaming ALS.\nWe\u0026rsquo;ve seen in the previous slides that the recursions for the gradient calculation take the following form, here presented in pseudo-code:\nuserBias += gamma * (error - lambda \\* userBias)  userFeature(i) += gamma * (error prodFeature(j) - lambda * userFeature(i)) We create a Factor class to encapsulate the features and the corresponding bias.\nWe recall that in the Spark ALS implementation, the features were stored in RDDs typed as a tuple of (id, Array), where now we have an equivalent form of (id, Factor) which allows us to capture the bias. I\u0026rsquo;ll now provide a quick overview of the steps required to go from the initial ratings stream to the trained model, in terms of Spark\u0026rsquo;s RDD operations.\nSimilarly to Spark\u0026rsquo;s ALS, we can assume that the model data will be in the form of Rating\u0026rsquo;s RDDs. These, as we\u0026rsquo;ve seen, will correspond to a mini-batch of ratings from our data stream. We first need to create the initial user and product latent factors for the observed data and we would start by creating two separate RDDs from the data, one keyed by user id, the other by product id.\n For each entry of those new RDDs (the user and product indexed ones) we will now generate a random vector of features. This can be done by simply filling a vector of size rank with random uniform values, but as you will recall, we now also have a bias associated with each entry, which will initially also be set to a random value.\n We now join the incoming ratings, with the generated user factors (using the user id as the key) getting a resulting RDD consisting of product ids, user ids, ratings and user factors (and the same thing for products and product factors).\n Finally, we have these two joint RDDs which have all the necessary quantities needed to calculate the partial gradient in each element. Recalling how to calculate a predicted rating in streaming ALS, we need the global bias, the user and product bias and the corresponding user and product latent vectors.\nThis is straightforward to calculate for each element as we can see from the pseudo-code.\nHere the dot function is simply a function to calculate the dot product treating the two factor arrays as vectors.\n\\[ \\hat{\\mathsf{R}}_{x,y}=\\mu + b_x + b_y + \\mathsf{U}_x^T \\cdot \\mathsf{P}_y \\]\nprediction = dot(userFactors.features, itemFactors.features) + userFactors.bias + itemFactors.bias + bias Given the prediction, the error is also straightforward to calculate, since the real rating is also included in this `RDD`.\n\\[ \\epsilon_{x,y} = \\mathsf{R}_{x,y} - \\hat{\\mathsf{R}}_{x,y} \\]\neps = rating - prediction And now, since we have the error, we can also easily calculate the update term for the user and product features. As mentioned previously, gamma and lambda are known model parameters which we pick ourselves when instantiating the streaming ALS algorithm.\n\\[ \\gamma \\left(\\epsilon_{x,y}\\mathsf{U}_x-\\lambda^{\\prime}\\mathsf{P}_y\\right) \\]\n(0 until rank).map { i =\u0026gt; \tgamma * (eps * userFactors.features(i) - lambda * itemFactors.features(i)) } Finally, we update the user and product biases given the model parameters and the previous bias.\n\\[ \\gamma \\left(\\epsilon_{x,y}-\\lambda_y b_y\\right) \\]\ngamma * (eps - lambda * itemFactors.bias) These calculated gradients can now be mapped to a new RDD which we will use to update the final biases and latent factors.\nThe last step is to split the gradients according to user and product, and finally, when in possession of all the individual gradients, we reduce them into latent factors by performing an aggregated sum for each user and product.\nSo these steps define the entirety of the streaming ALS operation. For each observation window, we calculate the latent factors RDD, and on the following window we update these factors, given the current observations.\nWe\u0026rsquo;ve covered the initialisation case, that is, we assumed the case where the model is not initialised and we received the first mini-batch of ratings. If, on the following window, we receive ratings for previously unseen user or products, the procedure is exactly the same, that is, we generate random factors and update as described.\n Now I\u0026rsquo;ll just quickly cover the case where we get some ratings from users or for some product we\u0026rsquo;ve already seen. For this new set of observations, we proceed exactly as previously, that is, we split the data into separate `RDD`s, each one containing the ratings but keyed by user and product id. I\u0026rsquo;ll assume that we get a mixture of completely new data, that is, unseen user and products and some ratings for previously seen users and products shown in red.\n The difference now is that, instead of assigning random factors and biases to each entry of these RDDs, we perform a full outer join between them and the current latent factors.\nThe strategy is then to keep the matching existing latent factor and create random features and biases just for the user and product entries we haven\u0026rsquo;t seen before.\nNow that we are in possession of this joint RDD, we can apply exactly the same steps as previously to update the factors and repeat these steps for all future incoming observations, allowing us to continuously update the model.\nIt is now easy to see that, in the limit situation where we only have one new rating, we would now only have to update a single entry of the latent factors RDD, in contrast with the batch method, where the entirety of the factors would be used in the ALS step.\n Let\u0026rsquo;s look at some results comparing the streaming implementation with the Spark\u0026rsquo;s batch implementation.\nThe dataset we have chosen to use in these tests is one of the MovieLens\u0026rsquo; datasets. These dataset are a widely used data in recommendation engine research. They are managed by the Lens corporation and are freely available for non-commercial applications.\nThese datasets come in several variants, namely a small variant, useful for a quick algorithm prototyping and testing, and a full variant, with approximately 26 million ratings (from 45,000 movies and 270,000 users), useful for a more comprehensive testing and benchmark.\nThe data is available as a set of Comma Separated Value files, each containing different variables, but we are mainly interested in the ratings file which contains four variables: a unique user and movie id, represented as integers, a rating represented by a value from 0 to 5 with steps of 0.5 and a timestamp for when the movie was rated by this user.\nFirst, we\u0026rsquo;ll start by training a batch ALS model using the MovieLens data. We assume that we already have the observations as an RDD of ratings and simply split the data into 80% for training and 20% for validation.\nval split: Array[RDD[Rating]] = ratings.randomSplit(0.8, 0.2)  val model = ALS.train(split(0), rank, iter, lambda) Here, we won\u0026rsquo;t show the steps to determine the best parameters for this dataset, were we performed a simple parameter grid search over a number of possible candidates. The Spark ALS API is quite simple and to train the model we simply pass the training RDD and the parameters.\nWe can now use the remaining 20% of the observations to calculate the RMSE between the model predictions and the actual ratings.\nWe now can persist the validation RDD, so we can use the exact same one for the streaming ALS run.\nval predictions: RDD[Rating] = model \t.predict(split(1).map { \tx =\u0026gt;(x.user, x.product)) \t}  val pairs = predictions \t.map(x =\u0026gt; ((x.user, x.product), x.rating)) \t.join( \tsplit(1) \t.map(x =\u0026gt; ((x.user, x.product), x.rating)) \t.values  val RMSE = math.sqrt( \tpairs.map(x =\u0026gt; math.pow(x._1 - x._2, 2)).mean()) In order to test the streaming version, we first need to define a data source. We start with the original MovieLens data and remove all the ratings from the validation observations.\nWe then create a simulated stream of observations using Kafka, with an interval of 5 seconds and with 1000 observations in each mini-batch. These are arbitrary numbers, chosen just for practical reasons. We could have, for instance, a single observation in each mini-batch.\nIt is not guaranteed that the best parameters (namely rank and lambda) chosen for the batch version are the best for the streaming implementation, however we\u0026rsquo;ve decided to use the same ones. For each mini-batch we then incrementally train the model and calculate the RMSE up to that point. Given the actual ratings in the validation set and the model\u0026rsquo;s prediction, the RMSE calculation is the same as in the batch version. And looking at the results, we can see that with each mini-batch (of 1000 observations), the RMSE from the streaming version (in blue) is edging towards the batch value (plotted as the horizontal dashed line).\n Caveats However, streaming ALS has pitfalls which we have to take into account.\nCold start An issue, which is shared with batch ALS, is usually called the cold start problem. This refers to initial point in a recommender engine where we have too few observations to make meaningful predictions. As we now know, when having a small number of ratings, since our latent factors are initialised to random numbers, most of our predicted ratings will also be random.\nAlthough this is not an exclusive problem to the streaming implementation, we might be tempted, since the system is suited for realtime recommendations, to immediately start serving predictions. It might be wise to exercise caution and train the model offline with a larger dataset or at least perform some model diagnostics to check how sensible our predictions are.\nHyperparameter estimation Another challenge we encounter is hyperparameter estimation.\nIn the batch ALS case, we can perform a grid search for instance and estimate the hyperparameters. If, after some time, we find ourselves with a new ratings or even new product and users, we can simply repeat this procedure using the totality of the data. As an example, if in batch ALS at any point we wish to estimate the model with a different rank, this would be perfectly acceptable.\n In the streaming case, we can\u0026rsquo;t do that. When we have a new batch of observations, we assume that previous ones were discarded since they are already incorporated in the latent factors. If they weren\u0026rsquo;t and we keep all the observations in the stream, we might as well use batch ALS.\n A solution is to perform a grid search in parallel from the start and prune the least performant models as time progresses. This has the disadvantage of being expensive in terms of resources, since we have to keep several models simultaneously and again, we have the cold start problem surfacing.\nThis means that we have no guarantee that the best parameters for a initial batch with few observations will still be the best further on.\n Performance Also, there are some performance considerations. As we\u0026rsquo;ve seen, we implement some operations which can be costly in a Spark setting. We have several join operations which can lead to a considerable amount of data shuffling between partitions.\nCare must be taken into choosing an appropriate partitioning strategy to minimise data shuffling.\nSpark\u0026rsquo;s implementation of batch ALS uses a specific method called blocked ALS, which computes outgoing and ingoing links between user and products vectors and then partitioning them in blocks in order to minimise data transfer between nodes.\n Also, to make predictions we might have to try and perform random access to the latent factors RDDs. This also can be quite inefficient since we are using lookup methods.\nIf you want to get straight setting up your own distributed recommendation engine, I highly suggest you start with Spark\u0026rsquo;s builtin solution. I would highly recommended looking at the jiminy project (part of the radanalytics.io community), a micro-service oriented complete recommendation engine, ready to deploy on OpenShift.\nThe engine is split into services such as a predictor and a modeler, along with a front-end and tools to simplify tasks (such as using the MovieLens data) and it\u0026rsquo;s a great way to look at how to put a modern recommender engine together and also a great code read.\n   Vinagre, J., Jorge, A. M., \u0026amp; Gama, J. (2014). Fast incremental matrix factorization for recommendation with positive-only feedback. In , International Conference on User Modeling, Adaptation, and Personalization (pp. 459â470).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/a-streaming-als-implementation.html","tags":null,"title":"A streaming ALS implementation"},{"categories":null,"contents":"Environments Create To create a new environment foo use\n$ conda create --name foo And to activate it use\n$ conda activate foo ","permalink":"https://ruivieira.dev/anaconda.html","tags":null,"title":"Anaconda"},{"categories":null,"contents":"Ansible notes.\nInstallation Debian/Ubuntu $ sudo apt update $ sudo apt install software-properties-common $ sudo add-apt-repository --yes --update ppa:ansible/ansible $ sudo apt install ansible Reference ","permalink":"https://ruivieira.dev/ansible.html","tags":null,"title":"Ansible"},{"categories":null,"contents":"A common introductory problem in Bayesian changepoint detection is the record of UK coal mining disasters from 1851 to 1962. More information can be found in Carlin, Gelfand and Smith (1992).\nAs we can see from the plot below, the number of yearly disasters ranges from 0 to 6 and we will assume that at some point within this time range a change in the accident rate has occured.\n The number of yearly disasters can be modelled as a Poisson with a unknown rate depending on the changepoint \\(k\\):\n\\[ y_t \\sim \\text{Po}\\left(\\rho\\right),\\qquad \\rho = \\begin{cases} \\mu, \u0026amp; \\text{if}\\ t=1,2,\\dots,k \\\\\\\\ \\lambda, \u0026amp; \\text{if}\\ t = k +1, k + 2, \\dots,m \\end{cases} \\]\nOur objective is to estimate in which year the change occurs (the changepoint \\(k\\)) and the accident rate before (\\(\\mu\\)) and after (\\(\\lambda\\)) the changepoint amounting to the parameter set \\(\\Phi = \\left\\lbrace\\mu,\\lambda,k\\right\\rbrace\\).\nWe will use Crystal (with crystal-gsl) to perform the estimation.\nWe start by placing independent priors on the parameters:\n \\(k \\sim \\mathcal{U}\\left(0, m\\right)\\) \\(\\mu \\sim \\mathcal{G}\\left(a_1, b_1\\right)\\) \\(\\lambda \\sim \\mathcal{G}\\left(a_2, b_2\\right)\\)  For the remainder we\u0026rsquo;ll set \\(a_1=a_2=0.5\\), \\(c_1=c_2=0\\) and \\(d_1=d_2=1\\).\nThe joint posterior of \\(\\Phi\\) is then:\n\\[ \\pi\\left(\\Phi|Y\\right) \\propto p\\left(Y|\\Phi\\right) \\pi\\left(k\\right) \\pi\\left(\\mu\\right) \\pi\\left(\\lambda\\right), \\]\nwhere the likelihood is\n\\begin{aligned} p\\left(Y|\\Phi\\right) \u0026amp;= \\prod_{i=1}^{k} p\\left(y_i|\\mu,k\\right) \\prod_{i=k+1}^{m} p\\left(y_i|\\lambda,k\\right) \\\\\\\\ \u0026amp;= \\prod_{i=1}^{k} \\frac{\\mu^{y_i}e^{-\\mu}}{y_i!} \\prod_{i=k+1}^{m} \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!}. \\end{aligned}\nAs such, the full joint posterior can be written as:\n\\begin{aligned} \\pi\\left(\\Phi|Y\\right) \u0026amp;\\propto \\prod_{i=1}^{k} \\frac{\\mu^{y_i}e^{-\\mu}}{y_i!} \\prod_{i=k+1}^{m} \\frac{\\lambda^{y_i}e^{-\\lambda}}{y_i!} \\left(\\mu^{a_1-1} e^{-\\mu b_1}\\right) \\left(\\lambda^{a_2-1} e^{-\\lambda b_2}\\right) \\frac{1}{m} \\\\\\\\ \u0026amp;= \\mu^{a_1 + \\sum_{1}^{k}y_i - 1}e^{-\\mu\\left(k+b\\_1\\right)} \\lambda^{a_2 + \\sum_{k+1}^{m}y_i - 1}e^{-\\lambda\\left(m-k+b_2\\right)} \\end{aligned}.\nIt follows that the full conditionals are, for $\\mu$:\n\\begin{aligned} \\pi\\left(\\mu|\\lambda,k,Y\\right) \u0026amp;\\propto \\mu^{a_1 + \\sum_{i=1}^{k}y_i-1}e^{-\\mu\\left(k+b_1\\right)} \\\\\\\\ \u0026amp;= \\mathcal{G}\\left(a_1+\\sum_{i=1}^{k}y_i, k + b_1\\right) \\end{aligned}\nWe can define the \\(\\mu\\) update as:\ndef mu_update(data : Array(Int), k : Int, b1 : Float64) : Float64  \tGamma.sample(0.5 + data[0..k].sum, k + b1)  end The full conditional for \\(\\lambda\\) is:\n\\begin{aligned} \\pi\\left(\\lambda|\\mu,k,Y\\right) \u0026amp;\\propto \\lambda^{a_2 + \\sum_{i=k+1}^{m}y_i-1}e^{-\\lambda\\left(m-k+b_2\\right)} \\\\\\\\ \u0026amp;= \\mathcal{G}\\left(a_2+\\sum_{i=k+1}^{m}y_i, m - k + b_2\\right), \\end{aligned}\nwhich we implement as:\ndef lambda_update(data : Array(Int), k : Int, b2 : Float64) : Float64  \tGamma.sample(0.5 + data[(k+1)..M].sum, M - k + b2)  end The next step is to take\n\\begin{aligned} b_1 \u0026amp;\\sim \\mathcal{G}\\left(a_1 + c_1,\\mu + d_1\\right) \\\\\\\\ b_2 \u0026amp;\\sim \\mathcal{G}\\left(a_2 + c_2,\\lambda + d_2\\right), \\end{aligned}\nwhich we will implement as:\ndef b1_update(mu : Float64) : Float64  \tGamma.sample(0.5, mu + 1.0)  end  def b2_update(lambda : Float64) : Float64  \tGamma.sample(0.5, lambda + 1.0)  end And finally we choose the next year, \\(k\\), according to\n\\[ p\\left(k|Y,\\Phi\\right)=\\frac{L\\left(Y|\\Phi\\right)}{\\sum_{k^{\\prime}} L\\left(Y|\\Phi^{\\prime}\\right)} \\]\nwhere\n\\[ L\\left(Y|\\Phi\\right) = e^{\\left(\\lambda-\\mu\\right)k}\\left(\\frac{\\mu}{\\lambda}\\right)^{\\sum_i^k y_i} \\]\nimplemented as\ndef l(data : Array(Int), k : Int, lambda : Float64, mu : Float64) : Float64  \tMath::E**((lambda - mu)*k) * (mu / lambda)**(data[0..k].sum)  end So, let\u0026rsquo;s start by writing our initials conditions:\niterations = 100000  b1 = 1.0 b2 = 1.0  M = data.size # number of data points  # parameter storage  mus = Array(Float64).new(iterations, 0.0)  lambdas = Array(Float64).new(iterations, 0.0)  ks = Array(Int32).new(iterations, 0) We can then cast the priors:\nmus[0] = Gamma.sample(0.5, b1)  lambdas[0] = Gamma.sample(0.5, b2)  ks[0] = Random.new.rand(M) And define the main body of our Gibbs sampler:\n(1...iterations).map { |i|  \tk = ks[i-1]  \tmus[i] = mu_update(data, k, b1)  \tlambdas[i] = lambda_update(data, k, b2)  \tb1 = b1_update(mus[i])  \tb2 = b2_update(lambdas[i])  \tks[i] = Multinomial.sample((0...M).map { |kk|  \tl(data, kk, lambdas[i], mus[i])  \t})  } Looking at the results, we see that the mean value of \\(k\\) is 38.761, which seems\nto indicate that the change in accident rates occurred somewhere near \\(1850+38.761\\approx 1889\\).\nWe can visually check this by looking at the graph below. Also plotted are the density for the accident rates before (\\(\\mu\\)) and after (\\(\\lambda\\)) the change.\n  Of course, one the main advantages of implementing the solution in Crystal is not only the boilerplate-free code, but the execution speed.\nCompared to an equivalent implementation in R the Crystal code executed roughly 17 times faster.\n   Language Time (s)     R 58.678   Crystal 3.587    ","permalink":"https://ruivieira.dev/bayesian-estimation-of-changepoints.html","tags":null,"title":"Bayesian estimation of changepoints"},{"categories":null,"contents":"ArXivist  A bot which periodically toots a paper published on ArXiV. The main Mastodon page of the bot can be found at https://botsin.space/@arxivstats. The current queue can be found at https://w6118k.deta.dev/\n","permalink":"https://ruivieira.dev/bots.html","tags":null,"title":"Bots"},{"categories":null,"contents":"The major guidelines of the Brutalist web designÂ 1 are:\nContent is readable on all reasonable screens and devices ð This guideline is followed by this site. The vast majority of the pages work with all major browsers, implement a responsive design. They also work with Javascript disabled as described in site details. It even works with unreasonable browsers, screens and devices, such as Internet Explorer 6 (2001) and NCA Mosaic 2 (1993).\n Only hyperlinks and buttons respond to clicks. ð This guideline is followed by this site. Buttons and hyperlinks (textual and TOC links) are the only way to navigate content (except for standard browser navigation, i.e. back button)\nHyperlinks are underlined and buttons look like buttons. ð¬ Not really followed. Hyperlinks are highlighted, rather than underlined. Buttons look like buttons, though.\nThe back button works as expected. ð This guideline is followed by this site. This site does not implement routers, history hijacking, etc. Hyperlinks and browser navigation are the only way to get around.\nView content by scrolling. ð Vertical scrolling, specifically.\nDecoration when needed and no unrelated content. ð This guideline is followed by this site. Decoration is judicious and mostly through colour. No splash images too.\nPerformance is a feature. ð Performance is an important concern.\n An area of work is image optimisation, since this the heaviest part of the site Javascript is minimal and the goal is to decrease dependence on it, not increase.    https://brutalist-web.design/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/brutalist-web-design.html","tags":null,"title":"Brutalist web design"},{"categories":null,"contents":"Notes on Clojure.\nReference Concatenating strings (require \u0026#39;[clojure.string :as string])  (string/join [\u0026#34;foo\u0026#34; \u0026#34;bar\u0026#34;]) List files recursively To list files recursively in Clojure1\n(file-seq \u0026#34;/etc\u0026#34;) Filter by extension (filter #(.endsWith (.toString %) \u0026#34;.conf\u0026#34;) \t(file-seq \u0026#34;/etc\u0026#34;))) Get home directory def home (System/getProperty \u0026#34;user.home\u0026#34;))   Compare with the Java version.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/clojure.html","tags":null,"title":"Clojure"},{"categories":null,"contents":"To prototype and test almost any application some type of input data is needed. Getting the right data can be difficult for several reasons, including strict licenses, a considerable amount of data engineering to shape the data to our requirements and the setup of dedicated data producers. Additionally, in modern applications, we are often interested in realtime/streaming and distributed processing of data with platforms such as Apache Kafka and Apache Spark and deployment in a cloud environment like OpenShift with tools such as oshinko.\nSimulating data is not trivial, since we might want to capture complex characteristic to evaluate our algorithms in conditions similar to the real world. In this post I\u0026rsquo;ll introduce a tool, timeseries-mock, which allows for a simple, containerised deployment of a data simulator along with some of the theory behind the data generation.\nState-space models A common way of modelling these patterns is to use state-space models (SSM). SSMs can be divided into a model and a observation structure.\n\\[ Y_t|\\theta_t,\\Phi \\sim f\\left(y_t|\\theta_t,\\Phi_t\\right) \\\\ \\theta_t|\\theta_{t-1},\\Phi_t \\sim g\\left(\\theta_t|\\theta_{t-1},\\Phi_t\\right). \\]\n It is clear from the above that the state possesses a Markovian nature. The state at time \\(t\\), \\(\\theta_t\\) will on depend on the previous value, \\(\\theta_{t-1}\\) and an observation at time \\(t\\), \\(y_t\\) will only depend on the current state, \\(\\theta_t\\), that is:\n\\[ p\\left(\\theta_{t}|\\theta_{0:t-1},y_{0:t-1}\\right)=p\\left(\\theta_{t}|\\theta_{t-1}\\right) \\\\ p\\left(\\theta_{t-1}|\\theta_{t:T},y_{t:T}\\right)=p\\left(\\theta_{t-1}|\\theta_{t}\\right) \\\\ p\\left(y_{t}|\\theta_{0:t},y_{0:t-1}\\right)=p\\left(y_{t}|\\theta_{t}\\right). \\]\nIn this post we will focus on a specific instance of SSMs, namely Dynamic Generalised Linear Models (DGLMs). If you want a deeper theoretical analysis of DGLMs I strongly recommend Mike West and Jeff Harrison\u0026rsquo;s \u0026ldquo;Bayesian Forecasting and Dynamic Models\u0026rdquo; (1997). In DGLMs, the observation follows a distribution from the exponential family, \\(E\\left(\\cdot\\right)\\) such, that\n\\[ Y_t|\\theta_t,\\Phi \\sim E\\left(\\eta_t,\\Phi\\right) \\\\ \\eta_t|\\theta_t = L\\left(\\mathsf{F}^T \\theta_t\\right) \\]\nwhere \\(L\\left(\\cdot\\right)\\) is the linear predictor and the state evolves according to a multivariate normal (MVN) distribution:\n\\[ \\theta_t \\sim \\mathcal{N}\\left(\\theta_t;\\mathsf{G}\\theta_{t-1},\\mathsf{W}\\right) \\]\nStructure The fundamental way in which timeseries-mock works is by specifying the underlying structure and observational model in a YAML configuration file. In the following sections we will look at the options available in terms of structural and observational components and look at how to represent them. As we\u0026rsquo;ve seen from (5), the structure will allows us to define the underlying patterns of the state evolution \\(\\lbrace \\theta_1, \\theta_2, \\cdots, \\theta_t\\rbrace\\). One of the advantages of DGLMs is the ability to compose several simpler components into a single complex structure. We will then look at some of these \u0026ldquo;fundamental\u0026rdquo; components.\nMean An underlying mean component will represent a random walk scalar state which can be specified in the configuration file by\nstructure:- type:meanstart:0.0noise:1.5In this case start will correspond the mean of the state prior, \\(m_0\\), and noise will correspond to the prior\u0026rsquo;s variance, \\(\\tau^2\\), that is\n\\[ \\theta_0 \\sim \\mathcal{N}\\left(m_0, \\tau^2\\right). \\]\nIn the figure below we can see the above configuration for, respectively, a higher and lower value of noise.\n Seasonality Seasonality is represented by Fourier components. A Fourier component can be completely specified by providing the period, start, noise and harmonics. The start and noise parameters are analogous to the mean components we saw previously. The period parameter refers to how long does it take for the cyclical pattern to repeat. This is done relatively to your time-point interval, such that\n\\[ P = p_{\\text{fourier}}\\cdot p_{\\text{stream}}. \\]\nThat is, if your stream\u0026rsquo;s rate is one observation every 100 milliseconds, \\(p_{\\text{stream}}=0.1\\), and the harmonic\u0026rsquo;s period is 2000, \\(p_{\\text{fourier}}=1000\\), then the seasonal component will repeat every \\(200\\) seconds. The configuration example\nstructure:- type:seasonperiod:200harmonics:5start:0.0noise:0.7will create a sequence of state vectors \\(\\boldsymbol{\\theta}_{0:T}\\) with five components, such that:\n\\[ \\boldsymbol{\\theta}_t = \\lbrace\\theta_{1,t},\\cdots,\\theta_{5,t}\\rbrace. \\]\nIn this example, period refers to the number of time-points for each cycle\u0026rsquo;s repetition and harmonics to the number of Fourier harmonics used. \u0026ldquo;Simpler\u0026rdquo; cyclic patterns usually require less harmonics. In the figure below we show on the lowest and highest frequency harmonics, on the left and right respectively.\n AR-p An AR(\\(p\\)) (Auto-Regressive) component can be specified using the directives:\nstructure:- type:armastart:0.0coefficients:0.1,0.3,0.15noise:0.5In the above example we would be creating an AR(3) component, with respective coefficients \\(\\phi=\\lbrace 0.1,0.3,0.15 \\rbrace\\). These coefficients will take part of the state model as\n\\[ \\mathsf{G} = \\begin{bmatrix} \\phi_1 \u0026amp; \\phi_2 \u0026amp; \\cdots \u0026amp; \\phi_{p-1} \u0026amp; \\phi_p \\\\ 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0 \\\\ \\vdots \u0026amp; \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots \\\\ 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix} \\]\nIn the following plots we show respectively the first and second component of the AR(3) state vector.\n Composing Structural composition of DGLM structures amounts to the individual composition of the state covariance matrix and state/observational evolution matrices such that:\n\\[ \\mathsf{F}^T = \\begin{bmatrix}\\mathsf{F}_1 \u0026amp; \\mathsf{F}_2 \u0026amp; \\dots \\mathsf{F}_i\\end{bmatrix}^T \\\\ \\mathsf{G} = \\text{blockdiag}\\left(\\mathsf{G}_1, \\mathsf{G}_2, \\dots, \\mathsf{G}_i\\right) \\\\ \\mathsf{W} = \\text{blockdiag}\\left(\\mathsf{W}_1, \\mathsf{W}_2, \\dots, \\mathsf{W}_i\\right) \\]\nTo express the composition of structures in the YAML configuration, we simply enumerate the separate components under the structure key. As as example, to compose the previous mean and seasonal components, we would simply write:\nstructure:- type:meanstart:0.0noise:1.5- type:seasonperiod:200harmonics:5start:0.0noise:0.7This would create a structure containing both an underlying mean and a seasonal component.\nObservations As we have seen from (3) that an observational model can be coupled with a structure to complete the DGLM specification. In the following sections we will look at some example observational models and in which situations they might be useful.\nContinuous Continuous observations are useful to model real valued data such as stock prices, temperature readings, etc. This can be achieved by specifying the observational component as a Gaussian distribution such that:\n\\[ Y_t|\\Phi \\sim \\mathcal{N}\\left(y_t|\\eta_t, \\mathsf{W}\\right). \\]\nobservations:- type:continuousnoise:1.5The following plot shows the coupling of the structure used in the mean section with the continuous (example above) observational model.\n Discrete Discrete observations, sometimes referred as \u0026ldquo;count data\u0026rdquo;, can be used to model integer quantities. This can be achieved by using a Poisson distribution in the observational model, such that:\n\\[ Y_t|\\Phi \\sim \\text{Po}\\left(y_t|\\eta_t\\right) \\]\nAn example configuration would be:\nobservations:- type:discreteIn this case we will use the previous ARMA(3) structure example and couple it with a discrete observational model. The result is shown in the plot below:\n Categorical In the categorical case, we model the observations according to a binomial distribution, such that\n\\[ Y_t \\sim \\text{Bin}\\left(y_t|\\eta_t,r\\right), \\]\nwhere \\(r\\) represents the number of categories. A typical example would be the case where \\(r=1\\) which would represent a binary outcome (0 or 1). The following configuration implements this very case:\nobservations:- type:categoricalcategories:1We can see in the plot below (states on the left, observations on the right) a realisation of this stream, when using the previous seasonal example structure.\n Often, when simulating a data stream, we might be interested in the category labels themselves, rather than a numerical value. The generator allows to pass directly a list of labels and output the labelled observations. Let\u0026rsquo;s assume we wanted to generate a stream of random DNA nucleotides (C, T, A and G). The generator allows to pass the labels directly and output the direct mapping between observations and label, that is:\n\\[ y_t: \\lbrace 0, 1, 2, 3 \\rbrace \\mapsto \\lbrace\\text{C, T, A, G}\\rbrace \\]\nobservations:- type:categoricalvalues:C,T,A,GUsing the same seasonal structure and observation model as above, the output would then be:\n Composite model In a real-world scenario we are interested in simulating multivariate data and that comprises of different observational models. For instance, combining observation components from categorical, continuous, etc.\nThe approach taken for multivariate composite models, is that the structures are composed as seen previously into a single one and the resulting state vector is then \u0026ldquo;collapsed\u0026rdquo; into a vector on natural parameters, \\(\\eta_t\\) which are then used to sample the individual observation components.\n\\[ \\theta_t = \\lbrace\\underbrace{\\theta_{1}, \\theta_{2}, \\theta_{3}}_{\\eta_1}, \\underbrace{\\theta_{4}, \\theta_{5}, \\theta_{6}}_{\\eta_2}\\rbrace \\\\ y = f(\\eta_t) \\\\ = \\lbrace f_1(\\eta_1), f_2(\\eta_2)\\rbrace \\]\nThe model composition can be expressed by grouping the different structures and observations under a `compose` key:\ncompose:- structure:# component 1- type:meanstart:0.0noise:0.5- observations:- type:continuousnoise:0.5- structure:# component 2- type:meanstart:5.0noise:3.7- observations:- type:continuousnoise:1.5Examples We will look at two separate examples, one that creates a stream of simulated stock prices and one that generates a fake HTTP log. We assume we want to simulate a stream of per-day stock prices for 3 different companies, each with different characteristics. In this case, we will model the following:\n Company A\u0026rsquo;s stocks start at quite a high value ($700) and are quite stable throughout time Company B\u0026rsquo;s stocks start slightly lower than A ($500) and are quite stable in the long run, but show heavy fluctuation from day to day Company C\u0026rsquo;s stocks start at $600 are very unpredictable  Since we will be using per-day data we won\u0026rsquo;t be streaming this in realtime! We can map each daily observation to a second in our stream so we will specify a period=1. All stocks will exhibit a small monthly effect (period=30), which will be indicated by a noise=0.01 and a yearly effect (period=365) with a noise=2.5.\nThe resulting configuration will be:\ncompose:- structure:# company A- type:meanstart:700noise:0.01# low structural variance- type:seasonperiod:30# monthly seasonalitynoise:0.1- type:seasonperiod:365.# yearly seasonalitynoise:1.7- observations:- type:continuousnoise:0.05# low observational variance- structure:# company B- type:meanstart:500noise:0.01# low structural variance- type:seasonperiod:30# monthly seasonalitynoise:0.7- type:seasonperiod:365.# yearly seasonalitynoise:3.7- observations:- type:continuousnoise:3.00# higher observational variance- structure:# company C- type:meanstart:600noise:3.0# higher structural variance- type:seasonperiod:30# monthly seasonalitynoise:0.1- type:seasonperiod:365.# yearly seasonalitynoise:0.25- observations:- type:continuousnoise:4.0# higher observational varianceA realisation of this stream looks like the figure below.\n To generate the fake HTTP log we will make the following assumptions:\n We will have a request type (GET, POST, PUT) which will vary following a random walk A set of visited pages which, for illustration purposes, will be limited to (/site/page.htm, /site/index.htm and /internal/example.htm). We also want that the URLs visited follow a seasonal pattern. An IP address in the IPv4 format (i.e. 0-255.0-255.0-255.0-255)  It is clear that for all variables the appropriate observational model is the categorical one. For the request type and the visited page we can pass directly the category name in the configuration file and for the IP we simply need four categorical observations with \\(r=255\\).\nIf the underlying structure is the same, a useful shortcut to specify several observation component is the replicate key. In this particular example to generate four 0-255 numbers with an underlying mean as the structure, we simple use:\n- replicate: 4 structure: - type: mean start: 0.0 noise: 2.1 observations: type: categorical categories: 255 The full configuration for the HTTP log simulation could then be something like this:\ncompose:- structure:- type:meanstart:0.0noise:0.01observations:type:categoricalvalues:GET,POST,PUT- structure:- type:meanstart:0.0noise:0.01- type:seasonstart:1.0period:15noise:0.2observations:type:categoricalvalues:/site/page.htm,/site/index.htm,/internal/example.htm- replicate:4structure:- type:meanstart:0.0noise:2.1observations:type:categoricalcategories:255[\u0026#34;PUT\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 171, 158, 59, 89] [\u0026#34;GET\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 171, 253, 71, 146] [\u0026#34;PUT\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 224, 252, 9, 156] [\u0026#34;POST\u0026#34;, \u0026#34;/site/index.htm\u0026#34;, 143, 253, 6, 126] [\u0026#34;POST\u0026#34;, \u0026#34;/site/page.htm\u0026#34;, 238, 254, 2, 48] [\u0026#34;GET\u0026#34;, \u0026#34;/site/page.htm\u0026#34;, 228, 252, 52, 126] [\u0026#34;POST\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 229, 234, 103, 233] [\u0026#34;GET\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 185, 221, 109, 195] ... Setting up the generator As I have mentioned in the beginning of this post, we want to fit the data simulation solution into a cloud computing workflow. To illustrate this we will use the OpenShift platform which allows for the deployment of containerised applications. A typical setup for a streaming data processing application would be as illustrated in the figure below. We have several sources connected to a message broker, such as Apache Kafka in this case. Data might be partitioned into \u0026ldquo;topics\u0026rdquo; which are then consumed by different applications, each performing data processing, either independently or in a distributed manner.\n An advantage of timeseries-mock would then be to replace the \u0026ldquo;real\u0026rdquo; data sources with a highly configurable simulator either for the prototyping or initial testing phase. If we consider our previous example of the \u0026ldquo;fake\u0026rdquo; HTTP log generation, an application for Web log analytics could be prototyped and tested with simulated log data very quickly, without being blocked by the lack of suitable real data. Since the data is consumed by proxy via the message broker\u0026rsquo;s topics, we could later on replace the simulator with real data sources seamlessly without an impact on any of the applications. To setup the generator (and assuming Kafka and your consumer application are already running on OpenShift) we only need to perform two steps:\n Write the data specifications in a YAML configuration Use the s2i to deploy the simulator  The s2i functionality of OpenShift allows to create deployment ready images by simply pointing to a source code location. In this case we could simply write:\n$ oc new-app centos/python-36-centos7~https://github.com/ruivieira/timeseries-mock \\ -e KAFKA_BROKERS=kafka:9092 \\ -e KAFKA_TOPIC=example \\ -e CONF=examples/mean_continuous.yml \\ --name=emitter In this case, we would deploy a simulator generating data according to the specifications in mean_continuous.yml. This data will be sent to the topic example of a Kafka broker running on port 9092.\n The stream will be ready to consume and message payload will a stream of serialised JSON strings. In the case of the simulated HTTP log this would be:\n{ name: \u0026#34;HTTP log\u0026#34; values: [\u0026#34;GET\u0026#34;, \u0026#34;/internal/example.htm\u0026#34;, 185, 221, 109, 195] }  name - the name given to this stream in the configuration file values - a single observation for this stream  After consuming the data it is straight-forward to do any post-processing if needed. For instance, the values above could be easily transformed into a standard Apache Web server log line.\nI hope you found this tool useful, simple to use and configure. Some future work includes adding more observations distributions beyond the exponential family and the ability to directly add transformation rules to the generated observations. If you have any suggestions, use cases (or found an issue!), please let me know in the repository.\nIf you have any comments please let me know on Mastodon (or Twitter).\nHappy coding!\n","permalink":"https://ruivieira.dev/containerised-streaming-data-generation-using-state-space-models.html","tags":null,"title":"Containerised Streaming Data Generation using State-Space Models"},{"categories":null,"contents":"Notes on containers.\nTips Extract image locally To extract a container\u0026rsquo;s image locally (e.g. using Docker) the following can be used:\ndocker export $CONTAINER_NAME \u0026gt; output.tar Alternatively, and using the $IMAGE_ID we can do:\ndocker save $IMAGE_ID$ \u0026gt; output.tar ","permalink":"https://ruivieira.dev/containers.html","tags":null,"title":"Containers"},{"categories":null,"contents":"Main documentation is available here.\nSetup Requirements For the purpose of these instructions we will assume the following are installed:\n Python 3.9.0 virtualenv  A new venv can be created with virtualenv env1 and activated with source venv/bin/activate. Once the environment is active we can install the cookiecutter package using pip install cookiecutter.\nThe create of the cookiecutter project can be done with\ncookiecutter https://github.com/drivendata/cookiecutter-data-science For the remainder of this text we will call the of the project you\u0026rsquo;ve just created as $PROJ.\n  More details at Python.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/cookiecutter-data-science.html","tags":null,"title":"Cookiecutter data science"},{"categories":null,"contents":"Similarity Let\u0026rsquo;s create two datasets, \\(\\mu_1\\) and \\(\\mu_2\\) such that\n\\[ \\mu_i = \\{x_1,\\dots,x_n\\} \\sim \\{\\mathcal{U}_1(-1,1),\\dots,\\mathcal{U}_n(-1,1)\\} \\]\nWe will use \\(N=100\\) observations for a vector sized \\(n=10\\).\nimport numpy as np import pandas as pd import scipy.stats as stats from scipy.spatial.distance import squareform  n = 10 N = 100  np.random.seed(0) mu_1 = np.random.normal(loc=0, scale=1, size=(N, n)) mu_2 = np.random.normal(loc=0, scale=1, size=(N, n)) We now add some noise, \\(\\epsilon=0.6\\), to \\(\\mu_2\\) such that\n\\[ \\mu_2 = \\epsilon \\mu_2 + (1-\\epsilon)*\\mu_1 \\]\nepsilon = 0.6 mu_2 = epsilon*mu_2 + (1-epsilon)*mu_1 We use Pandas to calculate the correlation matrix:\nC1 = pd.DataFrame(mu_1).corr() C2 = pd.DataFrame(mu_2).corr() And we plot the correlation matrices.\n Spearman correlation Calculate similarity using Spearman correlation between the top triangle of the covariance matrices \\(C_1\\) and \\(C_2\\).\nindices = np.triu_indices(C1.shape[0], k=1) print(C1[indices]) ","permalink":"https://ruivieira.dev/correlation-matrix.html","tags":null,"title":"Correlation matrix"},{"categories":null,"contents":"Building counterfactually fair models Data To evaluate counterfactual fairness we will be using the \u0026ldquo;law school\u0026rdquo; dataset1.\nThe Law School Admission Council conducted a survey across 163 law schools in the United States. It contains information on 21,790 law students such as their entrance exam scores (LSAT), their grade-point average (GPA) collected prior to law school, and their first year average grade (FYA). Given this data, a school may wish to predict if an applicant will have a high `FYA`. The school would also like to make sure these predictions are not biased by an individualâs race and sex. However, the LSAT, GPA, and FYA scores, may be biased due to social factors.\nWe start by importing the data into a [Pandas]] DataFrame.\nimport warnings  warnings.filterwarnings(\u0026#34;ignore\u0026#34;) import pandas as pd  df = pd.read_csv(\u0026#34;data/law_data.csv\u0026#34;, index_col=0) df.head()  race sex LSAT UGPA region_first ZFYA sander_index first_pf 0 White 1 39.0 3.1 GL -0.98 0.782738 1.0 1 White 1 36.0 3.0 GL 0.09 0.735714 1.0 2 White 2 30.0 3.1 MS -0.35 0.670238 1.0 5 Hispanic 2 39.0 2.2 NE 0.58 0.697024 1.0 6 White 1 37.0 3.4 GL -1.26 0.786310 1.0 Pre-processing We now pre-process the data. We start by creating categorical \u0026ldquo;dummy\u0026rdquo; variables according to the race variable.\ndf = pd.get_dummies(df, columns=[\u0026#34;race\u0026#34;], prefix=\u0026#34;\u0026#34;, prefix_sep=\u0026#34;\u0026#34;) df.iloc[:, : 7].head()  sex LSAT UGPA region_first ZFYA sander_index first_pf 0 1 39.0 3.1 GL -0.98 0.782738 1.0 1 1 36.0 3.0 GL 0.09 0.735714 1.0 2 2 30.0 3.1 MS -0.35 0.670238 1.0 5 2 39.0 2.2 NE 0.58 0.697024 1.0 6 1 37.0 3.4 GL -1.26 0.786310 1.0 df.iloc[:, 7 :].head()  Amerindian Asian Black Hispanic Mexican Other Puertorican White 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 1 5 0 0 0 1 0 0 0 0 6 0 0 0 0 0 0 0 1 We also want to expand the sex variable into male / female categorical variables and remove the original.\ndf[\u0026#34;male\u0026#34;] = df[\u0026#34;sex\u0026#34;].map(lambda x: 1 if x == 2 else 0) df[\u0026#34;female\u0026#34;] = df[\u0026#34;sex\u0026#34;].map(lambda x: 1 if x == 1 else 0) df = df.drop(axis=1, columns=[\u0026#34;sex\u0026#34;]) df.iloc[:, 0:7].head()  LSAT UGPA region_first ZFYA sander_index first_pf Amerindian 0 39.0 3.1 GL -0.98 0.782738 1.0 0 1 36.0 3.0 GL 0.09 0.735714 1.0 0 2 30.0 3.1 MS -0.35 0.670238 1.0 0 5 39.0 2.2 NE 0.58 0.697024 1.0 0 6 37.0 3.4 GL -1.26 0.786310 1.0 0 df.iloc[:, 7:].head()  Asian Black Hispanic Mexican Other Puertorican White male female 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 2 0 0 0 0 0 0 1 1 0 5 0 0 1 0 0 0 0 1 0 6 0 0 0 0 0 0 1 0 1 We will also convert the entrance exam scores (LSAT) to a discrete variable.\ndf[\u0026#34;LSAT\u0026#34;] = df[\u0026#34;LSAT\u0026#34;].astype(int) df.iloc[:, :6].head()  LSAT UGPA region_first ZFYA sander_index first_pf 0 39 3.1 GL -0.98 0.782738 1.0 1 36 3.0 GL 0.09 0.735714 1.0 2 30 3.1 MS -0.35 0.670238 1.0 5 39 2.2 NE 0.58 0.697024 1.0 6 37 3.4 GL -1.26 0.786310 1.0 df.iloc[:, 6:].head()  Amerindian Asian Black Hispanic Mexican Other Puertorican White \\ 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 1 5 0 0 0 1 0 0 0 0 6 0 0 0 0 0 0 0 1   male female 0 0 1 1 0 1 2 1 0 5 1 0 6 0 1 Protected attributes Counterfactual fairness enforces that a distribution over possible predictions for an individual should remain unchanged in a world where an individualâs protected attributes \\(A\\) had been different in a causal sense. Let\u0026rsquo;s start by defining the protected attributes. Obvious candidates are the different categorical variables for ethnicity (Asian, White, Black, etc) and gender (male, female).\nA = [  \u0026#34;Amerindian\u0026#34;,  \u0026#34;Asian\u0026#34;,  \u0026#34;Black\u0026#34;,  \u0026#34;Hispanic\u0026#34;,  \u0026#34;Mexican\u0026#34;,  \u0026#34;Other\u0026#34;,  \u0026#34;Puertorican\u0026#34;,  \u0026#34;White\u0026#34;,  \u0026#34;male\u0026#34;,  \u0026#34;female\u0026#34;, ] Training and testing subsets We will now divide the dataset into training and testing subsets. We will use the same ratio as inÂ 2, that is 20%.\nfrom sklearn.model_selection import train_test_split  df_train, df_test = train_test_split(df, random_state=23, test_size=0.2); Models Unfair model As detailed inÂ 2, the concept of counterfactual fairness holds under three levels of assumptions of increasing strength.\nThe first of such levels is Level 1, where \\(\\hat{Y}\\) is built using only the observable non-descendants of \\(A\\). This only requires partial causal ordering and no further causal assumptions, but in many problems there will be few, if any, observables which are not descendants of protected demographic factors.\nFor this dataset, since LSAT, GPA, and FYA are all biased by ethnicity and gender, we cannot use any observed features to construct a Level 1 counterfactually fair predictor as described in Level 1.\nInstead (and in order to compare the performance with Level 2 and 3 models) we will build two unfair baselines.\n A Full model, which will be trained with the totality of the variables An Unaware model (FTU), which will be trained will all the variables, except the protected attributes \\(A\\).  Let\u0026rsquo;s proceed with calculating the Full model.\nFull model As mentioned previously, the full model will be a simple linear regression in order to predict ZFYA using all of the variables.\nfrom sklearn.linear_model import LinearRegression  linreg_unfair = LinearRegression() The inputs will then be the totality of the variabes (protected variables \\(A\\), as well as UGPA and LSAT).\nimport numpy as np  X = np.hstack(  (  df_train[A],  np.array(df_train[\u0026#34;UGPA\u0026#34;]).reshape(-1, 1),  np.array(df_train[\u0026#34;LSAT\u0026#34;]).reshape(-1, 1),  ) ) print(X) [[ 0. 0. 0. ... 1. 3.1 39. ]  [ 0. 0. 0. ... 1. 3.5 36. ]  [ 0. 0. 0. ... 1. 3.9 46. ]  ...  [ 0. 0. 0. ... 1. 2.9 33. ]  [ 0. 0. 0. ... 0. 2.9 31. ]  [ 0. 0. 0. ... 0. 3.6 39. ]] As for our target, we are trying to predict ZFYA (first year average grade).\ny = df_train[\u0026#34;ZFYA\u0026#34;] y[:10] 10454 0.56 14108 0.60 20624 -0.14 8316 0.20 14250 0.02 18909 -1.47 8949 1.36 1658 0.39 23340 0.10 26884 0.48 Name: ZFYA, dtype: float64 We fit the model:\nlinreg_unfair = linreg_unfair.fit(X, y) And perform some predictions on the test subset.\nX_test = np.hstack(  (  df_test[A],  np.array(df_test[\u0026#34;UGPA\u0026#34;]).reshape(-1, 1),  np.array(df_test[\u0026#34;LSAT\u0026#34;]).reshape(-1, 1),  ) ) X_test array([[ 0. , 0. , 0. , ..., 0. , 3.4, 32. ],  [ 0. , 0. , 0. , ..., 1. , 3.5, 41. ],  [ 0. , 0. , 0. , ..., 1. , 3.9, 42. ],  ...,  [ 0. , 0. , 0. , ..., 0. , 2.3, 28. ],  [ 0. , 0. , 0. , ..., 0. , 3.3, 36. ],  [ 0. , 0. , 0. , ..., 0. , 2.9, 37. ]]) predictions_unfair = linreg_unfair.predict(X_test) predictions_unfair array([ 0.08676147, 0.34942627, 0.4609375 , ..., -0.25949097,  0.19308472, 0.14471436]) We will also calculate the unfair model score for future use.\nscore_unfair = linreg_unfair.score(X_test, df_test[\u0026#34;ZFYA\u0026#34;]) print(score_unfair) 0.12701634112845117 from sklearn.metrics import mean_squared_error  RMSE_unfair = np.sqrt(mean_squared_error(df_test[\u0026#34;ZFYA\u0026#34;], predictions_unfair)) print(RMSE_unfair) 0.8666709890234552 Fairness through unawareness (FTU) As also mentioned inÂ 2, the second baseline we will use is an Unaware model (FTU), which will be trained will all the variables, except the protected attributes \\(A\\).\nlinreg_ftu = LinearRegression() We will create the inputs as previously, but without using the protected attributes, \\(A\\).\nX_ftu = np.hstack(  (  np.array(df_train[\u0026#34;UGPA\u0026#34;]).reshape(-1, 1),  np.array(df_train[\u0026#34;LSAT\u0026#34;]).reshape(-1, 1),  ) ) X_ftu array([[ 3.1, 39. ],  [ 3.5, 36. ],  [ 3.9, 46. ],  ...,  [ 2.9, 33. ],  [ 2.9, 31. ],  [ 3.6, 39. ]]) And we fit the model:\nlinreg_ftu = linreg_ftu.fit(X_ftu, y) Again, let\u0026rsquo;s perform some predictions on the test subset.\nX_ftu_test = np.hstack(  (np.array(df_test[\u0026#34;UGPA\u0026#34;]).reshape(-1, 1), np.array(df_test[\u0026#34;LSAT\u0026#34;]).reshape(-1, 1)) ) X_ftu_test array([[ 3.4, 32. ],  [ 3.5, 41. ],  [ 3.9, 42. ],  ...,  [ 2.3, 28. ],  [ 3.3, 36. ],  [ 2.9, 37. ]]) predictions_ftu = linreg_ftu.predict(X_ftu_test) predictions_ftu array([-0.06909331, 0.35516229, 0.50304555, ..., -0.53109868,  0.08204563, 0.0226846 ]) As previously, let\u0026rsquo;s calculate this model\u0026rsquo;s score.\nftu_score = linreg_ftu.score(X_ftu_test, df_test[\u0026#34;ZFYA\u0026#34;]) print(ftu_score) 0.0917442226187073 RMSE_ftu = np.sqrt(mean_squared_error(df_test[\u0026#34;ZFYA\u0026#34;], predictions_ftu)) print(RMSE_ftu) 0.8840061503773576 Latent variable model Still according toÂ 2, a Level 2 approach will model latent âfairâ variables which are parents of observed variables.\nIf we consider a predictor parameterised by \\(\\theta\\), such as:\n\\[ \\hat{Y} \\equiv g_\\theta (U, X_{\\nsucc A}) \\]\nwith \\(X_{\\nsucc A} \\subseteq X\\) are non-descendants of \\(A\\). Assuming a loss function \\(l(\\cdot,\\cdot)\\) and training data \\(\\mathcal{D}\\equiv\\{(A^{(i), X^{(i)}, Y^{(i)}})\\}\\), for \\(i=1,2\\dots,n\\), the empirical loss is defined as\n\\[ L(\\theta)\\equiv \\sum_{i=1}^n \\mathbb{E}[l(y^{(i)},g_\\theta(U^{(i)}, x^{(i)}_{\\nsucc A}))]/n \\]\nwhich has to be minimised in order to \\(\\theta\\). Each \\(n\\) expectation is with respect to random variable \\(U^{(i)}\\) such that\n\\[ U^{(i)}\\sim P_{\\mathcal{M}}(U|x^{(i)}, a^{(i)}) \\]\nwhere \\(P_{\\mathcal{M}}(U|x,a)\\) is the conditional distribution of the background variables as given by a causal model \\(M\\) that is available by assumption.\nIf this expectation cannot be calculated analytically, Markov chain Monte Carlo (MCMC) can be used to approximate it as in the following algorithm.\nWe will follow the model specified in the original paper, where the latent variable considered is \\(K\\), which represents a student\u0026rsquo;s knowledge. \\(K\\) will affect GPA, LSAT and the outcome, FYA. The model can be defined by:\n\\begin{aligned} GPA \u0026amp;\\sim \\mathcal{N}(GPA_0 + w_{GPA}^KK + w_{GPA}^RR + w_{GPA}^SS, \\sigma_{GPA}) \\\\ LSAT \u0026amp;\\sim \\text{Po}(\\exp(LSAT_0 + w_{LSAT}^KK + w_{LSAT}^RR + w_L^SS)) \\\\ FYA \u0026amp;\\sim \\mathcal{N}(w_{FYA}^KK + w_{FYA}^RR + w_{FYA}^SS, 1) \\\\ K \u0026amp;\\sim \\mathcal{N}(0,1) \\end{aligned}\nThe priors used will be:\n\\begin{aligned} GPA_0 \u0026amp;\\sim \\mathcal{N}(0, 1) \\\\ LSAT_0 \u0026amp;\\sim \\mathcal{N}(0, 1) \\\\ GPA_0 \u0026amp;\\sim \\mathcal{N}(0, 1) \\end{aligned}\nimport pymc3 as pm  K = len(A)   def MCMC(data, samples=1000):   N = len(data)  a = np.array(data[A])   model = pm.Model()   with model:  # Priors  k = pm.Normal(\u0026#34;k\u0026#34;, mu=0, sigma=1, shape=(1, N))  gpa0 = pm.Normal(\u0026#34;gpa0\u0026#34;, mu=0, sigma=1)  lsat0 = pm.Normal(\u0026#34;lsat0\u0026#34;, mu=0, sigma=1)  w_k_gpa = pm.Normal(\u0026#34;w_k_gpa\u0026#34;, mu=0, sigma=1)  w_k_lsat = pm.Normal(\u0026#34;w_k_lsat\u0026#34;, mu=0, sigma=1)  w_k_zfya = pm.Normal(\u0026#34;w_k_zfya\u0026#34;, mu=0, sigma=1)   w_a_gpa = pm.Normal(\u0026#34;w_a_gpa\u0026#34;, mu=np.zeros(K), sigma=np.ones(K), shape=K)  w_a_lsat = pm.Normal(\u0026#34;w_a_lsat\u0026#34;, mu=np.zeros(K), sigma=np.ones(K), shape=K)  w_a_zfya = pm.Normal(\u0026#34;w_a_zfya\u0026#34;, mu=np.zeros(K), sigma=np.ones(K), shape=K)   sigma_gpa_2 = pm.InverseGamma(\u0026#34;sigma_gpa_2\u0026#34;, alpha=1, beta=1)   mu = gpa0 + (w_k_gpa * k) + pm.math.dot(a, w_a_gpa)   # Observed data  gpa = pm.Normal(  \u0026#34;gpa\u0026#34;,  mu=mu,  sigma=pm.math.sqrt(sigma_gpa_2),  observed=list(data[\u0026#34;UGPA\u0026#34;]),  shape=(1, N),  )  lsat = pm.Poisson(  \u0026#34;lsat\u0026#34;,  pm.math.exp(lsat0 + w_k_lsat * k + pm.math.dot(a, w_a_lsat)),  observed=list(data[\u0026#34;LSAT\u0026#34;]),  shape=(1, N),  )  zfya = pm.Normal(  \u0026#34;zfya\u0026#34;,  mu=w_k_zfya * k + pm.math.dot(a, w_a_zfya),  sigma=1,  observed=list(data[\u0026#34;ZFYA\u0026#34;]),  shape=(1, N),  )   step = pm.Metropolis()  trace = pm.sample(samples, step, progressbar = False)   return trace train_estimates = MCMC(df_train) Multiprocess sampling (4 chains in 4 jobs) CompoundStep \u0026gt;Metropolis: [sigma_gpa_2] \u0026gt;Metropolis: [w_a_zfya] \u0026gt;Metropolis: [w_a_lsat] \u0026gt;Metropolis: [w_a_gpa] \u0026gt;Metropolis: [w_k_zfya] \u0026gt;Metropolis: [w_k_lsat] \u0026gt;Metropolis: [w_k_gpa] \u0026gt;Metropolis: [lsat0] \u0026gt;Metropolis: [gpa0] \u0026gt;Metropolis: [k] /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 77 seconds. The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge. The estimated number of effective samples is smaller than 200 for some parameters. Let\u0026rsquo;s plot a single trace for \\(k^{(i)}\\).\nimport matplotlib.pyplot as plt import seaborn as sns from plotutils import *  # Thin the samples before plotting k_trace = train_estimates[\u0026#34;k\u0026#34;][:, 0].reshape(-1, 1)[0::100] plt.subplot(1, 2, 1) plt.hist(k_trace, color=colours[0], bins=100) plt.subplot(1, 2, 2) plt.scatter(range(len(k_trace)), k_trace, s=1, c=colours[0]) plt.show()  train_k = np.mean(train_estimates[\u0026#34;k\u0026#34;], axis=0).reshape(-1, 1) train_k array([[-0.00531227],  [-0.13776645],  [-0.02434896],  ...,  [ 0.02273157],  [-0.2767904 ],  [-0.15568193]]) We can now estimate \\(k\\) using the test data:\ntest_map_estimates = MCMC(df_test) Multiprocess sampling (4 chains in 4 jobs) CompoundStep \u0026gt;Metropolis: [sigma_gpa_2] \u0026gt;Metropolis: [w_a_zfya] \u0026gt;Metropolis: [w_a_lsat] \u0026gt;Metropolis: [w_a_gpa] \u0026gt;Metropolis: [w_k_zfya] \u0026gt;Metropolis: [w_k_lsat] \u0026gt;Metropolis: [w_k_gpa] \u0026gt;Metropolis: [lsat0] \u0026gt;Metropolis: [gpa0] \u0026gt;Metropolis: [k] /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), /Users/rui/Library/Python/3.8/lib/python/site-packages/pymc3/step_methods/metropolis.py:226: RuntimeWarning: overflow encountered in exp  \u0026#34;accept\u0026#34;: np.exp(accept), Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 59 seconds. The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge. The estimated number of effective samples is smaller than 200 for some parameters. Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 35 seconds. The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge. The estimated number of effective samples is smaller than 200 for some parameters.\ntest_k = np.mean(test_map_estimates[\u0026#34;k\u0026#34;], axis=0).reshape(-1, 1) test_k array([[ 0.36632736],  [ 0.09415253],  [ 0.03452081],  ...,  [ 0.00471526],  [-0.09991792],  [ 0.19771541]]) We now build the Level 2 predictor, using \\(k\\) as the input.\nlinreg_latent = LinearRegression() linreg_latent = linreg_latent.fit(train_k, df_train[\u0026#34;ZFYA\u0026#34;]) predictions_latent = linreg_latent.predict(test_k) predictions_latent array([0.18043648, 0.1160878 , 0.10198943, ..., 0.09494268, 0.07020488,  0.14057256]) latent_score = linreg_latent.score(test_k, df_test[\u0026#34;ZFYA\u0026#34;]) print(latent_score) 0.0027649341873033917 RMSE_latent = np.sqrt(mean_squared_error(df_test[\u0026#34;ZFYA\u0026#34;], predictions_latent)) print(RMSE_latent) 0.9262963924423802 Additive error model Finally, in Level 3, we model GPA, LSAT, and FYA as continuous variables with additive error terms independent of race and sex3.\nThis corresponds to\n\\begin{aligned} GPA \u0026amp;= b_G + w^R_{GPA}R + w^S_{GPA}S + \\epsilon_{GPA}, \\epsilon_{GPA} \\sim p(\\epsilon_{GPA}) \\\\ LSAT \u0026amp;= b_L + w^R_{LSAT}R + w^S_{LSAT}S + \\epsilon_{LSAT}, \\epsilon_{LSAT} \\sim p(\\epsilon_{LSAT}) \\\\ FYA \u0026amp;= b_{FYA} + w^R_{FYA}R + w^S_{FYA}S + \\epsilon_{FYA} , \\epsilon_{FYA} \\sim p(\\epsilon_{FYA}) \\end{aligned}\nWe estimate the error terms \\(\\epsilon_{GPA}, \\epsilon_{LSAT}\\) by first fitting two models that each use race and sex to individually predict GPA and LSAT. We then compute the residuals of each model (e.g., \\(\\epsilon_{GPA} =GPAâ\\hat{Y}_{GPA}(R, S)\\)). We use these residual estimates of \\(\\epsilon_{GPA}, \\epsilon_{LSAT}\\) to predict \\(FYA\\). InÂ 2 this is called Fair Add.\nSince the process is similar for the individual predictions for GPA and LSAT, we will write a method to avoid repetion.\ndef calculate_epsilon(data, var_name, protected_attr):  X = data[protected_attr]  y = data[var_name]   linreg = LinearRegression()  linreg = linreg.fit(X, y)   predictions = linreg.predict(X)   return data[var_name] - predictions Let\u0026rsquo;s apply it to each variable, individually. First we calculate \\(\\epsilon_{GPA}\\):\nepsilons_gpa = calculate_epsilon(df, \u0026#34;UGPA\u0026#34;, A) epsilons_gpa 0 -0.242 1 -0.342 2 -0.100 5 -0.873 6 0.058  ... 27472 0.800 27473 0.358 27474 0.658 27475 -0.300 27476 -0.100 Name: UGPA, Length: 21791, dtype: float64 Next, we calculate \\(\\epsilon_{LSAT}\\):\nepsilons_LSAT = calculate_epsilon(df, \u0026#34;LSAT\u0026#34;, A) epsilons_LSAT 0 1.789 1 -1.211 2 -7.689 5 5.055 6 -0.211  ... 27472 -4.689 27473 0.789 27474 -1.211 27475 -6.689 27476 -9.689 Name: LSAT, Length: 21791, dtype: float64 Let\u0026rsquo;s visualise the \\(\\epsilon\\) distribution quickly:\nimport matplotlib.pyplot as plt import seaborn as sns  plt.subplot(1, 2, 1) plt.hist(epsilons_gpa, color=colours[0], bins=100) plt.title(\u0026#34;$\\epsilon_{GPA}$\u0026#34;) plt.xlabel(\u0026#34;$\\epsilon_{GPA}$\u0026#34;)  plt.subplot(1, 2, 2) plt.hist(epsilons_LSAT, color=colours[1], bins=100) plt.title(\u0026#34;$\\epsilon_{LSAT}$\u0026#34;) plt.xlabel(\u0026#34;$\\epsilon_{LSAT}$\u0026#34;) plt.show()  We finally use the calculated \\(\\epsilon\\) to train a model in order to predict FYA. We start by getting the subset of the \\(\\epsilon\\) which match the training indices.\nX = np.hstack(  (  np.array(epsilons_gpa[df_train.index]).reshape(-1, 1),  np.array(epsilons_LSAT[df_train.index]).reshape(-1, 1),  ) ) X array([[-0.24179687, 1.7890625 ],  [ 0.15820312, -1.2109375 ],  [ 0.55820312, 8.7890625 ],  ...,  [-0.44179688, -4.2109375 ],  [-0.25087891, -4.7265625 ],  [ 0.39980469, 1.31054688]]) linreg_fair_add = LinearRegression()  linreg_fair_add = linreg_fair_add.fit(  X,  df_train[\u0026#34;ZFYA\u0026#34;], ) We now use this model to calculate the predictions\nX_test = np.hstack(  (  np.array(epsilons_gpa[df_test.index]).reshape(-1, 1),  np.array(epsilons_LSAT[df_test.index]).reshape(-1, 1),  ) )  predictions_fair_add = linreg_fair_add.predict(X_test) predictions_fair_add array([-0.04394693, 0.24454891, 0.35558793, ..., -0.38844376,  0.06136776, 0.01295201]) And as previously, we calculate the model\u0026rsquo;s score:\nfair_add_score = linreg_fair_add.score(X_test, df_test[\u0026#34;ZFYA\u0026#34;]) print(fair_add_score) 0.04475841449183948 RMSE_fair_add = np.sqrt(mean_squared_error(df_test[\u0026#34;ZFYA\u0026#34;], predictions_fair_add)) print(RMSE_fair_add) 0.9065835039365202 Comparison The scores, so far, are:\nprint(f\u0026#34;Unfair score:\\t{score_unfair}\u0026#34;) print(f\u0026#34;FTU score:\\t{ftu_score}\u0026#34;) print(f\u0026#34;L2 score:\\t{latent_score}\u0026#34;) print(f\u0026#34;Fair add score:\\t{fair_add_score}\u0026#34;) Unfair score:\t0.12701634112845117 FTU score:\t0.0917442226187073 L2 score:\t0.0027649341873033917 Fair add score:\t0.04475841449183948 print(f\u0026#34;Unfair RMSE:\\t{RMSE_unfair}\u0026#34;) print(f\u0026#34;FTU RMSE:\\t{RMSE_ftu}\u0026#34;) print(f\u0026#34;L2 RMSE:\\t{RMSE_latent}\u0026#34;) print(f\u0026#34;Fair add RMSE:\\t{RMSE_fair_add}\u0026#34;) Unfair RMSE:\t0.8666709890234552 FTU RMSE:\t0.8840061503773576 L2 RMSE:\t0.9262963924423802 Fair add RMSE:\t0.9065835039365202 Measuring counterfactual fairness First, we will measure two quantities, the Statistical Parity Difference (SPD)4 and Disparate impact (DI)5.\nStatistical Parity Difference / Disparate Impact from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio  parities = [] impacts = []  for a in A:  parity = demographic_parity_difference(df_train[\u0026#34;ZFYA\u0026#34;], df_train[\u0026#34;ZFYA\u0026#34;],  sensitive_features = df_train[a])  di = demographic_parity_ratio(df_train[\u0026#34;ZFYA\u0026#34;], df_train[\u0026#34;ZFYA\u0026#34;],  sensitive_features = df_train[a])  parities.append(parity)  impacts.append(di) df_parities = pd.DataFrame({\u0026#39;protected\u0026#39;:A,\u0026#39;parity\u0026#39;:parities,\u0026#39;impact\u0026#39;:impacts}) import matplotlib.pyplot as plt from plotutils import *  fig = plt.figure()  ax = fig.add_subplot(111) ax2 = ax.twinx()  fig.suptitle(\u0026#39;Statistical Parity Difference and Disparate Impact\u0026#39;)  width = 0.4 df_parities.plot(x =\u0026#39;protected\u0026#39;, y = \u0026#39;parity\u0026#39;, kind = \u0026#39;bar\u0026#39;, ax = ax, width = width,  position=1, color=colours[0], legend=False)  df_parities.plot(x =\u0026#39;protected\u0026#39;, y = \u0026#39;impact\u0026#39;, kind = \u0026#39;bar\u0026#39;, ax = ax2, width = width,  position = 0, color = colours[1], legend = False)  ax.axhline(y = 0.1, linestyle = \u0026#39;dashed\u0026#39;, alpha = 0.7, color = colours[0]) ax2.axhline(y = 0.55, linestyle = \u0026#39;dashed\u0026#39;, alpha = 0.7, color = colours[1])   patches, labels = ax.get_legend_handles_labels() ax.legend(patches, [\u0026#39;Stat Parity Diff\u0026#39;], loc = \u0026#39;upper left\u0026#39;)  patches, labels = ax2.get_legend_handles_labels() ax2.legend(patches, [\u0026#39;Disparate Impact\u0026#39;], loc = \u0026#39;upper right\u0026#39;)    labels = [item.get_text() for item in ax.get_xticklabels()]  for i in range(len(A)):  labels[i] = A[i]  ax.set_xticklabels(labels) ax.set_xlabel(\u0026#39;Protected Features\u0026#39;)  ax.set_ylabel(\u0026#39;Statistical Parity Difference\u0026#39;) ax2.set_ylabel(\u0026#39;Disparate Impact\u0026#39;)  plt.show()  Finding sensitive features Typically a \\(SPD \u0026gt; 0.1\\) and a \\(DI \u0026lt; 0.9\\) might indicate discrimination on those features. All protected attributes fail the SPD test and, in our dataset, we have two features (Hispanic and Mexican) which clearly fail the DI test.\nfor a in [\u0026#34;Mexican\u0026#34;, \u0026#34;Hispanic\u0026#34;]:  spd = demographic_parity_difference(y_true=df_train[\u0026#34;ZFYA\u0026#34;],  y_pred=df_train[\u0026#34;ZFYA\u0026#34;],  sensitive_features = df_train[a])  print(f\u0026#34;SPD({a}) = {spd}\u0026#34;)  di = demographic_parity_ratio(y_true=df_train[\u0026#34;ZFYA\u0026#34;],  y_pred=df_train[\u0026#34;ZFYA\u0026#34;],  sensitive_features = df_train[a])  print(f\u0026#34;DI({a}) = {di}\u0026#34;) SPD(Mexican) = 0.0014017257538768636 DI(Mexican) = 0.5556529360210342 SPD(Hispanic) = 0.003272247102713093 DI(Hispanic) = 0.34227833235466826   : McIntyre, Frank, and Michael Simkovic. \u0026ldquo;Are law degrees as valuable to minorities?.\u0026rdquo; International Review of Law and Economics 53 (2018): 23-37.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : Kusner, Matt J., Joshua Loftus, Chris Russell, and Ricardo Silva. \u0026ldquo;Counterfactual fairness.\u0026rdquo; In Advances in neural information processing systems, pp. 4066-4076. 2017.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : That may in turn be correlated with one-another.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : See {ref}`fairness:demographic-parity-difference`.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : See {ref}`fairness:disparate-impact`.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/counterfactual-fairness.html","tags":null,"title":"Counterfactual Fairness"},{"categories":null,"contents":"Here we will look at how to build a counterfactually fair model, as detailed in Counterfactual Fairness, specifically the \u0026ldquo;Fair Add\u0026rdquo; model.\nThis implementation will rely mostly on Apache Commons Math1 linear regression implementations, namely the Ordinary Least Squares (OLS) regression2. We start then by adding the relevant Maven dependencies:\n```xml  org.apache.commons commons-math3 3.6.1  ```\nData will be passed as a `RealMatrix`3. This matrix will have dimensions \\(N\\times f\\), where \\(N\\) is the number of observations and \\(f\\) is the number of features.\nWe can instatiate the model using\n```java // RealMatrix data = \u0026hellip; final CounterfactuallyFairModel model = new CounterfactuallyFairModel(data); ```\nWe will then need the following information:\n The protected attributes indices, `protectedIndices` The variable indices, `variableIndices` The target variable index, `targetIndex`  Assuming that we have the same variables as in the counterfactual fairness example, let\u0026rsquo;s say that the protected attributes have in the `data` matrix, column numbers `5, 6, 7, 8, 9, 10, 11, 12, 13, 14` and the model variables (`LSAT` and `UGPA`) have indices `1, 0` and the target (`ZFYA`) has index `2`. We then calculate the counterfactually fair model using:\n```java model.calculate(new int[]{5, 6, 7, 8, 9, 10, 11, 12, 13, 14}, new int[]{1, 0}, 2); ```\nThe `calculate` method performs the following:\n```java public void calculate(int[] protectedIndices, int[] variableIndices, int targetIndex) { final RealMatrix residuals = new Array2DRowRealMatrix(this.data.getRowDimension(), variableIndices.length);\nfor (int i = 0; i \u0026lt; variableIndices.length; i++) { final int index = variableIndices[i]; final RealVector varResidual = this.calculateEpsilon(protectedIndices, index); residuals.setColumn(i, varResidual.toArray()); }\n// predict target from residuals final OLSMultipleLinearRegression regression = new OLSMultipleLinearRegression(); regression.newSampleData(this.data.getColumn(targetIndex), residuals.getData());  } ```\nAs in counterfactual Fairness , we calculate a regression model to predict each of the variable (`LSAT` and `UGPA`) using the protected variables. The resulting residuals, \\(\\epsilon_{LSAT}\\) and \\(\\epsilon_{UGPA}\\) will in turn be used to calculate another regression model in order to predict the target variable `ZFYA`.\nThe residuals are calculated using the `calculateEpsilon` method, which consists of:\n```java public RealVector calculateEpsilon(int[] protectedIndices, int targetIndex) { int[] protectedRows = new int[this.data.getRowDimension()]; Arrays.setAll(protectedRows, i -\u0026gt; i); final RealMatrix _x = this.data.getSubMatrix(protectedRows, protectedIndices); final RealVector _y = this.data.getSubMatrix(protectedRows, new int[]{targetIndex}).getColumnVector(0);\nfinal OLSMultipleLinearRegression regression = new OLSMultipleLinearRegression(); regression.newSampleData(\\_y.toArray(), \\_x.getData()); return new ArrayRealVector(regression.estimateResiduals());  } ```\nWhich simply calculates a regression model for the variables using the protected attributes and returning a `RealVector` with the residual \\(\\epsilon\\).\n  https://commons.apache.org/proper/commons-math/.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://commons.apache.org/proper/commons-math/javadocs/api-3.6/org/apache/commons/math3/stat/regression/OLSMultipleLinearRegression.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://commons.apache.org/proper/commons-math/javadocs/api-3.6/org/apache/commons/math3/linear/RealMatrix.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/counterfactual-fairness-in-java.html","tags":null,"title":"Counterfactual Fairness in Java"},{"categories":null,"contents":"A special type of Explainability.\nDesiderata According to Verma et alÂ 1 the counterfactual desiderata is:\n Validity Actionability Sparsity Data manifold closeness Causality Amortised inference  Validity We assume that a counterfactual is valid if it solves the optimisation as states in Wachter et al2. If we defined the loss function as\n\\[ L(x,x^{\\prime},y^{\\prime},\\lambda)=\\lambda\\cdot(\\hat{f}(x^{\\prime})ây^{\\prime})^2+d(x,x^{\\prime}), \\]\nwe can define the counterfactual as\n\\[ \\arg \\underset{x^{\\prime}}{\\min}\\underset{\\lambda}{\\max} \\lambda\\cdot(\\hat{f}(x^{\\prime})ây^{\\prime})^2+d(x,x^{\\prime}) \\]\nwhere:\n \\(x \\in \\mathcal{X}\\) is the original data point \\(x^{\\prime} \\in \\mathcal{X}\\) is the counterfactual \\(y^{\\prime} \\in \\mathcal{Y}\\) is the desired label \\(d\\) is a [Distance metrics|distance metric]] to measure the distance between \\(x\\) and \\(x^{\\prime}\\). this could be a [Distance metrics#Manhattan distance L1|L1]] or L2 distance, a quadratic distance, etc.  Actionability Still according toÂ 2, actionability refers to the ability of a counterfactual method to separate between mutable and immutable features. Immutable, and additionally legally protected features, shouldn\u0026rsquo;t be changed by a counterfactual implementation. Formally, if we defined our set of mutable (or actionable) features as \\(\\mathcal{A}\\), we have\n\\[ \\arg \\underset{x^{\\prime} \\in \\mathcal{A}}{\\min}\\underset{\\lambda}{\\max} \\lambda\\cdot(\\hat{f}(x^{\\prime})ây^{\\prime})^2+d(x,x^{\\prime}) \\]\nSparsity According toÂ 2 Shorter counterfactuals are easier to understand and an effective counterfactual implementation should change the least amount of features as possible. If a sparsity penalty term is added to our definition\n\\[ g(x^{\\prime}-x) \\]\nwhich increases the more features are changed and could be a L0 or [Distance metrics#Manhattan distance L1|L1]] metric, for instance. We can then define the counterfactual as\n\\[ \\arg \\underset{x^{\\prime} \\in \\mathcal{A}}{\\min}\\underset{\\lambda}{\\max} \\lambda\\cdot(\\hat{f}(x^{\\prime})ây^{\\prime})^2+d(x,x^{\\prime})+g(x^{\\prime}-x) \\]\nData manifold closeness Still according toÂ 2, data manifold closeness is the property which guarantees that the counterfactual will be as close to the training data as possible. This can translate into a more \u0026ldquo;realistic\u0026rdquo; counterfactual, since it is possible that the counterfactual would take extreme or never seen before values in order to satisfy the previous conditions. Formally, we can write a penalty term for the adherence to the training data manifold, \\(\\mathcal{X}\\) as \\(l(x^{\\prime};\\mathcal{X})\\) and the define the counterfactual as\n\\[ \\arg \\underset{x^{\\prime} \\in \\mathcal{A}}{\\min}\\underset{\\lambda}{\\max} \\lambda\\cdot(\\hat{f}(x^{\\prime})ây^{\\prime})^2+d(x,x^{\\prime})+g(x^{\\prime}-x)+l(x^{\\prime};\\mathcal{X}) \\]\nCausality Causality refers to the property where feature changes will impact dependent features. That is, we no longer assume that all features are independent. This implies that the counterfactual method needs to mantain the causal relations between features.\nAmortised inference Amortised inference refers to the property of a counterfactual search to provide multiple counterfactuals for a single data point.\nAlternative methods Constraint solvers An alternative method to find counterfactuals is to use constraint solvers. This is explored more in-depth in counterfactuals with constraint solvers .\n  : Verma, Sahil, John Dickerson, and Keegan Hines. \u0026ldquo;Counterfactual Explanations for Machine Learning: A Review.\u0026rdquo; arXiv preprint arXiv:2010.10596 (2020).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : Wachter, Sandra, Brent Mittelstadt, and Chris Russell. \u0026ldquo;Counterfactual explanations without opening the black box: Automated decisions and the GDPR.\u0026rdquo; Harv. JL \u0026amp; Tech. 31 (2017): 841.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/counterfactuals.html","tags":null,"title":"Counterfactuals"},{"categories":null,"contents":"Scoring An implementation on how to calculate counterfactuals with Constraint Solvers (namely [OptaPlanner]]) is available here.\nThis implementation satisfies several criteria of the counterfactuals .\nThe penalisation score is represented with a BendableBigDecimalScoreÂ 1, having three \u0026ldquo;hard\u0026rdquo; levels and one \u0026ldquo;soft\u0026rdquo; level.\n The first hard level component, 1, penalises the score according to the distance between the prediction, \\(y^{\\prime}\\) for the currently proposed solution, \\(x^{\\prime}\\) and the original prediction \\(y\\), that is this our \\((\\hat{f}(x^{\\prime})-y^{\\prime})^2\\). This corresponds to the counterfactual\u0026rsquo;s validity.\nThe actionability is score with 2. This component penalises the score according to number of immutable features which were changed in the counterfactual.\nA confidence score component, 3 is use to, optionally, impose a minimum confidence threshold to the counterfactual\u0026rsquo;s associated prediction, \\(x^{\\prime}\\).\nFinally, the feature distance, 4, penalises the score according to the feature distance. This is the representation of\n\\[ d(x, x^{\\prime}). \\]\nIn the concrete implementation linked above, the distance, \\(d\\), chosen is a [Distance metrics#Manhattan distance L1|Manhattan]] (or \\(L^1\\)) distance calculated feature-wise. This also corresponds to the [Counterfactuals#Validity|validity property.]]\nImplementation  Entities are defined by classes such as Integer, Categorical, Boolean or Float, as shown in 5. Each of the features, shown in 6, is created as an instance of one of these entities. For instance, feature1 would be of type Integer and feature2 would be of type Categorical, etc.\nThe original data point, \\(x\\) is represented by this set of features (6).\nA planning solution (PlanningSolution), illustrated in 7 will produce candidate solutions (shown in 8)\nFor each solution, we propose a new set of features (\\(x^{\\prime}\\)) as a counterfactual candidate. For instance, solution A in 8.\nIn the following section we will look at how each component is calculated. We will refer to each \u0026ldquo;hard\u0026rdquo; level component as \\(H_1, H_2\\) and \\(H_3\\) and the \u0026ldquo;soft\u0026rdquo; component as \\(S_1\\). The overal score consists, then, of \\(S=\\{H_1, H_2, H_3, S_1 \\}\\)\n### Prediction distance\nThe first component of the score, 1 is established by sending the proposed counterfactual \\(x^{\\prime}\\), 8 to a predictive model, 9 and calculating the distance between the desired outcome, \\(y^{\\prime}\\) and the model\u0026rsquo;s prediction. This is done component wise, for each feature of the output. That is, for a prediction with \\(N\\) features, we calculate\n\\[ H_1=\\left(\\sum_i^Nf(x^{\\prime}_i) - y^{\\prime}_i\\right)^2 \\]\nTolerance For numerical features, the above score (\\(H_1\\)) will cause the counterfactual to be invalid, unless the distance between the outcomes and proposed values is exactly zero.\nWe can solve this problem by introducing a \u0026ldquo;tolerance\u0026rdquo; adjustment, which allows proposed values to be accepted if they are \u0026ldquo;close enough\u0026rdquo; to the goal.\nTo make the tolerance scale-invariant and unit-less we can use a relative change and set the distance to zero, if smaller than the threshold \\(t\\), that is\n\\[ d = \\begin{cases} 0,\u0026amp;\\qquad\\text{if}\\,\\frac{\\vert f(x\u0026rsquo;_i)-y\u0026rsquo;_i\\vert}{\\max(\\vert f(x\u0026rsquo;_i)\\vert,\\vert y\u0026rsquo;_i\\vert)} \u0026lt; t \\\\\\\\ \\vert f(x\u0026rsquo;_i)-y\u0026rsquo;_i\\vert,\u0026amp;\\qquad\\text{otherwise} \\end{cases} \\]\nand compare to the threshold \\(t\\). As an example, for a goal \\(y\u0026rsquo;_i=3\\) and a threshold of \\(t=0.01\\), around the goal we would have the distance as in the figure below:\n This would however fail for the edge case where \\(y^{\\prime}_i=0\\) as we can see below:\n To solve this, we can introduce a special case for \\(y^{\\prime}_i=0\\), such that:\n\\[ d_{g=0} = \\begin{cases} 0,\u0026amp;\\qquad \\text{if}\\ |f(x^{\\prime}_i)|\u0026lt; t\\\\\\\\ \\lVert f(x^{\\prime}_i) - y^{\\prime}_i \\rVert,\u0026amp;\\qquad\\text{otherwise} \\end{cases} \\]\nSo that we have now the desired behaviour at \\(y^{\\prime}_i=0\\):\n Gower distance An alternative metric for the outcome distance (and mixed variables in general) is the Gower distance.\nActionability score For the second component, the actionability score, 2. We calculate the number of features for the protected set \\(\\mathcal{A}\\), which have a different value from the original. That is, assuming we have a certain number of protectd features \\(M\\), such that \\(\\mathcal{A}=\\{A_1,A_2,\\dots,A_M\\}\\), we calculate:\n\\[ H_2 = \\sum_{a \\in \\mathcal{A}} \\mathbb{1}(x_a \\neq x^{\\prime}_a), \\]\nConfidence score For each feature \\(i\\), if we have a prediction confidence, \\(p_i(f(x^{\\prime}))\\), we calculate the number of features which have a confidence below a certain predefined threshold, \\(P_i\\). If the threshold is not defined, this component will always be zero and not influence the counterfactual selection. Assuming we have defined a threshold for all \\(N\\) features, \\(P = \\{P_1, P_2, \\dots, P_N\\}\\) we calculate this score as\n\\[ H_3 = \\sum_i^N \\mathbb{1} \\left( p_i \\left( f(x^{\\prime}) \u0026lt; P_i \\right) \\right) \\]\nFeature distance Considering that each datapoint \\(x\\) consists of different \\(N\\) features, such that \\(x=\\left(f_1,\\dots,f_n\\right)\\) and that each feature might be numerical or categorical[^categorical], we calculate the distance between a datapoint \\(x\\) and a potential counterfactual \\(x^{\\prime}\\):\n\\[ d\\left(x,x^{\\prime}\\right)=\\sum_{i=1}^Nd^{\\prime}\\left(x_i,x_i^{\\prime}\\right) \\] $$ dâ²\\left(x_i,x_iâ²\\right)=\n\\begin{cases} \\left(x_i-x_i^{\\prime}\\right)^2,\\quad\\text{if}\\ x_i,x_i^{\\prime}\\in\\mathbb{N} \\lor x_i,x_i^{\\prime}\\in\\mathbb{R}\\\\ 1-\\delta_{x,x^{\\prime}},\\quad\\text{if}\\ x_i,x_i^{\\prime}\\ \\text{categorical} \\end{cases}\n$$\nSince in many scenarios we might not have access to the training data, the above distance are not normalised. In the event that we do have access to training data, then we can use the standard deviation (\\(SD\\)) to normalise the features. The \\(SD\\) can be calculated as:\n\\[ SD=\\sqrt{\\frac{1}{N}\\sum_{i=1}^N\\left(x_i-\\bar{x}\\right)^2} \\]\nso that, in this case, we scale the numerical features with\n\\[ \\bar{d}^{\\prime}\\left(x_i,x_i^{\\prime}\\right)= \\frac{\\left(x_i-x_i^{\\prime}\\right)^2}{SD}. \\]\nSearching To search for a counterfactual, we start by specifying a search domain for each feature. This will include:\n An upper and lower bounds for numerical features, respectively \\(\\mathcal{D}_l, \\mathcal{D}_u\\) A set of categories for categorical features, \\(\\mathcal{C}\\) \\(\\mathcal{B}=\\{0,1\\}\\) for the specific case of boolean/binary values  Typically these values would be either established by someone with domain knowledge, or by values that might reflect our expectation for the actual counterfactual (for instance, an age would have realistic values).\nThe algorithm used for the search is Tabu search2 (Glover, 1989).\n   : c.f. https://docs.optaplanner.org/8.0.0.Final/optaplanner-javadoc/org/optaplanner/core/api/score/buildin/bendablebigdecimal/BendableBigDecimalScore.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n :  Glover, F. (1989). Tabu searchâpart i. ORSA Journal on computing, 1(3), 190â206.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/counterfactuals-with-constraint-solvers.html","tags":null,"title":"Counterfactuals with Constraint Solvers"},{"categories":null,"contents":"Installation Fedora To install Deno on Fedora, first download the installation file:\ncurl -fsSL https://deno.land/x/install/install.sh | sh And then add the following to your shell\u0026rsquo;s profile (e.g. ~/.bashrc):\nexport DENO_INSTALL=\u0026#34;/home/$USER/.deno\u0026#34; export PATH=\u0026#34;$DENO_INSTALL/bin:$PATH\u0026#34; Topis  Deno types  ","permalink":"https://ruivieira.dev/deno.html","tags":null,"title":"Deno"},{"categories":null,"contents":"Union types function add(a: any, b: any) { if (typeof a === \u0026#39;number\u0026#39; \u0026amp;\u0026amp; typeof b === \u0026#39;number\u0026#39;) { return a + b; } if (typeof a === \u0026#39;string\u0026#39; \u0026amp;\u0026amp; typeof b === \u0026#39;string\u0026#39;) { return a.concat(b); } throw new Error(\u0026#39;Parameters must be numbers or strings\u0026#39;); } return add(true, false); error: TS2345 [ERROR]: Argument of type \u0026lsquo;boolean\u0026rsquo; is not assignable to parameter of type \u0026lsquo;string | number\u0026rsquo;. console.log(add(true, false));})())));\nfunction add(a: number | string, b: number | string) { if (typeof a === \u0026#39;number\u0026#39; \u0026amp;\u0026amp; typeof b === \u0026#39;number\u0026#39;) { return a + b; } if (typeof a === \u0026#39;string\u0026#39; \u0026amp;\u0026amp; typeof b === \u0026#39;string\u0026#39;) { return a.concat(b); } throw new Error(\u0026#39;Parameters must be numbers or strings\u0026#39;); } return add(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;); ","permalink":"https://ruivieira.dev/deno-types.html","tags":null,"title":"Deno types"},{"categories":null,"contents":"Digital gardens are places where information grows.\nChallenges Chronological is the wrong metaphor, but how to capture time and sequence? As an example, have a Git commit hash as well as a recent changes history. Each page already display a commit hash to give it a context as well as a recently updated section in the index. The RSS 2.0 file also provides a temporal source of truth.\n","permalink":"https://ruivieira.dev/digital-garden.html","tags":null,"title":"Digital Garden Digital Garden"},{"categories":null,"contents":"L-p metrics Manhattan distance (L1) Given two vectors \\(p\\) and \\(q\\), such that\n\\begin{aligned} p \u0026amp;= \\left(p_1, p_2, \\dots,p_n\\right) \\\\ q \u0026amp;= \\left(q_1, q_2, \\dots,q_n\\right) \\end{aligned}\nwe define the Manhattan distance as:\n\\[ d_1(p, q) = \\|p - q\\|_1 = \\sum_{i=1}^n |p_i-q_i| \\]\nEuclidean distance (L2) In general, for points given by Cartesian coordinates in $n$-dimensional Euclidean space, the distance is\n\\[ d(p,q)=\\sqrt {(p_{1}-q_{1})^{2}+(p_{2}-q_{2})^{2}+\\cdots +(p_{i}-q_{i})^{2}+\\cdots +(p_{n}-q_{n})^{2}} \\]\nCluster distances Within-cluster sum of squares (WCSS) Given a set of observations (\\(x_1, x_2,\\dots,x_n\\)), where each observation is a $d$-dimensional real vector, $k$-means clustering aims to partition the \\(n\\) observations into \\(k\\) (\\(\\leq n\\)) sets \\(S=\\lbrace S_1, S_2, \\dots, S_k\\rbrace\\) so as to minimize the within-cluster sum of squares (WCSS) (i.e. variance). Formally, the objective is to find:\n\\[ {\\underset {\\mathbf {S} }{\\operatorname {arg\\,min} }}\\sum _{i=1}^{k}\\sum _{\\mathbf {x} \\in S_{i}}\\left\\|\\mathbf {x} -{\\boldsymbol {\\mu }}_{i}\\right\\|^{2}={\\underset {\\mathbf {S} }{\\operatorname {arg\\,min} }}\\sum _{i=1}^{k}|S_{i}|\\operatorname {Var} S_{i} \\]\nwhere \\(\\mu_i\\) is the mean of points in \\(S_i\\). This is equivalent to minimizing the pairwise squared deviations of points in the same cluster:\n\\[ {\\displaystyle {\\underset {\\mathbf {S} }{\\operatorname {arg\\,min} }}\\sum _{i=1}^{k}\\,{\\frac {1}{2|S_{i}|}}\\,\\sum _{\\mathbf {x} ,\\mathbf {y} \\in S_{i}}\\left\\|\\mathbf {x} -\\mathbf {y} \\right\\|^{2}} \\]\nThe equivalence can be deduced from identity\n\\[{\\displaystyle \\sum _{\\mathbf {x} \\in S_{i}}\\left\\|\\mathbf {x} -{\\boldsymbol {\\mu }}_{i}\\right\\|^{2}=\\sum _{\\mathbf {x} \\neq \\mathbf {y} \\in S_{i}}(\\mathbf {x} -{\\boldsymbol {\\mu }}_{i})({\\boldsymbol {\\mu }}_{i}-\\mathbf {y} )}. \\]\nBecause the total variance is constant, this is equivalent to maximizing the sum of squared deviations between points in different clusters (between-cluster sum of squares, BCSS) which follows from the law of total variance.\nDunn index A full explanation is available at Dunn index.\nGower distance A full explanation with examples is available at Gower distance.\n","permalink":"https://ruivieira.dev/distance-metrics.html","tags":null,"title":"Distance metrics"},{"categories":null,"contents":"Setup The following modules must be enabled in init.el:\n`(go +lsp)` in the `lang` section `lsp` in the `tools` section `snippets` in the `editor` section `gopls` should be installed.\nRunning `doom sync` will finish the setup.\n","permalink":"https://ruivieira.dev/doom-emacs.html","tags":null,"title":"DOOM Emacs"},{"categories":null,"contents":"Configuration is at the same time the most fun and biggest challenge of any Emacs installation. I think it\u0026rsquo;s a good time to recall Anthony Bourdainâs thoughts about mise en place.\n Mise-en-place is the religion of all good line cooks. Do not mess with a line cookâs âmeezâ â meaning his setup, his carefully arranged supplies of sea salt, rough-cracked pepper, softened butter, cooking oil, wine, backups, and so on. As a cook, your station, and its condition, its state of readiness, is an extension of your nervous systemâ¦ The universe is in order when your station is set up the way you like it: you know where to find everything with your eyes closed, everything you need during the course of the shift is at the ready at armâs reach, your defenses are deployed. If you let your mise-en-place run down, get dirty and disorganized, youâll quickly find yourself spinning in place and calling for backup. I worked with a chef who used to step behind the line to a dirty cookâs station in the middle of a rush to explain why the offending cook was falling behind. Heâd press his palm down on the cutting board, which was littered with peppercorns, spattered sauce, bits of parsley, bread crumbs and the usual flotsam and jetsam that accumulates quickly on a station if not constantly wiped away with a moist side towel. âYou see this?â heâd inquire, raising his palm so that the cook could see the bits of dirt and scraps sticking to his chefâs palm. âThatâs what the inside of your head looks like now.â\nâ Anthony Bourdain, from Kitchen Confidential.\n This an annotated version of my DOOM Emacs configuration. The source files can be found on Github or Sourcehut.\nLanguages Python virtualenv In order to use Python\u0026rsquo;s virtualenv, the virtualenvwrapper.el1 module is used. This is done by adding to packages.el\n(package! virtualenvwrapper) The only configuration I use for this library is setting my virtualenv root location in config.el\n(use-package! virtualenvwrapper) (after! virtualenvwrapper  (setq venv-location \u0026#34;~/.virtualenvs/\u0026#34;) ) From a Python project the virtual environment can be selected by using M-x venv-workon.\nBlack formatter To allow formatting of Python blocks in org-mode and elsewhere, add python-blackÂ 2 to packages.el.\n(package! python-black) Then we configure it with\n(use-package! python-black  :after python  :hook (python-mode . python-black-on-save-mode-enable-dwim)) We should install black-machiattoÂ 3 to allow formatting of partial regions.\nGo The following modules must be enabled in init.el:\n (go +lsp) in the lang section lsp in the tools section snippets in the editor section  gopls should be installed.\nTemplates To enable support of Go templates, install the lang/web packages by adding to init.el.\n(web +html) This will install the web-mode package4 To specify the sepcific template engine as Go M-x web-mode-set-engine to go.\nRunning doom sync will finish the setup.\nPikchr Support for Pikchr5 is added via the pikchr-mode package. By adding\n(package! pikchr-mode) It is necessary to install the pikchr binary according to the instructions in Pikchr. That page also contains examples.\nUI Prettify symbols Since Emacs 24.46 there is a builtin prettify-symbols-mode. It can be customized by changing prettify-symbols-alist. These strings will be replace by our selection, typically an unicode symbol. In this configuration we use the following:\n(defun my/pretty-symbols ()  (setq prettify-symbols-alist  \u0026#39;((\u0026#34;#+begin_src python\u0026#34; . \u0026#34;ð\u0026#34;)  (\u0026#34;#+begin_src elisp\u0026#34; . \u0026#34;Î»\u0026#34;)  (\u0026#34;#+begin_src jupyter-python\u0026#34; . \u0026#34;ð\u0026#34;)  (\u0026#34;#+end_src\u0026#34; . \u0026#34;â\u0026#34;)  (\u0026#34;#+results:\u0026#34; . \u0026#34;ð¨\u0026#34;)  (\u0026#34;#+RESULTS:\u0026#34; . \u0026#34;ð¨\u0026#34;)))) This will, for instance, replace the beginning of Python org-babel blocks with the single symbol. To register the prettify list with each mode we use\n(add-hook \u0026#39;org-mode-hook \u0026#39;my/pretty-symbols) Or we can register the prettify-symbols-mode as a global mode\n(global-prettify-symbols-mode +1) company company is great, but it can get in the way when using on org-mode buffers. To disable add the following:\n(after! org  ;; disable auto-complete in org-mode buffers  (remove-hook \u0026#39;org-mode-hook #\u0026#39;auto-fill-mode)  ;; disable company too  (setq company-global-modes \u0026#39;(not org-mode))  ;; ...  ) Beacon Beacon highlights the current cursor line after major movements. Especially useful for HDPi screens. Add it on packages.el:\n (package! beacon) And enable the global minor-mode on config.el with:\n ;; global beacon minor-mode  (use-package! beacon)  (after! beacon (beacon-mode 1)) Focus This mode relies on the Focus package that dims regions not on \u0026hellip; focus. Since the package is on MELPA, it can be installed by adding to packages.el:\n (package! focus) Next, require it from config.el\n (use-package! focus) And call it by setting the mode with M-x focus-mode.\nNavigation Treemacs treemacs7 is a great file navigation explorer for Emacs. However, since it has its own iternal concept of project, it needs an external helper to be able to synchronise with other project management tools, such as projectile.\nTo be able to synchronise treemacs and projectile the treemacs-projectile module must be used. It can be activated using\n(use-package treemacs-projectile  :after (treemacs projectile))  (after! (treemacs projectile)  (treemacs-project-follow-mode 1)) This guarantees that when moving to a buffer of a different projectile project, the treemacs tree will reflect that.\nDirvish Dirvish offers a suitable replacement/enhancement for dired with features such as improved UI and image preview. The only requirement for dirvish is the ls alternative exa It is available from MELPA which means you can add it to packages.el with\n(package! dirvish) and then enable it on config.el with\n(use-package! dirvish) Tools vterm An interesting talk on the advantages of using vterm as the default Emacs terminal emulator can be found can found at EmacsConf 2021 \u0026ldquo;A Tour of vterm\u0026rdquo;. To use vterm as the Emacs shell, the respective section in init.el should be selected:\n(doom!  :term  ;;eshell ; the elisp shell that works everywhere  ;;shell ; simple shell REPL for Emacs  ;;term ; basic terminal emulator for Emacs  vterm ; the best terminal emulation in Emacs ) We also need to install libvterm, with in macOS can be done with\nbrew install libvterm and in Linux with\n$ sudo apt-get install -y libvterm-dev # Ubuntu $ sudo dnf -y install libvterm # Fedora deadgrep For full-text search, deadgrep8 is used, which leverages ripgrep. To install ripgrep on Linux, run\n$ sudo apt install ripgrep # Ubuntu $ sudo dnf install ripgrep # Fedora   https://github.com/porterjamesj/virtualenvwrapper.el\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/emacs-vault/emacs-python-black\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/wbolster/black-macchiato\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://web-mode.org/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://pikchr.org/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.emacswiki.org/emacs/PrettySymbol\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/Alexander-Miller/treemacs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/Wilfred/deadgrep\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/doom-emacs.html","tags":null,"title":"DOOM Emacs"},{"categories":null,"contents":"There are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the Dunn index, Davis-Bouldin index and Silhoutte index.\nBut before we start, let\u0026rsquo;s introduce some concepts.\nWe are interested in clustering algorithms for a dataset \\(\\mathcal{D}\\) with \\(N\\) elements in a $n$-dimensional real space, that is:\n\\[ \\mathcal{D} = {x_1, x_2, \\ldots, x_N} \\in \\mathbb{R}^p \\]\nThe clustering algorithm will create a set \\(C\\) of \\(K\\) distinct disjoint groups from \\(\\mathcal{D}\\) \\(C={c_1, c_2, \\ldots, c_k}\\), such that:\n\\[ \\cup_{c_k\\in C}c_k=\\mathcal{D} \\\\ c_k \\cap c_l \\neq \\emptyset \\forall k\\neq l \\]\nEach group (or cluster) \\(c_k\\), will have a centroid, \\(\\bar{c}_k\\), which is the mean vector of its elements such that:\n\\[ \\bar{c}_k=\\frac{1}{|c_k|}\\sum_{x_i \\in c_k}x_i \\]\nWe will also make use of the dataset\u0026rsquo;s mean vector, \\(\\bar{\\mathcal{D}}\\), defined as:\n\\[ \\bar{\\mathcal{D}}=\\frac{1}{N}\\sum_{x_i \\in X}x_i \\]\nDunn index The Dunn index aims at quantifying the compactness and variance of the clustering. A cluster is considered compact if there is small variance between members of the cluster. This can be calculated using \\(\\Delta(c_k)\\), where\n\\[ \\Delta(c_k) = \\max_{x_i, x_j \\in c_k}{d_e(x_i, x_j)} \\]\nand \\(d_e\\) is the Euclidean distance defined as:\n\\[ d_e=\\sqrt{\\sum_{j=1}^p (x_{ij}-x_{kj})^2}. \\]\nA cluster is considered well separated if the cluster are far-apart. This can quantified using\n\\[ \\delta(c_k, c_l) = \\min_{x_i \\in c_k}\\min_{x_j\\in c_l}{d_e(x_i, x_j)}. \\]\nGiven these quantities, the Dunn index for a set of clusters \\(C\\), \\(DI( C)\\), is then defined by:\n\\[ DI( C)=\\frac{\\min_{c_k \\in C}{\\delta(c_k, c_l)}}{\\max_{c_k\\in C}\\Delta(c_k)} \\]\nA higher Dunn Index will indicate compact, well-separated clusters, while a lower index will indicate less compact or less well-separated clusters.\nWe can now try to calculate the metric for the dataset we\u0026rsquo;ve created previously. Let\u0026rsquo;s simulate some data and apply the Dunn index from scratch. First, we will create a compact and well-separated dataset using the make_blobs method in scikit-learn. We will create a dataset of \\(\\mathbb{R}^2\\) data (for easier plotting), with three clusters.\nfrom sklearn.datasets import make_blobs  X, y = make_blobs(n_samples=1000,  centers=3,  n_features=2,  random_state=23) import pandas as pd from plotnine import * from plotnine.data import * from plotutils import *  data = pd.DataFrame(X, columns=[\u0026#34;x1\u0026#34;, \u0026#34;x2\u0026#34;]) data[\u0026#34;y\u0026#34;] = y data[\u0026#34;y\u0026#34;] = data.y.astype(\u0026#39;category\u0026#39;)  ggplot(data=data) + \\  geom_point(mapping=aes(x=\u0026#34;x1\u0026#34;, y=\u0026#34;x2\u0026#34;, colour=\u0026#34;y\u0026#34;)) + \\  scale_color_manual(values=[colours[0], colours[1], colours[2]]) + \\  theme_classic() We now cluster the data[^2] and we will have, as expected three distinct clusters, plotted below.\nfrom sklearn import cluster  k_means = cluster.KMeans(n_clusters=3) k_means.fit(data) y_pred = k_means.predict(data)  prediction = pd.concat([data, pd.DataFrame(y_pred, columns=[\u0026#39;pred\u0026#39;])], axis = 1)  clus0 = prediction.loc[prediction.pred == 0] clus1 = prediction.loc[prediction.pred == 1] clus2 = prediction.loc[prediction.pred == 2] k_list = [clus0.values, clus1.values,clus2.values] Let\u0026rsquo;s focus now on two of these cluster, let\u0026rsquo;s call them \\(c_k\\) and \\(c_l\\).\nck = k_list[0] cl = k_list[1] We know we have to calculate the distance between the points in \\(c_k\\) and \\(c_l\\). We know that the `len(ck)=len(cl)=333` we create\nimport numpy as np  values = np.ones([len(ck), len(cl)]) values array([[1., 1., 1., ..., 1., 1., 1.],  [1., 1., 1., ..., 1., 1., 1.],  [1., 1., 1., ..., 1., 1., 1.],  ...,  [1., 1., 1., ..., 1., 1., 1.],  [1., 1., 1., ..., 1., 1., 1.],  [1., 1., 1., ..., 1., 1., 1.]]) For each pair of points, we then get the norm of \\(x_i-x_j\\). For instance, for \\(i=0\\in c_k\\) and \\(i=1\\in c_l\\), we would have:\nvalues[0, 1] = np.linalg.norm(ck[0]-cl[1]) print(ck[0], cl[1]) print(values[0, 1]) [-5.37039106 3.47555168 2. 0. ] [ 5.46312794 -3.08938807 1. 1. ] 12.746119711608184 The calculation of \\(\\delta(c_k, c_l)\\) between two clusters \\(c_k\\) and \\(c_l\\) will be defined as follows:\nimport numpy as np  def Î´(ck, cl):  values = np.ones([len(ck), len(cl)])  for i in range(0, len(ck)):  for j in range(0, len(cl)):  values[i, j] = np.linalg.norm(ck[i]-cl[j])  return np.min(values) So, for our two clusters above, \\(\\delta(c_k, c_l)\\) will be:\nÎ´(ck, cl) 8.13474311744193 Within a single cluster \\(c_k\\), we can calculate \\(\\Delta(c_k)\\) similarly as:\ndef Î(ci):  values = np.zeros([len(ci), len(ci)])  for i in range(0, len(ci)):  for j in range(0, len(ci)):  values[i, j] = np.linalg.norm(ci[i]-ci[j])  return np.max(values) So, for instance, for our \\(c_k\\) and \\(c_l\\) we would have:\nprint(Î(ck)) print(Î(cl)) 6.726025773561468 6.173844284636552 We can now define the Dunn index as\ndef dunn(k_list):  Î´s = np.ones([len(k_list), len(k_list)])  Îs = np.zeros([len(k_list), 1])  l_range = list(range(0, len(k_list)))  for k in l_range:  for l in (l_range[0:k]+l_range[k+1:]):  Î´s[k, l] = Î´(k_list[k], k_list[l])  Îs[k] = Î(k_list[k])  di = np.min(Î´s)/np.max(Îs)  return di and calculate the Dunn index for our clustered values list as\ndunn(k_list) 0.14867620697065728 Intuitively, we can expect a dataset with less well-defined clusters to have a lower Dunn index. Let\u0026rsquo;s try it. We first generate the new dataset.\nX, y = make_blobs(n_samples=1000,  centers=3,  n_features=2,  cluster_std=10.0,  random_state=24)  df = pd.DataFrame(X, columns=[\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;])  k_means = cluster.KMeans(n_clusters=3) k_means.fit(df)  #K-means training y_pred = k_means.predict(df)  prediction = pd.concat([df,pd.DataFrame(y_pred, columns=[\u0026#39;pred\u0026#39;])], axis = 1) prediction[\u0026#34;pred\u0026#34;] = prediction.pred.astype(\u0026#39;category\u0026#39;) ggplot(data=prediction) +\\ geom_point(mapping=aes(x=\u0026#34;A\u0026#34;, y=\u0026#34;B\u0026#34;, colour=\u0026#34;pred\u0026#34;)) + \\ scale_color_manual(values=[colours[0], colours[1], colours[2]]) + theme_classic()  \u0026lt;ggplot: (317671277)\u0026gt; clus0 = prediction.loc[prediction.pred == 0] clus1 = prediction.loc[prediction.pred == 1] clus2 = prediction.loc[prediction.pred == 2] k_list = [clus0.values, clus1.values,clus2.values] dunn(k_list) 0.019563892388205984 ","permalink":"https://ruivieira.dev/dunn-index.html","tags":null,"title":"Dunn index"},{"categories":null,"contents":"Elisp is the programming language used to program and configure Emacs.\nSome Elisp topics:\n Elisp snippets  ","permalink":"https://ruivieira.dev/elisp.html","tags":null,"title":"Elisp"},{"categories":null,"contents":"Snippets Execute command in shell buffer comint-send-string is the function we\u0026rsquo;re looking for.1\nIt takes a PROCESS and a STRING. You can get the process from the shell buffer, and conveniently the shell function returns the buffer, so you can streamline it all into something like:\n(defun my-server ()  \u0026#34;SSH to my.server.com in `shell\u0026#39;buffer.\u0026#34;  (interactive)  (comint-send-string  (get-buffer-process (shell))  \u0026#34;ssh my.server.com\\n\u0026#34;)) Where the (shell) call will take care of creating the shell buffer and/or process if necessary.2\nFree variables In some situations, for instance when setting a variable in a DOOM Emacs like\n(setq my/variable \u0026#34;value\u0026#34;) You might get the warning\nWarning: assignment to free variable `er/try-expand-list\u0026#39; This is because set and setq do not declare lexical variables3. The solution is to use4\n(defvar my/variable \u0026#34;value\u0026#34;) Lists to arrays List of lists To convert a list of lists, e.g.\n (defvar mylist ((\u0026#34;1\u0026#34; \u0026#34;a\u0026#34;) (\u0026#34;2\u0026#34; \u0026#34;b\u0026#34;) (\u0026#34;3\u0026#34; \u0026#34;c\u0026#34;))) The method to convert a single element from the list is\n (require \u0026#39;cl)  (coerce (nth 0 mylist) \u0026#39;vector)  ;; [\u0026#34;1\u0026#34; \u0026#34;a\u0026#34;] We now just need to map this for all the list\n (mapcar (lambda (arg) (coerce arg \u0026#39;vector)) mylist) Reference defcustom You can specify variables using defcustom so that you and others can then use Emacsâs customize feature to set their values. (You cannot use customize to write function definitions; but you can write defuns in your .emacs file. Indeed, you can write any Lisp expression in your .emacs file.)5\nSQLite Emacs provides functionality to interact with SQLite databases. For these examples we will use the emacSQL package. To open a database file /tmp/foo.sqlite we issue:\n (defvar db (emacsql-sqlite \u0026#34;~/tmp/foo.sqlite\u0026#34;)) We can then issue SELECT statements with\n ;; Query the database for results:  (emacsql db [:select [name id]  :from people  :where (\u0026gt; salary 62000)])  ;; =\u0026gt; ((\u0026#34;Susan\u0026#34; 1001))   shell is built on top of the comint library.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n n.b. if there\u0026rsquo;s an existing one, shell will re-use that.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Only let does.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n But not quote the symbol.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n The docs for defcustom: https://www.gnu.org/software/emacs/manual/html%5Fnode/eintr/defcustom.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/elisp-snippets.html","tags":null,"title":"Elisp snippets"},{"categories":null,"contents":"Notes on Emacs My current flavour/distribution of Emacs is DOOM Emacs spacemacs DOOM Emacs. Yes, DOOM Emacs is my preferred configuration framework at the moment. I have used Spacemacs for a long time, but the performance increase by switching to DOOM Emacs is simply to great to be ignored. Recently, I have also migrated to the Emacs 28 branch which includes Elisp native compilation. It is a thing of beauty in terms of speed.\nThis page refers to broad Emacs base configuration. For specific Emacs recipes check the Emacs cookbook.\nInstallation macOS Many people swear by emacs-mac as the gold standard for macOS Emacs distributions. To install it, using homebrew simply run\n$ brew tap railwaycat/emacsmacport $ brew install --cask emacs-mac-spacemacs-icon Alternatively, you can choose whatever icon you want from here. A good alternative is for instance --with-emacs-big-sur-icon. On Linux you can use my icon, if you wish.\nHowever, emacs-mac is, at the time of writing, targetting Emacs 27. If you want to use Emacs 28 (and don\u0026rsquo;t want to build it from source) a good option if emacs-plus. To install it use:\n$ brew install emacs-plus@28 --with-native-comp --with-modern-doom3-icon Fedora At the time of writing1, Fedora only supports, officially, Emacs 27. If you want to try Emacs 28 (and the native compilation feature) you need to install it using\n$ sudo dnf copr enable deathwish/emacs-pgtk-nativecomp and then (if Emacs is already present)\n$ sudo dnf upgrade emacs otherwise run\n$ sudo dnf install emacs Ubuntu For Ubuntu (and other Linux distros, including Fedora) an option is to use the Snap store. The available Snap can install Emacs 28 with native compilation enabled. To use it, simply run\n$ sudo snap install emacs --edge --classic From source In December 2021 the pgtk branch of Emacs was merged into master2. Among other features this adds full Wayland support and better font rendering for the Emacs GUI. This version can be compiled from source with just a few simple steps.\nDependencies To build this version in Linux (I\u0026rsquo;m assuming Ubuntu and variants) you will need the following dependencies:\n autoconf build-essential, provides GCC, make, libc, etc. libgtk-3-dev, Gnome dependencies libgnutls28-dev, provides libgnutls28 libtiff5-dev, libgif-dev, libjpeg-dev, libpng-dev and libxpm-dev provide image support libncurses-dev, provides terminal support texinfo, for Info documentation  I also wanted to include Emacs\u0026rsquo; native JSON support and Elisp native compilation, so will additionally need:\n libjansson4, libjansson-dev, provides native JSON support libgccjit0, libgccjit-10-dev, gcc-10 and g++-10  A one-liner to install all dependencies is:\n$ sudo apt update $ sudo apt install build-essential libgtk-3-dev libgnutls28-dev \\  libtiff5-dev libgif-dev libjpeg-dev libpng-dev libxpm-dev \\  libncurses-dev texinfo \\  libjansson4 libjansson-dev \\  libgccjit0 libgccjit-10-dev gcc-10 g++-10 Building We can then clone the Emacs repo and run autogen:\n$ sudo apt update $ git clone git://git.sv.gnu.org/emacs.git $ cd emacs $ ./autogen.sh To use native Elisp compilation we will use gcc-10, so before starting the build run:\n $ export CC=/usr/bin/gcc-10 CXX=/usr/bin/gcc-10 Emacs supports --with-xxx to enable support for feature xxx, which in our case will be:\n --with-pgtk, native GTK support --with-json, native JSON support --with-native-compilation, native compilation support  So we can run the configure script with\n$ ./configure --with-native-compilation --with-json --with-pgtk We can now start the build and installation (you can choose the approriate number for your machine for the parallel run, in this case `8`):\n$ make -j8 $ sudo make install If everything completes successfully you should have emacs 29 available in /usr/local/bin\n$ emacs --version  GNU Emacs 29.0.50 Copyright (C) 2021 Free Software Foundation, Inc. GNU Emacs comes with ABSOLUTELY NO WARRANTY. You may redistribute copies of GNU Emacs under the terms of the GNU General Public License. For more information about these matters, see the file named COPYING. Configuration  Annotated DOOM Emacs config  Completion I recently move from helm3 to ivy. The main reason is that apparently helm development has stalled.\nThe important stuff? Icon I\u0026rsquo;ve also made a vaporwave Emacs icon which you can find in here.\n Cursor A cursor should blink, in my opinion. For a history of the blinking cursor see The Forgotten History of the Blinking Cursor. You can instruct Emacs to blink it with the appropriate mode4.\n(blink-cursor-mode 1) Themes An excellent resource for Emacs themes is Peach MELPA. Some selected theme are below.\nHere is a list of good themes for Emacs:\n zenburn ample alect cyberpunk gruvbox  The theme that I\u0026rsquo;m currently using is spacemacs-light. It works really well the new org-mode styling. A more detailed rundown of the specific theming can be found at DOOM Emacs.\nElisp  The main page for Elisp You can check my solutions for the Euler project in Elisp: Project Euler in Elisp  Command line Running org files   Fedora 32/33.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://mail.gnu.org/archive/html/emacs-devel/2021-12/msg01732.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n The main Helm maintainer is Thierry Volpiatto.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.emacswiki.org/emacs/NonBlinkingCursor\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/emacs.html","tags":null,"title":"Emacs"},{"categories":null,"contents":"Ordering JSON by key value Run json-pretty-print-buffer-ordered1\nProjects Creating a projectile project To create a projectile project either use a valid Git repository or create the special .projectile file in root.\nFuzzy search Do a SPC p f, but make sure the projectile project is created.\nSplit screen The standard Emacs keys are valid here (even for Spacemacs).\n SPC w h  Indent a block of text Select the block with V and then press Ctrl-x TAB. Then use h or l to move it along\n  If using spacemacs, it requires the Javascript layer\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/emacs-cookbook.html","tags":null,"title":"Emacs cookbook"},{"categories":null,"contents":"An Emacs package for Quarkus.\n","permalink":"https://ruivieira.dev/emacs-quarkus.html","tags":null,"title":"Emacs Quarkus"},{"categories":null,"contents":" Root Mean Squared Error  ","permalink":"https://ruivieira.dev/error-metrics.html","tags":null,"title":"Error metrics"},{"categories":null,"contents":"Topics Counterfactuals  Counterfactuals with Constraint Solvers  Fairness  Counterfactual Fairness (also how to create counterfactually fair models [Counterfactual Fairness in Java|in Java]])  Resources  TrustyAI Explainability Toolkit1 pre-print, https://arxiv.org/abs/2104.12717 A nice presentation on AI/ML explainability: https://explainml-tutorial.github.io/neurips20  Literature  Kakogeorgiou, Ioannis, and Konstantinos Karantzalos. \u0026ldquo;Evaluating Explainable Artificial Intelligence Methods for Multi-label Deep Learning Classification Tasks in Remote Sensing.\u0026rdquo; arXiv preprint arXiv:2104.01375 (2021).    : Geada, Rob, Tommaso Teofili, Rui Vieira, Rebecca Whitworth and Daniele Zonca. âTrustyAI Explainability Toolkit.â (2021).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/explainability.html","tags":null,"title":"Explainability"},{"categories":null,"contents":"Summary ","permalink":"https://ruivieira.dev/extending-junit.html","tags":null,"title":"Extending JUnit"},{"categories":null,"contents":"","permalink":"https://ruivieira.dev/feature-scaling.html","tags":null,"title":"Feature scaling"},{"categories":null,"contents":"A recommended graphical Gemini browser is Lagrange or Amfora for a text-based/terminal browser.\nSyntax Gemini syntax is quite similar to Markdown\nSetup Using the agate server\n","permalink":"https://ruivieira.dev/gemini.html","tags":null,"title":"Gemini"},{"categories":null,"contents":"Introduction This is a page containing the topics for Git1.\n Git cookbook    https://git-scm.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/git.html","tags":null,"title":"Git"},{"categories":null,"contents":"Tree Truncate history To truncate [[Git]] history, that is discard all commits before a specific one, you can do the following. Assume I have a commit with a certain hash, say abc123, and want to drop all commits before this one. Create a new orphan branch (name not important) called, say, truncated.\n$ git checkout --orphan truncated abc123 And then rebase master (or any other main branch) on top of truncated.\n$ git commit -m \u0026#34;Truncate history\u0026#34; $ git rebase --onto truncated abc123 master Your new branch truncated will be free of master history.\nHooks pre-push The pre-push script is called by git push, when the push actually happens. If the exit status is 0, then the push will proceed, otherwise it will be stopped.\nThe script is supplied with the following arguments:\n$1 -- Name of the remote to which the push is being done (Ex: origin) $2 -- URL to which the push is being done (Ex: https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;username\u0026gt;/\u0026lt;project_name\u0026gt;.git) Information about the commits which are being pushed is supplied as lines to the standard input in the form:\n\u0026lt;local_ref\u0026gt; \u0026lt;local_sha1\u0026gt; \u0026lt;remote_ref\u0026gt; \u0026lt;remote_sha1\u0026gt; Sample values:\nlocal_ref = refs/heads/master local_sha1 = 68a07ee4f6af8271dc40caae6cc23f283122ed11 remote_ref = refs/heads/master remote_sha1 = efd4d512f34b11e3cf5c12433bbedd4b1532716f ","permalink":"https://ruivieira.dev/git-cookbook.html","tags":null,"title":"Git cookbook"},{"categories":null,"contents":"Some notes regarding the Go language. Some topics have graduated to their own page:\n Go resource bundling Go filesystem operations  Setup First things first. How to install the Go language in different OSes.\nFedora You can either use dnf directly and simply run\n$ sudo dnf install golang-bin This might not install the latest and greatest. If you want to use the most recent version, download it directly from https://golang.org/doc/install#install. If applicable, delete any previous /usr/local/go directory with\n$ sudo rm -rf /usr/local/go Next, extract the archive file with\n$ sudo tar -C /usr/local -xzf /home/foo/tmp/go-$VERSION.linux-amd64.tar.gz And add /usr/local/go/bin to the $PATH.\nmacOS The best way to perform an attended installation of Go in macOS is to simply download the installer from https://go.dev/dl/ and running it.\nLanguage design Go doesn\u0026rsquo;t have sets The Go language, notoriously, does not have1 some common data structures like sets. There are two main reasons for that:\n Go does not have generics12 Go relies on you writing your own data structures, generally  Go lacks generics, which prevent writing a \u0026hellip; well, generic and efficient set implementation. Also, writing your own (non-generic) set with ~map~s is quite straight-forward.2 The usual structure for a type T is map[T]bool, where the key is the element and the value is just a placeholder. For instance, for a int set, we can add elements:\n s := map[int]bool{1: true, 3: true}  s[1] = true // already presenvar t  s[2] = true // adds new element Set union set_1 := map[int]bool{1:true, 2:true, 3:false} set_2 := map[int]bool{1:false, 2:false, 4:false} set_union := map[int]bool{}  for k, _ := range set_1{  set_union[k] = true } for k, _ := range set_2{  set_union[k] = true } fmt.Println(set_union) Set intersection set_1 := map[int]bool{1:true, 2:true, 3:false} set_2 := map[int]bool{1:false, 2:false, 4:false} set_intersection := map[int]bool{} for k,_ := range set_1 {  if set_2[k] {  set_intersection[k] = true  } } fmt.Println(set_intersection) Set to array To convert a (map) set to an array:\narray := make([]int, 0) set_1 := map[int]bool{1:true, 2:true, 3:false}  for k := range set_1 {  array = append(array, k) } fmt.Println(array) CI GitHub A potential workflow for GitHub is to use GitHub Actions for Go. An example workflow file, .github/workflows/test.yml, which runs go test (see Testing in Go) and go vet is:\non:[push, pull_request\\]name:Testjobs:test:strategy:matrix:go-version:[1.14.x, 1.15.x]os:[ubuntu-latest]runs-on:${{ matrix.os }}steps:- name:Install Gouses:actions/setup-go@v2with:go-version:${{ matrix.go-version }}- name:Checkout codeuses:actions/checkout@v2- name:Testrun:go test ./...- name:Vetrun:go vet ./...Containers Minimal example A minimal example of a Go container configuration for a web server running on port 8080:\n# Start from the latest golang base imageFROMgolang:latest# Add Maintainer InfoLABEL maintainer=\u0026#34;Rui Vieira\u0026#34;# Set the Current Working Directory inside the containerWORKDIR/app# Copy go mod and sum filesCOPY go.mod go.sum ./# Download all dependencies. Dependencies will be cached if the go.mod and go.sum files are not changedRUN go mod download# Copy the source from the current directory to the Working Directory inside the containerCOPY . .# Build the Go appRUN go build -o main .# Expose port 8080 to the outside worldEXPOSE8080# Command to run the executableCMD [\u0026#34;./main\u0026#34;]Reference Conversions    How to convert a string to byte array?\nThe conversion is simple:\n b := []byte(\u0026#34;This is a string\u0026#34;)   Collections    Sort map keys alphabetically\nIf a map contains string keys, i.e. var myMap map[string]T, we must sort the map keys independently. For instance:\nkeys := make([]string, 0) for k, _ := range myMap {  keys = append(keys, k) } sort.Strings(keys) for _, k := range keys {  fmt.Println(k, myMap[k]) }      Check for element\nIf we consider a collection, say, []string collection, the way to check for an element already present is, for instance:\nfunc existsIn(needle string, haystack []string) bool {  for _, element := range haystack {  if element == needle {  return true  }  }  return false }   Templates    Check if variable empty\nIn a Go template you check if a variable is empty by doing:\n{{if .Items}} \u0026lt;ul\u0026gt;  {{range .Items}}  \u0026lt;li\u0026gt;{{.Name}}\u0026lt;/li\u0026gt;  {{end}} \u0026lt;/ul\u0026gt; {{end}}      Looping over a map\nLooping over the map var data map[string]bool in a Go template:\n{{range $index, $element := .}} {{$index}}: {{$element}} {{end}}   Processes    Executing external processes\nExecuting an external process and directing input and output to Stdout and Stderr.\n cmd := exec.Command(\u0026#34;ls\u0026#34;, \u0026#34;-1ao\u0026#34;)  cmd.Stdout = os.Stdout  cmd.Stderr = os.Stderr  err := cmd.Run()  if err != nil { \tlog.Fatalf(\u0026#34;cmd.Run() failed with %s\\\\n\u0026#34;, err)  }   Testing in Go Place the tests in your place of choosing, but keep the package declaration. Test functions should be parameterised as (t *testing.T) and start with the prefix Test, for instance:\npackage main  func TestFoo(t *testing.T) { \tvalue := Foo(5, 5) \t// ... assertions The test files themselves must have the suffix *_test.go. Call the tests with go test.\nOutput    Printing struct keys\nTo print a struct along with its keys, we can use the Printf switch as in the official documentation. That is,\nfmt.Printf(\u0026#34;%+v\\n\u0026#34;, myStruct)   Date and time    Check if a date is empty\nIf a date is unassigned, the .IsZero() method can be used to check it\na := time.Time{} a.IsZero() // This will be true     As of the time of writing, that is Go 1.15.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Go indeed has generics starting with 1.18.\nSome other techniques for maps replacing sets:\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/go.html","tags":null,"title":"Go"},{"categories":null,"contents":"Notes on Go filesystem operations.\nCopying files Go does not have an utility method to copy files. We have to rely on writing our own implementation using the reading and writing functionality in other packages. As an example:\npackage main  import ( \t\u0026#34;io\u0026#34; \t\u0026#34;log\u0026#34; \t\u0026#34;os\u0026#34; )  func main() { \tfrom, err := os.Open(\u0026#34;./foo.txt\u0026#34;) \tif err != nil { \tlog.Fatal(err) \t} \tdefer from.Close()  \tto, err := os.OpenFile(\u0026#34;./bar.txt\u0026#34;, os.O_RDWR|os.O_CREATE, 0666) \tif err != nil { \tlog.Fatal(err) \t} \tdefer to.Close()  \t_, err = io.Copy(to, from) \tif err != nil { \tlog.Fatal(err) \t} } Path operations Basepath To get the basepath of a path string we use the Dir method:\nfilepath.Dir(\u0026#34;/etc/foo/file.txt\u0026#34;) // \u0026#34;/etc/foo\u0026#34; Check if directory exists if _, err := os.Stat(\u0026#34;/etc/foo/\u0026#34;); os.IsNotExist(err) { \t// do something because it does not exist } Create nested directories Use MkdirAll:\nos.MkdirAll(\u0026#34;/etc/long/nested/path/to/create\u0026#34;, os.ModePerm) ","permalink":"https://ruivieira.dev/go-filesystem-operations.html","tags":null,"title":"Go filesystem operations"},{"categories":null,"contents":"Notes on the installation and usage of pkger.\nInstallation done with\ngo get github.com/markbates/pkger/cmd/pkger pkger works by bundling the resources with a code-generated pkg.go. The configuration of assets to be bundled is done by reflection at compile time and not direct configuration. This is done by replacing standard Go file operations with pkger proxy ones, such as:\ntype Pkger interface {  Parse(p string) (Path, error)  Current() (here.Info, error)  Info(p string) (here.Info, error)  Create(name string) (File, error)  MkdirAll(p string, perm os.FileMode) error  Open(name string) (File, error)  Stat(name string) (os.FileInfo, error)  Walk(p string, wf filepath.WalkFunc) error  Remove(name string) error  RemoveAll(path string) error } type File interface {  Close() error  Info() here.Info  Name() string  Open(name string) (http.File, error)  Path() Path  Read(p []byte) (int, error)  Readdir(count int) ([]os.FileInfo, error)  Seek(offset int64, whence int) (int64, error)  Stat() (os.FileInfo, error)  Write(b []byte) (int, error) } Example Bundling a Go template file.\ntmplFile, _ := pkger.Open(\u0026#34;/templates/page.tmpl\u0026#34;) tmplBytes, _ := ioutil.ReadAll(tmplFile) tmplString := string(tmplBytes)  tpl, err := template.New(\u0026#34;page\u0026#34;).Parse(tmplString) _ = tpl.Execute(f, ...) The bundling is simply done by running\npkger and building as usual\ngo build ","permalink":"https://ruivieira.dev/go-resource-bundling.html","tags":null,"title":"Go resource bundling"},{"categories":null,"contents":"For features \\(x_i=\\{x_{i1},\\dots,x_{ip}\\}\\) and \\(x_j=\\{x_{j1},\\dots,x_{jp}\\}\\), the Gower similarity matrixÂ 1 can be defined as\n\\[ S_{\\text{Gower}}(x_i, x_j) = \\frac{\\sum_{k=1}^p s_{ijk}\\delta_{ijk}}{\\sum_{k=1}^p \\delta_{ijk}}. \\]\nFor each feature \\(k=1,\\dots,p\\) a score \\(s_{ijk}\\) is calculated. A quantity \\(\\delta_{ijk}\\) is also calculated having possible values \\(\\{0,1\\}\\) depending on whether the variables \\(x_i\\) and \\(x_j\\) can be compared or not (e.g. if they have different types).\nA special case2 for when no missing values exist can be formulated as the mean of the Gower similarity scores, that is:\n\\[ S_{\\text{Gower}}(x_i, x_j) = \\frac{\\sum_{k=1}^p s_{ijk}}{p}. \\]\nThe score \\(s_{ijk}\\) calculation will depend on the type of variable and below we will see some examples.\nThis similarity score will take values between \\(0 \\leq s_{ijk} \\leq 1\\) with \\(0\\) representing maximum similarity and \\(1\\) no similarity.\nScoring Numerical variables For numerical variables the score can be calculated as\n\\[ s_{ijk} = 1 - \\frac{|x_{ik}-x_{jk}|}{R_k}. \\]\nThis is simply a L1 distance between the two values normalised by a quantity \\(R_k\\). The quantity \\(R_k\\) refers to the range of feature (population or sample).\nCategorical variables For categorical variables we will use following score:\n\\[ s_{ijk} = 1\\{x_{ik}=x_{jk}\\} \\]\nThis score will be \\(1\\) if the categories are the same and \\(0\\) if they are not.\nIn reality the score \\(S_{\\text{Gower}}(x_i, x_j)\\) will be a similarity score taking values between \\(1\\) (for equal points) and \\(0\\) for extremely dissimilar points. In order to turn this value into a distance metric we can convert it using (for instance)\n\\[ d_{\\text{Gower}} = \\sqrt{1-S_{\\text{Gower}}}. \\]\nThis will take values of \\(1\\) for the furthest points and \\(0\\) for the same points.\nExample Here we will use the special case when no missing values exist. A test dataset can be:\nimport pandas as pd  df = pd.DataFrame({  \u0026#34;Sex1\u0026#34;: [\u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;],  \u0026#34;Sex2\u0026#34;: [\u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;],  \u0026#34;Age1\u0026#34;: [15, 15, 15, 15, 15, 15, 15, 15, 15, 15],  \u0026#34;Age2\u0026#34;: [15, 36, 58, 78, 100, 15, 36, 58, 78, 100] }) df  Sex1 Sex2 Age1 Age2 0 M M 15 15 1 M M 15 36 2 F F 15 58 3 F F 15 78 4 F F 15 100 5 M F 15 15 6 M F 15 36 7 F M 15 58 8 F M 15 78 9 F M 15 100 For the numerical variable (age) we can define the range as \\(R_{\\text{age}}=\\left(\\max{\\text{age}}-\\min{\\text{age}}\\right)\\).\nage_min = df[[\u0026#34;Age1\u0026#34;, \u0026#34;Age2\u0026#34;]].min().min() age_max = df[[\u0026#34;Age1\u0026#34;, \u0026#34;Age2\u0026#34;]].max().max() R_age = age_max - age_min We can now calculate the score for each numerical field\ndef s_numeric(x1, x2, R):  return 1 - abs(x1-x2)/R df[\u0026#39;s_age\u0026#39;] = df.apply(lambda x: s_numeric(x[\u0026#39;Age1\u0026#39;], x[\u0026#39;Age2\u0026#39;], R_age), axis=1) df  Sex1 Sex2 Age1 Age2 s_age 0 M M 15 15 1.000 1 M M 15 36 0.753 2 F F 15 58 0.494 3 F F 15 78 0.259 4 F F 15 100 0.000 5 M F 15 15 1.000 6 M F 15 36 0.753 7 F M 15 58 0.494 8 F M 15 78 0.259 9 F M 15 100 0.000 For categorical variables we can define the following score function:\ndef s_categorical(x1, x2):  return 1 if x1==x2 else 0 df[\u0026#39;s_sex\u0026#39;] = df.apply(lambda x: s_categorical(x[\u0026#39;Sex1\u0026#39;], x[\u0026#39;Sex2\u0026#39;]), axis=1) df  Sex1 Sex2 Age1 Age2 s_age s_sex 0 M M 15 15 1.000 1 1 M M 15 36 0.753 1 2 F F 15 58 0.494 1 3 F F 15 78 0.259 1 4 F F 15 100 0.000 1 5 M F 15 15 1.000 0 6 M F 15 36 0.753 0 7 F M 15 58 0.494 0 8 F M 15 78 0.259 0 9 F M 15 100 0.000 0 We can now calculate the final score using\nimport math  df[\u0026#39;s\u0026#39;] = df.apply(lambda x: (x[\u0026#39;s_age\u0026#39;] + x[\u0026#39;s_sex\u0026#39;])/2.0, axis=1) df[\u0026#39;d\u0026#39;] = df.apply(lambda x: math.sqrt(1.0 - x[\u0026#39;s\u0026#39;]), axis=1) df  Sex1 Sex2 Age1 Age2 s_age s_sex s d 0 M M 15 15 1.000 1 1.000 0.000 1 M M 15 36 0.753 1 0.876 0.351 2 F F 15 58 0.494 1 0.747 0.503 3 F F 15 78 0.259 1 0.629 0.609 4 F F 15 100 0.000 1 0.500 0.707 5 M F 15 15 1.000 0 0.500 0.707 6 M F 15 36 0.753 0 0.376 0.790 7 F M 15 58 0.494 0 0.247 0.868 8 F M 15 78 0.259 0 0.129 0.933 9 F M 15 100 0.000 0 0.000 1.000 Range impact Varying bounds Let\u0026rsquo;s visualise how the choice of range can affect the scoring, if can set it arbitrarily. First let\u0026rsquo;s pick two random points, \\(x_1=(30, M)\\) and \\(x_2=(35, F)\\).\nWe will vary the bounds from a \\(15\\leq x_{min}\u0026lt;30\\) and \\(35\u0026lt; x_{max} \\leq 100\\).\ndef score(x1, x2, R):  s_0 = 1-abs(x1[0]-x2[0])/R  s_1 = 1 if x1[1]==x2[1] else 0  return (s_0 + s_1)/2.0  def distance(s):  return math.sqrt(1.0-s) import numpy as np  x1 = (30, \u0026#39;M\u0026#39;) x2 = (35, \u0026#39;F\u0026#39;) bmin = np.linspace(15, 30, num=1000) bmax = np.linspace(36, 100, num=1000) scores_min = [distance(score(x1, x2, 100-bm)) for bm in bmin] scores_max = [distance(score(x1, x2, bm-15)) for bm in bmax]  Let\u0026rsquo;s try with more separated points\nx1 = (16, \u0026#39;M\u0026#39;) x2 = (90, \u0026#39;F\u0026#39;) bmin = np.linspace(15, 16, num=1000, endpoint=False) bmax = np.linspace(91, 100, num=1000) scores_min = [distance(score(x1, x2, 100-bm)) for bm in bmin] scores_max = [distance(score(x1, x2, bm-16)) for bm in bmax]  Varying range directly We will now try to see how the distance between two point comparisons (very close, very far) changes when varying the range directly. We will choose two sets of points, \\(x_1=(1000, M), x_2=(1001, F)\\) and \\(x_1=(500, M), x_2=(50000, F)\\). The range will vary between\n\\[ \\max(x_1, x_2)-\\min(x_1, x_2)\u0026lt;R\u0026lt;100000. \\]\nWe are also interested on the weight the categorical variable will have on the final distance with varying bounds, so we will also calculate them for an alternative \\(x_2\u0026rsquo;=(1001, M)\\) anf \\(x_2\u0026rsquo;=(50000, M)\\).\nFor the first set of points we will have:\nx1 = (1000.0, \u0026#39;M\u0026#39;) x2 = (1001.0, \u0026#39;F\u0026#39;) MAX_RANGE = 100000 R = np.linspace(max(x1[0], x2[0])-min(x1[0], x2[0]), MAX_RANGE, num=100000)  distances_M = [distance(score(x1, x2, i)) for i in R] distances_F = [distance(score(x1, (x2[0], \u0026#39;M\u0026#39;), i)) for i in R]  And for far away points we will have:\nx1 = (500.0, \u0026#39;M\u0026#39;) x2 = (50000.0, \u0026#39;F\u0026#39;) MAX_RANGE = 100000 R = np.linspace(max(x1[0], x2[0])-min(x1[0], x2[0]), MAX_RANGE, num=100000)  distances_M = [distance(score(x1, x2, i)) for i in R] distances_F = [distance(score(x1, (x2[0], \u0026#39;M\u0026#39;), i)) for i in R]  Categorical impact Predictably, in the scenario where we calculate the mean of the Gower distances, for a point \\(x\\) with \\(p\\) features, \\(x=(x_{1},\\dots,x_{p})\\), the contribution to the final distance of a categorial variable will be either \\(0\\) or \\(1/p\\), regardless of the range.\nMissing range For the previous examples the range \\(R\\) was available, but how to calculate the mixed distance when the numerical range is absent?\nA possible way is to use scale each feature using unit scaling:\n\\[ f_u(x) = \\frac{x}{||x||} \\]\nWe will visualise how a difference varying from \\(-1000 \\leq \\delta \\leq 1000\\) varies with the \\(f_u(\\delta)\\) transformation.\ndef f_unit(x):  return np.exp(x)/(np.exp(x)+1.0) def ilogit(eta):  return 1.0 - 1.0/(np.exp(eta)+1)  delta = np.linspace(-10, 10, num=20000) transformed = [ilogit(abs(x)) for x in delta]  ax = sns.scatterplot(delta, transformed) ax.set(xlabel=\u0026#34;Range\u0026#34;, ylabel=\u0026#34;Distance\u0026#34;,  title=\u0026#34;Gower distance\\nfor varying range (far away points)\u0026#34;) # ax.set(ylim=(0, 1), xscale=\u0026#34;log\u0026#34;) plt.show() transformed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0.9999546021312976 0.9999545567105143 0.9999545112442892 0.9999544657325772 0.9999544201753325 0.9999543745725097 0.9999543289240632 0.9999542832299472 0.9999542374901161 0.9999541917045244 0.9999541458731259 0.999954099995875 0.999954054072726 0.9999540081036327 0.9999539620885493 0.9999539160274296 0.9999538699202277 0.9999538237668976 0.999953777567393 0.9999537313216678 0.9999536850296756 0.9999536386913703 0.9999535923067056 0.9999535458756348 0.9999534993981118 0.9999534528740901 0.999953406303523 0.9999533596863641 0.9999533130225668 0.9999532663120844 0.99995321955487 0.9999531727508773 0.9999531259000591 0.9999530790023687 0.9999530320577592 0.9999529850661837 0.9999529380275952 0.9999528909419467 0.999952843809191 0.9999527966292812 0.9999527494021698 0.9999527021278098 0.999952654806154 0.999952607437155 0.9999525600207654 0.9999525125569378 0.9999524650456248 0.9999524174867789 0.9999523698803524 0.9999523222262979 0.9999522745245677 0.9999522267751141 0.9999521789778892 0.9999521311328455 0.9999520832399349 0.9999520352991097 0.999951987310322 0.9999519392735235 0.9999518911886666 0.9999518430557028 0.9999517948745844 0.9999517466452629 0.9999516983676903 0.9999516500418181 0.9999516016675982 0.9999515532449822 0.9999515047739215 0.9999514562543679 0.9999514076862727 0.9999513590695874 0.9999513104042634 0.9999512616902521 0.9999512129275047 0.9999511641159725 0.9999511152556066 0.9999510663463583 0.9999510173881787 0.9999509683810187 0.9999509193248294 0.9999508702195617 0.9999508210651666 0.999950771861595 0.9999507226087975 0.9999506733067249 0.9999506239553281 0.9999505745545575 0.9999505251043639 0.9999504756046977 0.9999504260555097 0.99995037645675 0.9999503268083693 0.9999502771103177 0.9999502273625458 0.9999501775650036 0.9999501277176415 0.9999500778204096 0.9999500278732579 0.9999499778761366 0.9999499278289957 0.9999498777317851 0.9999498275844548 0.9999497773869547 0.9999497271392344 0.9999496768412438 0.9999496264929326 0.9999495760942505 0.999949525645147 0.9999494751455719 0.9999494245954744 0.9999493739948041 0.9999493233435105 0.9999492726415429 0.9999492218888505 0.9999491710853827 0.9999491202310886 0.9999490693259174 0.9999490183698183 0.9999489673627402 0.9999489163046321 0.9999488651954431 0.999948814035122 0.9999487628236178 0.9999487115608789 0.9999486602468546 0.9999486088814932 0.9999485574647434 0.9999485059965539 0.9999484544768732 0.9999484029056498 0.9999483512828321 0.9999482996083686 0.9999482478822075 0.9999481961042971 0.9999481442745858 0.9999480923930215 0.9999480404595525 0.9999479884741269 0.9999479364366927 0.9999478843471978 0.9999478322055902 0.9999477800118178 0.9999477277658284 0.9999476754675696 0.9999476231169894 0.9999475707140352 0.9999475182586547 0.9999474657507955 0.999947413190405 0.9999473605774308 0.9999473079118203 0.9999472551935207 0.9999472024224793 0.9999471495986434 0.9999470967219602 0.9999470437923769 0.9999469908098405 0.999946937774298 0.9999468846856964 0.9999468315439827 0.9999467783491036 0.999946725101006 0.9999466717996368 0.9999466184449425 0.99994656503687 0.9999465115753655 0.9999464580603761 0.9999464044918478 0.9999463508697273 0.9999462971939609 0.999946243464495 0.9999461896812759 0.9999461358442497 0.9999460819533628 0.999946028008561 0.9999459740097907 0.9999459199569977 0.9999458658501279 0.9999458116891274 0.9999457574739421 0.9999457032045176 0.9999456488807996 0.999945594502734 0.9999455400702664 0.9999454855833422 0.9999454310419071 0.9999453764459065 0.9999453217952858 0.9999452670899905 0.9999452123299657 0.9999451575151568 0.999945102645509 0.9999450477209673 0.9999449927414769 0.9999449377069828 0.99994488261743 0.9999448274727634 0.9999447722729279 0.9999447170178684 0.9999446617075294 0.9999446063418558 0.9999445509207922 0.9999444954442832 0.9999444399122733 0.9999443843247071 0.9999443286815289 0.9999442729826831 0.999944217228114 0.999944161417766 0.9999441055515831 0.9999440496295094 0.9999439936514893 0.9999439376174666 0.9999438815273853 0.9999438253811894 0.9999437691788228 0.9999437129202291 0.9999436566053522 0.9999436002341359 0.9999435438065236 0.9999434873224591 0.9999434307818859 0.9999433741847473 0.9999433175309869 0.999943260820548 0.9999432040533739 0.9999431472294078 0.999943090348593 0.9999430334108725 0.9999429764161895 0.999942919364487 0.9999428622557078 0.999942805089795 0.9999427478666915 0.9999426905863398 0.9999426332486828 0.9999425758536633 0.9999425184012237 0.9999424608913067 0.9999424033238548 0.9999423456988104 0.9999422880161158 0.9999422302757136 0.9999421724775458 0.9999421146215547 0.9999420567076825 0.9999419987358713 0.9999419407060631 0.9999418826182 0.9999418244722238 0.9999417662680763 0.9999417080056995 0.9999416496850351 0.9999415913060247 0.99994153286861 0.9999414743727326 0.999941415818334 0.9999413572053556 0.9999412985337388 0.9999412398034251 0.9999411810143557 0.9999411221664717 0.9999410632597144 0.999941004294025 0.9999409452693443 0.9999408861856135 0.9999408270427734 0.9999407678407649 0.9999407085795289 0.999940649259006 0.9999405898791371 0.9999405304398628 0.9999404709411234 0.9999404113828597 0.9999403517650121 0.9999402920875209 0.9999402323503266 0.9999401725533693 0.9999401126965893 0.9999400527799268 0.9999399928033219 0.9999399327667146 0.9999398726700448 0.9999398125132525 0.9999397522962776 0.9999396920190599 0.999939631681539 0.9999395712836547 0.9999395108253466 0.9999394503065543 0.9999393897272172 0.9999393290872748 0.9999392683866664 0.9999392076253314 0.9999391468032091 0.9999390859202385 0.9999390249763589 0.9999389639715094 0.9999389029056289 0.9999388417786563 0.9999387805905308 0.9999387193411908 0.9999386580305754 0.9999385966586231 0.9999385352252725 0.9999384737304625 0.9999384121741314 0.9999383505562177 0.9999382888766597 0.9999382271353959 0.9999381653323645 0.9999381034675037 0.9999380415407516 0.9999379795520464 0.9999379175013262 0.9999378553885288 0.9999377932135921 0.999937730976454 0.9999376686770522 0.9999376063153246 0.9999375438912088 0.9999374814046422 0.9999374188555625 0.9999373562439072 0.9999372935696137 0.9999372308326192 0.9999371680328611 0.9999371051702766 0.9999370422448028 0.9999369792563769 0.9999369162049359 0.9999368530904166 0.999936789912756 0.9999367266718912 0.9999366633677585 0.999936600000295 0.9999365365694373 0.9999364730751217 0.999936409517285 0.9999363458958637 0.9999362822107939 0.9999362184620122 0.9999361546494547 0.9999360907730579 0.9999360268327575 0.99993596282849 0.9999358987601911 0.9999358346277969 0.9999357704312433 0.999935706170466 0.9999356418454008 0.9999355774559835 0.9999355130021497 0.9999354484838349 0.9999353839009746 0.9999353192535043 0.9999352545413592 0.9999351897644749 0.9999351249227865 0.999935060016229 0.9999349950447377 0.9999349300082477 0.9999348649066939 0.9999347997400112 0.9999347345081344 0.9999346692109984 0.9999346038485378 0.9999345384206875 0.9999344729273818 0.9999344073685554 0.9999343417441426 0.999934276054078 0.9999342102982959 0.9999341444767305 0.9999340785893159 0.9999340126359864 0.9999339466166759 0.9999338805313186 0.9999338143798482 0.9999337481621988 0.9999336818783041 0.9999336155280978 0.9999335491115137 0.9999334826284851 0.9999334160789459 0.9999333494628294 0.999933282780069 0.999933216030598 0.9999331492143498 0.9999330823312576 0.9999330153812543 0.9999329483642733 0.9999328812802474 0.9999328141291095 0.9999327469107926 0.9999326796252295 0.9999326122723527 0.9999325448520953 0.9999324773643895 0.999932409809168 0.9999323421863633 0.9999322744959077 0.9999322067377336 0.9999321389117732 0.9999320710179588 0.9999320030562224 0.9999319350264961 0.999931866928712 0.9999317987628019 0.9999317305286978 0.9999316622263312 0.9999315938556341 0.999931525416538 0.9999314569089746 0.9999313883328752 0.9999313196881715 0.9999312509747947 0.9999311821926763 0.9999311133417473 0.999931044421939 0.9999309754331825 0.9999309063754088 0.9999308372485489 0.9999307680525338 0.999930698787294 0.9999306294527606 0.999930560048864 0.9999304905755351 0.9999304210327042 0.9999303514203021 0.9999302817382588 0.9999302119865049 0.9999301421649706 0.9999300722735861 0.9999300023122816 0.9999299322809871 0.9999298621796325 0.999929792008148 0.9999297217664631 0.9999296514545079 0.9999295810722119 0.9999295106195047 0.9999294400963161 0.9999293695025754 0.9999292988382121 0.9999292281031557 0.9999291572973351 0.9999290864206799 0.9999290154731192 0.9999289444545818 0.999928873364997 0.9999288022042936 0.9999287309724005 0.9999286596692465 0.9999285882947602 0.9999285168488704 0.9999284453315056 0.9999283737425945 0.9999283020820652 0.9999282303498462 0.9999281585458659 0.9999280866700524 0.999928014722334 0.9999279427026385 0.999927870610894 0.9999277984470287 0.9999277262109703 0.9999276539026464 0.9999275815219849 0.9999275090689134 0.9999274365433595 0.9999273639452507 0.9999272912745143 0.9999272185310779 0.9999271457148685 0.9999270728258136 0.99992699986384 0.9999269268288751 0.9999268537208457 0.9999267805396788 0.9999267072853011 0.9999266339576395 0.9999265605566207 0.9999264870821711 0.9999264135342176 0.9999263399126865 0.9999262662175042 0.9999261924485972 0.9999261186058914 0.9999260446893132 0.9999259706987887 0.999925896634244 0.999925822495605 0.9999257482827976 0.9999256739957475 0.9999255996343807 0.9999255251986225 0.9999254506883988 0.9999253761036349 0.9999253014442564 0.9999252267101886 0.9999251519013568 0.9999250770176862 0.9999250020591021 0.9999249270255293 0.9999248519168928 0.9999247767331179 0.9999247014741289 0.999924626139851 0.9999245507302088 0.9999244752451267 0.9999243996845296 0.9999243240483416 0.9999242483364873 0.999924172548891 0.9999240966854769 0.9999240207461692 0.9999239447308919 0.9999238686395691 0.9999237924721247 0.9999237162284825 0.9999236399085665 0.9999235635123002 0.9999234870396072 0.9999234104904112 0.9999233338646357 0.999923257162204 0.9999231803830394 0.9999231035270653 0.9999230265942046 0.9999229495843807 0.9999228724975164 0.9999227953335348 0.9999227180923586 0.9999226407739107 0.9999225633781138 0.9999224859048905 0.9999224083541635 0.999922330725855 0.9999222530198876 0.9999221752361835 0.9999220973746652 0.9999220194352546 0.9999219414178738 0.9999218633224449 0.9999217851488899 0.9999217068971306 0.9999216285670885 0.9999215501586858 0.9999214716718439 0.9999213931064841 0.9999213144625282 0.9999212357398974 0.9999211569385131 0.9999210780582966 0.9999209990991689 0.999920920061051 0.9999208409438641 0.9999207617475291 0.9999206824719666 0.9999206031170975 0.9999205236828426 0.9999204441691223 0.9999203645758572 0.9999202849029678 0.9999202051503744 0.9999201253179971 0.9999200454057564 0.9999199654135723 0.9999198853413648 0.9999198051890538 0.9999197249565593 0.9999196446438011 0.9999195642506988 0.9999194837771722 0.9999194032231407 0.9999193225885239 0.9999192418732411 0.9999191610772116 0.9999190802003548 0.9999189992425896 0.9999189182038354 0.9999188370840109 0.9999187558830351 0.999918674600827 0.999918593237305 0.9999185117923881 0.9999184302659948 0.9999183486580435 0.9999182669684527 0.9999181851971407 0.9999181033440258 0.9999180214090262 0.9999179393920599 0.999917857293045 0.9999177751118995 0.999917692848541 0.9999176105028876 0.9999175280748568 0.9999174455643661 0.9999173629713333 0.9999172802956756 0.9999171975373105 0.9999171146961552 0.9999170317721269 0.9999169487651427 0.9999168656751196 0.9999167825019747 0.9999166992456247 0.9999166159059865 0.9999165324829766 0.9999164489765118 0.9999163653865085 0.9999162817128833 0.9999161979555523 0.999916114114432 0.9999160301894386 0.9999159461804881 0.9999158620874966 0.99991577791038 0.9999156936490541 0.9999156093034347 0.9999155248734376 0.9999154403589784 0.9999153557599724 0.9999152710763353 0.9999151863079823 0.9999151014548286 0.9999150165167896 0.9999149314937802 0.9999148463857155 0.9999147611925104 0.9999146759140799 0.9999145905503385 0.9999145051012011 0.999914419566582 0.999914333946396 0.9999142482405573 0.9999141624489803 0.9999140765715794 0.9999139906082685 0.9999139045589619 0.9999138184235734 0.999913732202017 0.9999136458942065 0.9999135595000556 0.999913473019478 0.9999133864523871 0.9999132997986966 0.9999132130583198 0.9999131262311699 0.9999130393171602 0.9999129523162038 0.9999128652282138 0.9999127780531031 0.9999126907907844 0.9999126034411707 0.9999125160041746 0.9999124284797087 0.9999123408676855 0.9999122531680176 0.999912165380617 0.9999120775053962 0.9999119895422673 0.9999119014911424 0.9999118133519335 0.9999117251245524 0.9999116368089109 0.9999115484049209 0.9999114599124939 0.9999113713315414 0.9999112826619749 0.9999111939037059 0.9999111050566456 0.9999110161207051 0.9999109270957955 0.999910837981828 0.9999107487787133 0.9999106594863625 0.9999105701046861 0.9999104806335948 0.9999103910729993 0.99991030142281 0.9999102116829373 0.9999101218532913 0.9999100319337826 0.9999099419243209 0.9999098518248166 0.9999097616351795 0.9999096713553194 0.999909580985146 0.9999094905245692 0.9999093999734984 0.9999093093318431 0.9999092185995128 0.9999091277764167 0.999909036862464 0.999908945857564 0.9999088547616255 0.9999087635745576 0.9999086722962691 0.9999085809266688 0.9999084894656654 0.9999083979131673 0.9999083062690832 0.9999082145333215 0.9999081227057902 0.9999080307863979 0.9999079387750526 0.9999078466716621 0.9999077544761347 0.999907662188378 0.9999075698082999 0.9999074773358079 0.9999073847708096 0.9999072921132126 0.9999071993629243 0.9999071065198518 0.9999070135839025 0.9999069205549833 0.9999068274330015 0.9999067342178637 0.999906640909477 0.9999065475077479 0.9999064540125833 0.9999063604238895 0.999906266741573 0.9999061729655403 0.9999060790956975 0.999905985131951 0.9999058910742067 0.9999057969223706 0.9999057026763486 0.9999056083360465 0.9999055139013701 0.9999054193722248 0.9999053247485163 0.99990523003015 0.9999051352170312 0.999905040309065 0.9999049453061568 0.9999048502082114 0.999904755015134 0.9999046597268291 0.9999045643432017 0.9999044688641565 0.9999043732895979 0.9999042776194306 0.9999041818535587 0.9999040859918866 0.9999039900343185 0.9999038939807585 0.9999037978311106 0.9999037015852786 0.9999036052431665 0.9999035088046777 0.9999034122697161 0.999903315638185 0.999903218909988 0.9999031220850283 0.9999030251632091 0.9999029281444336 0.9999028310286048 0.9999027338156257 0.9999026365053989 0.9999025390978274 0.9999024415928137 0.9999023439902605 0.99990224629007 0.9999021484921446 0.9999020505963868 0.9999019526026985 0.9999018545109819 0.9999017563211388 0.9999016580330712 0.9999015596466807 0.9999014611618692 0.999901362578538 0.9999012638965888 0.9999011651159229 0.9999010662364414 0.9999009672580457 0.9999008681806366 0.9999007690041154 0.9999006697283828 0.9999005703533396 0.9999004708788863 0.9999003713049238 0.9999002716313524 0.9999001718580725 0.9999000719849843 0.9998999720119881 0.9998998719389839 0.9998997717658716 0.9998996714925513 0.9998995711189226 0.9998994706448852 0.9998993700703387 0.9998992693951827 0.9998991686193163 0.999899067742639 0.9998989667650499 0.999898865686448 0.9998987645067324 0.999898663225802 0.9998985618435554 0.9998984603598915 0.9998983587747086 0.9998982570879053 0.99989815529938 0.9998980534090308 0.9998979514167561 0.9998978493224538 0.999897747126022 0.9998976448273584 0.9998975424263608 0.9998974399229269 0.9998973373169542 0.9998972346083401 0.999897131796982 0.9998970288827772 0.9998969258656228 0.9998968227454158 0.9998967195220532 0.9998966161954318 0.9998965127654482 0.9998964092319992 0.9998963055949813 0.9998962018542908 0.9998960980098242 0.9998959940614774 0.9998958900091469 0.9998957858527284 0.999895681592118 0.9998955772272113 0.9998954727579041 0.999895368184092 0.9998952635056705 0.9998951587225349 0.9998950538345804 0.9998949488417024 0.9998948437437958 0.9998947385407556 0.9998946332324766 0.9998945278188537 0.9998944222997813 0.9998943166751542 0.9998942109448666 0.999894105108813 0.9998939991668875 0.9998938931189844 0.9998937869649974 0.9998936807048207 0.9998935743383479 0.9998934678654727 0.999893361286089 0.9998932546000898 0.9998931478073687 0.999893040907819 0.9998929339013339 0.9998928267878064 0.9998927195671293 0.9998926122391957 0.999892504803898 0.9998923972611292 0.9998922896107816 0.9998921818527475 0.9998920739869194 0.9998919660131894 0.9998918579314497 0.9998917497415922 0.9998916414435087 0.999891533037091 0.9998914245222308 0.9998913158988196 0.999891207166749 0.99989109832591 0.9998909893761941 0.9998908803174923 0.9998907711496956 0.9998906618726949 0.9998905524863811 0.9998904429906447 0.9998903333853764 0.9998902236704664 0.9998901138458054 0.9998900039112835 0.9998898938667906 0.9998897837122172 0.9998896734474527 0.9998895630723872 0.9998894525869103 0.9998893419909115 0.9998892312842805 0.9998891204669065 0.9998890095386787 0.9998888984994863 0.9998887873492182 0.9998886760877636 0.999888564715011 0.9998884532308492 0.9998883416351668 0.9998882299278524 0.9998881181087941 0.9998880061778803 0.9998878941349991 0.9998877819800386 0.9998876697128865 0.9998875573334307 0.999887444841559 0.9998873322371589 0.9998872195201178 0.9998871066903231 0.999886993747662 0.9998868806920217 0.9998867675232891 0.9998866542413511 0.9998865408460947 0.9998864273374064 0.9998863137151727 0.9998861999792801 0.9998860861296149 0.9998859721660635 0.9998858580885117 0.9998857438968457 0.9998856295909514 0.9998855151707144 0.9998854006360205 0.9998852859867551 0.9998851712228037 0.9998850563440517 0.999884941350384 0.999884826241686 0.9998847110178424 0.9998845956787381 0.999884480224258 0.9998843646542867 0.9998842489687084 0.9998841331674078 0.9998840172502689 0.9998839012171761 0.9998837850680133 0.9998836688026645 0.9998835524210135 0.9998834359229438 0.9998833193083393 0.9998832025770832 0.9998830857290588 0.9998829687641496 0.9998828516822384 0.9998827344832084 0.9998826171669425 0.9998824997333232 0.9998823821822334 0.9998822645135554 0.9998821467271718 0.9998820288229647 0.9998819108008165 0.9998817926606091 0.9998816744022243 0.9998815560255442 0.9998814375304503 0.9998813189168243 0.9998812001845475 0.9998810813335015 0.9998809623635672 0.9998808432746259 0.9998807240665586 0.999880604739246 0.999880485292569 0.9998803657264083 0.9998802460406442 0.9998801262351571 0.9998800063098274 0.9998798862645353 0.9998797660991605 0.9998796458135834 0.9998795254076833 0.9998794048813402 0.9998792842344335 0.9998791634668427 0.9998790425784472 0.9998789215691258 0.999878800438758 0.9998786791872226 0.9998785578143983 0.9998784363201639 0.9998783147043981 0.9998781929669792 0.9998780711077856 0.9998779491266955 0.999877827023587 0.999877704798338 0.9998775824508265 0.9998774599809301 0.9998773373885266 0.9998772146734932 0.9998770918357074 0.9998769688750465 0.9998768457913877 0.9998767225846077 \u0026hellip;      :  Gower, J. C. (1971). A general coefficient of similarity and some of its properties. Biometrics, (), 857â871.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : This is for instance the case we deal with in the counterfactuals with constraint solvers.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/gower-distance.html","tags":null,"title":"Gower distance"},{"categories":null,"contents":"Installation macOS You can install GPG on macOS using:\n$ brew install gpg Troubleshooting macOS Can\u0026rsquo;t access keychain from UI If a program cannot access the keychain from the UI, probably there\u0026rsquo;s some problem in prompting you for the passphrase. You can install, for instance pinentry to solve this. Install it with\n$ brew install pinentry-mac and then register pinentry as the passphrase input option:\n$ echo \u0026#34;pinentry-program /usr/local/bin/pinentry-mac\u0026#34; \u0026gt;\u0026gt; ~/.gnupg/gpg-agent.conf ","permalink":"https://ruivieira.dev/gpg.html","tags":null,"title":"GPG"},{"categories":null,"contents":"Missing headers On macOS, if you find missing headers when installing polyglot packages, try:\n$ export CPATH=`xcrun --show-sdk-path`/usr/include ","permalink":"https://ruivieira.dev/graalvm.html","tags":null,"title":"GraalVM"},{"categories":null,"contents":" Hill-climbing optimisation  ","permalink":"https://ruivieira.dev/gradient-free-optimisation.html","tags":null,"title":"Gradient-free optimisation"},{"categories":null,"contents":"I have been working in a new library called gulp which you can find on https://github.com/ruivieira/gulp.\nOn the project\u0026rsquo;s page there are some usage examples but I will try to summarise the main points here.\nThe purpose of this library is to facilitate the parallel development of R and Java code, using rJava as the bridge. Creating bindings in rJava is quite simple, the tricky part of the process (in my opinion) being the maintenance of the bindings (usually done by hand) when refactoring your code.\nAs an example, let\u0026rsquo;s assume you have the following Java class:\n```java @ExportClassReference(value=\u0026ldquo;test\u0026rdquo;)\npublic class Test {\n// Java code\n} ```\nThat you wish to call from R.\n","permalink":"https://ruivieira.dev/gulp.html","tags":null,"title":"gulp"},{"categories":null,"contents":"Global maximum Let\u0026rsquo;s try it with the function\n\\[ f(x,y) = e^{-\\left(x^2+y^2\\right)} \\]\nimport numpy as np import matplotlib.pyplot as plt from plotutils import *  x = np.linspace(-2.0, 2.0, 1000) y = np.linspace(-2.0, 2.0, 1000) X, Y = np.meshgrid(x, y)  Z = np.exp(-(X ** 2 + Y ** 2))  fig, ax = plt.subplots(1, 1) cp = ax.contourf(X, Y, Z, cmap=cmaps[1])  ax.set_title(\u0026#34;f(x,y)\u0026#34;) ax.set_xlabel(\u0026#34;x\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) plt.show() from gradient_free_optimizers import HillClimbingOptimizer  search_space = {  \u0026#34;x\u0026#34;: x,  \u0026#34;y\u0026#34;: y, } opt = HillClimbingOptimizer(search_space) def f(pos):  x = pos[\u0026#34;x\u0026#34;]  y = pos[\u0026#34;y\u0026#34;]  z = np.exp(-(x**2 + y**2))  return z result = opt.search(f,  n_iter=30000,  verbosity=[\u0026#39;print_times\u0026#39;],  random_state=23) opt.results Local maximum Let\u0026rsquo;s try it with the function\n\\[ f(x,y) = e^{-\\left(x^2+y^2\\right)}+2e^{-\\left((x-1.7)^2+(y-1.7)^2\\right)} \\]\nx = np.linspace(-1.0, 3.0, 1000) y = np.linspace(-1.0, 3.0, 1000) X, Y = np.meshgrid(x, y)  Z = np.exp(-(X**2 + Y**2))+2*np.exp(-((X-1.7)**2+(Y-1.7)**2))  fig,ax=plt.subplots(1,1) cp = ax.contourf(X, Y, Z, cmap=cmaps[1])  ax.set_title(\u0026#39;f(x,y)\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;y\u0026#39;) plt.show() opt = HillClimbingOptimizer(search_space) def f(pos):  x = pos[\u0026#34;x\u0026#34;]  y = pos[\u0026#34;y\u0026#34;]  z = np.exp(-(x**2 + y**2))+2*np.exp(-((x-1.7)**2+(y-1.7)**2))  return z result = opt.search(f,  n_iter=30000,  verbosity=[\u0026#39;print_times\u0026#39;],  random_state=23) opt.results ","permalink":"https://ruivieira.dev/hill-climbing-optimisation.html","tags":null,"title":"Hill-climbing optimisation"},{"categories":null,"contents":"HTML Tricks Meters A meter element is availble natively for HTML.\n\u0026lt;label for=\u0026#34;value1\u0026#34;\u0026gt;Low\u0026lt;/label\u0026gt; \u0026lt;meter id=\u0026#34;value1\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;100\u0026#34; low=\u0026#34;30\u0026#34; high=\u0026#34;75\u0026#34; optimum=\u0026#34;80\u0026#34; value=\u0026#34;25\u0026#34;\u0026gt;\u0026lt;/meter\u0026gt;  \u0026lt;label for=\u0026#34;value2\u0026#34;\u0026gt;Medium\u0026lt;/label\u0026gt; \u0026lt;meter id=\u0026#34;value2\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;100\u0026#34; low=\u0026#34;30\u0026#34; high=\u0026#34;75\u0026#34; optimum=\u0026#34;80\u0026#34; value=\u0026#34;50\u0026#34;\u0026gt;\u0026lt;/meter\u0026gt;  \u0026lt;label for=\u0026#34;value3\u0026#34;\u0026gt;High\u0026lt;/label\u0026gt; \u0026lt;meter id=\u0026#34;value3\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;100\u0026#34; low=\u0026#34;30\u0026#34; high=\u0026#34;75\u0026#34; optimum=\u0026#34;80\u0026#34; value=\u0026#34;80\u0026#34;\u0026gt;\u0026lt;/meter\u0026gt; Low \nMedium \nHigh \nOrdered list start Change the starting point of an ordered list.\n\u0026lt;ol start=\u0026#34;11\u0026#34;\u0026gt;  \u0026lt;li\u0026gt;Eleven\u0026lt;/li\u0026gt;  \u0026lt;li\u0026gt;Twelve\u0026lt;/li\u0026gt;  \u0026lt;li\u0026gt;Thirteen\u0026lt;/li\u0026gt;  \u0026lt;li\u0026gt;Fourteen\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; Eleven Twelve Thirteen Fourteen  HTML Native Search \u0026lt;div class=\u0026#34;wrapper\u0026#34;\u0026gt;  \u0026lt;h1\u0026gt;HTML native search\u0026lt;/h1\u0026gt;   \u0026lt;input list=\u0026#34;items\u0026#34;\u0026gt;   \u0026lt;datalist id=\u0026#34;items\u0026#34;\u0026gt;  \u0026lt;option value=\u0026#34;Rui\u0026#34;\u0026gt;  \u0026lt;option value=\u0026#34;Vieira\u0026#34;\u0026gt;  \u0026lt;option value=\u0026#34;ruivieira.dev\u0026#34;\u0026gt;  \u0026lt;option value=\u0026#34;HTML\u0026#34;\u0026gt;  \u0026lt;/datalist\u0026gt; \u0026lt;/div\u0026gt; Native HTML Search   Fieldset element \u0026lt;form\u0026gt;  \u0026lt;fieldset\u0026gt;  \u0026lt;legend\u0026gt;Best editor\u0026lt;/legend\u0026gt;   \u0026lt;input type=\u0026#34;radio\u0026#34; id=\u0026#34;emacs\u0026#34; name=\u0026#34;editor\u0026#34;\u0026gt;  \u0026lt;label for=\u0026#34;emacs\u0026#34;\u0026gt;Emacs\u0026lt;/label\u0026gt;\u0026lt;br/\u0026gt;   \u0026lt;input type=\u0026#34;radio\u0026#34; id=\u0026#34;vim\u0026#34; name=\u0026#34;editor\u0026#34;\u0026gt;  \u0026lt;label for=\u0026#34;vim\u0026#34;\u0026gt;Vim\u0026lt;/label\u0026gt;\u0026lt;br/\u0026gt;   \u0026lt;input type=\u0026#34;radio\u0026#34; id=\u0026#34;nano\u0026#34; name=\u0026#34;editor\u0026#34;\u0026gt;  \u0026lt;label for=\u0026#34;nano\u0026#34;\u0026gt;nano\u0026lt;/label\u0026gt;  \u0026lt;/fieldset\u0026gt; \u0026lt;/form\u0026gt;   Best editor \u0026lt;input type=\u0026quot;radio\u0026quot; id=\u0026quot;emacs\u0026quot; name=\u0026quot;editor\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;emacs\u0026quot;\u0026gt;Emacs\u0026lt;/label\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;input type=\u0026quot;radio\u0026quot; id=\u0026quot;vim\u0026quot; name=\u0026quot;editor\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;vim\u0026quot;\u0026gt;Vim\u0026lt;/label\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;input type=\u0026quot;radio\u0026quot; id=\u0026quot;nano\u0026quot; name=\u0026quot;editor\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;nano\u0026quot;\u0026gt;nano\u0026lt;/label\u0026gt;    Spellchecking \u0026lt;label for=\u0026#34;input1\u0026#34;\u0026gt;spellcheck=\u0026#34;true\u0026#34;\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;input1\u0026#34; spellcheck=\u0026#34;true\u0026#34;\u0026gt;  \u0026lt;label for=\u0026#34;input2\u0026#34;\u0026gt;spellcheck=\u0026#34;false\u0026#34;\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;input2\u0026#34; spellcheck=\u0026#34;false\u0026#34;\u0026gt; spellcheck=\u0026ldquo;true\u0026rdquo; spellcheck=\u0026ldquo;false\u0026rdquo; Sliders \u0026lt;label for=\u0026#34;volume\u0026#34;\u0026gt;Volume (goes to 11): \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;range\u0026#34; id=\u0026#34;volume\u0026#34; name=\u0026#34;volume\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;11\u0026#34;\u0026gt; Volume (goes to 11):  Details  \u0026lt;details\u0026gt;  \u0026lt;summary\u0026gt;  Spoiler  \u0026lt;/summary\u0026gt;   \u0026lt;p\u0026gt;  Keyser SÃ¶ze is a myth.  \u0026lt;/p\u0026gt;  \u0026lt;/details\u0026gt;   Spoiler   Keyser SÃ¶ze is a myth.  Mark \u0026lt;p\u0026gt;This is an \u0026lt;mark\u0026gt;example with highlight\u0026lt;/mark\u0026gt; since it\u0026#39;s so important\u0026lt;/p\u0026gt; This is an example with highlight since it's so important\n","permalink":"https://ruivieira.dev/html.html","tags":null,"title":"HTML"},{"categories":null,"contents":"Templates Special pages By default, the type for a piece of content is inherited from the the contentâs section. So, the file you create for content at content/posts/my-post.md automatically has a type of posts. However, you may want to keep my-post.md within that section because you want to rely on Hugoâs default behavior to render the page to yoursite.com/posts/my-post, but you want it to render according to a different layout. In this case, you can specify a type for the content that overrides the default behavior. Types are always singular.\nYou can then put specific layouts in a layout folder of the same name as the type (hence why it works with mylayout). You are telling Hugo that your About page, while living inside the root content section, is of the specific mylayout type. Further, you could even specify a layout that Hugo should use to render your About page:\n+++ date = \u0026#34;2017-04-17T11:01:21-04:00\u0026#34; draft = false title = \u0026#34;About\u0026#34; type = \u0026#34;mylayout\u0026#34; layout = \u0026#34;speciallayout\u0026#34; +++ In this example, Hugo will render the page according to what you create in ./themes/mytheme/layouts/mylayout/speciallayout.html. If you do not specify the layout, Hugo then looks for the the next layout in the lookup order.\n","permalink":"https://ruivieira.dev/hugo.html","tags":null,"title":"Hugo"},{"categories":null,"contents":"Stardate 96893.29.\nYou are the USS Euler\u0026rsquo;s Science Officer at a moment when the computer graphical displays and voice systems went down. You only have enough deuterium for a short travel and need to find the nearest star system. This is not a simple matter of looking at a chart. You have multiple dimensions in which you can travel. In a bid for galactic peace, the Federation mandated that both Emacs and Vim should be installed in all computers. You open your favourite editor and, fortunately, know exactly how to formulate the solution to your problem: a $d$-dimensional nearest neighbour algorithm.\nGiven a dataset \\(\\mathcal{D}\\) of \\(n\\) points in a space \\(X\\) we want to be able to tell which are the closest point to a query point \\(q \\in X\\), preferably in a way which is computationally cheaper than brute force methods (_e.g._ iterating through all of the points) which typically solve this problem in \\(\\mathcal{O}(dn)\\)Â [^arya1998].\n\\(X\\) could have \\(d\\) dimensions (that is \\(\\mathcal{D} \\subset X : \\mathbb{R}^d\\)) and we define closest using1 Minkowski distance metrics, that is:\nSpace decomposition BBD trees belong to the category of hierarchical space decomposition trees. In BBD trees, specifically, space is divided in $d$-dimensional rectangles and cells. Cells can either represent another $d$-dimensional rectangle or the intersection of two rectangles (one, the outer box fully enclosing the other, the inner box). Another important distinction of BBD trees is that rectangle\u0026rsquo;s size (in this context, the largest length in all of the \\(d\\) dimensions) is bounded by a constant value. The space decomposition must follow an additional rule which is boxes must be sticky. If we consider a inner box \\([x_{inner}, y_{inner}]\\) contained in a outer box \\([x_{outer}, y_{outer}]\\), such that\n\\[ [x_{inner}, y_{inner}] \\subseteq [x_{outer}, y_{outer}], \\]\nthen, considering \\(w = y_{inner} - x_{inner}\\), the box is considered sticky if either\n$$\n\\begin{aligned} x_{inner}-x_{outer} = 0 \u0026amp;\\lor x_{inner}-x_{outer} \\nleq w \\\\ y_{outer}-y_{inner} = 0 \u0026amp;\\lor y_{outer}-y_{inner} \\nleq w. \\end{aligned}\n$$\nAn illustration of the stickiness concept can viewed in the diagram below.\nFigure 2. Visualisation of the \u0026ldquo;stickiness\u0026rdquo; criteria for \\(\\mathbb{R}^2\\) rectangles.\nStickiness provides some important geometric properties to the space decomposition which will be discussed further on. The actual process of space decomposition will produce a tree of nodes, each with an associated $d$-dimensional rectangle enclosing a set of points. Each node will be further decomposed into children nodes, containing a region of space with a subset of the parent\u0026rsquo;s data points. If a node has no children it will be called a leaf node. The division process can occur either by means of:\n a fair split, this is done by partitioning the space with an hyperplane, resulting in a low and high children nodes a shrink, splitting the box into a inner box (the inner child) and a outer box (the outer child).  Figure 3. \u0026ldquo;Fair split\u0026rdquo; and \u0026ldquo;shrinking\u0026rdquo; division strategies example in \\(\\mathbb{R}^2\\) with respective high/low and outer/inner children.\nThe initial node of the tree, the root node, will include all the dataset points, \\(\\mathcal{D}\\). In the Figure 4 we can see a representation of the root node for the dataset presented above. We can see the node boundaries in dashed red lines as well as the node\u0026rsquo;s center, marked as \\(\\mu_{root}\\).\nFigure 4. Associated cell for the BBD-tree root node for the example dataset. Node boundaries in red and node centre labelled as \\(\\mu_{root}\\).\nThe actual method to calculate the division can either be based on the midpoint algorithm or the middle interval algorithm. The method used for these examples is the latter, for which more details can be found inÂ [^kosaraju1995]. The next step is to divide the space according to the previously mentioned rules. As an example, we can see the root node\u0026rsquo;s respective children in Figure 5.\nFigure 5. BBD-tree root node\u0026rsquo;s lower (_left_) and upper (_right_) children. Node boundaries in red and centres labelled with a red cross.\nThis process is repeated until the child nodes are leaves and cannot be divided anymore. To better visualise the construction process it would be helpful to have a larger tree, so we will now consider still the 2-dimensional case, but now with a larger dataset (Figure 6), consisting of 2000 samples in total, each half from a bivariate Gaussian distribution:\n$$\n\\begin{aligned} \\text{X}_1 \u0026amp;\\sim \\mathcal{N}([0,0], \\mathbf{I}) \\\\ \\text{X}_2 \u0026amp;\\sim \\mathcal{N}([3, 3], \\mathbf{I}). \\\\ \\end{aligned}\n$$\nFigure 6. Larger example dataset in \\(\\mathbb{R}^2\\) consisting of a realisation of \\(n=2000\\) from two bivariate Gaussian distributions centred in \\(\\mu_1=(0,0)\\) and \\(\\mu_2=(3,3)\\) and with \\(\\Sigma=\\mathbf{I}\\).\nWith this larger dataset, we have enough points to illustrate the tree node building. This time, we will start from the root node and always follow either the \u0026ldquo;lower\u0026rdquo; nodes or the \u0026ldquo;upper\u0026rdquo; nodes (as show in Figure 7). We can clearly see the cells getting smaller, until finally we have a single point included (_i.e._ a leaf node).\nFigure 7. BBD-tree node building process for the bivariate dataset. On the left we traverse the upper tree nodes and on the right the lower tree nodes.\nThis division process illustrates an important property of BBD-trees. Although other space decomposition algorithms (such as kd-trees) display a geometric reduction of number of points enclosed in each cell, methods such as the BBD-tree, which impose constraints on the cell\u0026rsquo;s size aspect ratio as stated before, display not only a geometric reduction in the number of points, but also in the cell\u0026rsquo;s size as well. The construction cost of a BBD-tree is \\(\\mathcal{O}(dn \\log n)\\) and the tree itself will have \\(\\mathcal{O}(n)\\) nodes and \\(\\mathcal{O}(\\log n)\\) height.\nTree querying Now that we have successfully constructed a BBD-tree, we want to actually find the (approximate) nearest neighbour of an arbitrary query point \\(q\\) (Figure 8).\nFigure 8. Query point \\(q\\) (red) for the bivariate dataset.\nThe first step consists in descending the tree in order to locate the smallest cell containing the query point \\(q\\). This process is illustrated for the bivariate data in Figure 9.\nFigure 9. BBD-tree descent to locate the smallest cell containing \\(q\\) (red).\nOnce the cell has been located, we proceed to enumerate all the leaf nodes contained by it and calculate our distance metric \\(L_2\\) in this case) between the query point \\(q\\) and the leaf nodes, eventually declaring the point with the smallest \\(L_2\\) as the aproximate NN. BBD-trees provide strong guarantees that the ANN will be located within this cell and not in a neighbouring cell. In Figure 10 we zoomed in the smallest cell containing \\(q\\) and show the associated calculated \\(L_2\\) distance for each node.\nFigure 10. \\(L_2\\) distance between leaf nodes and the query point \\(q\\) inside the smallest cell containing \\(q\\).\nAn important property of BBD-trees is that the tree structure does not need to be recalculated if we change either \\(\\epsilon\\) or if we decide to use another \\(L_m\\) distance metricÂ [^arya1998]. The query time for a point \\(q\\) in a BBD-tree is \\(\\mathcal{O}(\\log n)\\). For comparison, if you recall, the query time for a brute force method is typically \\(\\mathcal{O}(dn)\\).\nFiltering and k-NN Great. Now that you solved the USS Euler\u0026rsquo;s problem, you want to make a suggestion to the federation. Where to place several star-bases and how to divide the system\u0026rsquo;s coverage between them. An immediate generalisation of this method is easily applicable to the problem of clustering. Note that, at the moment, we are not concerned with determining the \u0026ldquo;best\u0026rdquo; clusters for our data[^2]. Given a set of points \\(Z = \\{z_1, z_2, \\dots, z_n\\}\\), we are concerned now in partitioning the data in clusters centred in each of the \\(Z\\) points. A way of looking at this, is that we are building, for each point \\(z_n\\) a Voronoi cell \\(V(z_n)\\). This is achieved by a method called filtering. Filtering, in general terms, works by walking the tree with the list of candidate centres (\\(Z\\)) and pruning points from the candidate list as we move down. We will denote an arbitrary node as \\(n\\), \\(z^{\\star}_w\\) and \\(n_w\\) respectively as the candidate and the node weight, \\(z^{\\star}_n\\) and \\(n_n\\) as the candidate and node count. The algorithm steps, as detailed inÂ 2, are detailed below:\nFilter(\\(n\\), \\(Z\\)) { \\(\\qquad C \\leftarrow n.cell\\) \\(\\qquad\\) if (\\(n\\) is a leaf) { \\(\\qquad\\qquad z^{\\star} \\leftarrow\\) the closest point in \\(Z\\) to \\(n.point\\) \\(\\qquad\\qquad z^{\\star}_w \\leftarrow z^{\\star}_w + n.point\\) \\(\\qquad\\qquad z^{\\star}_n \\leftarrow z^{\\star}_n + 1\\qquad\\) } else { \\(\\qquad\\qquad z^{\\star} \\leftarrow\\) the closest point in \\(Z\\) to \\(C\\)\u0026rsquo;s midpoint $\\qquad\\qquad$**for each** (\\(z \\in Z \\setminus \\{z^{\\star}\\}\\)) { \\(\\qquad\\qquad\\qquad\\) if (\\(z.isFarther(z^{\\star},C)\\)) { \\(\\qquad\\qquad\\qquad\\qquad Z \\leftarrow Z \\setminus \\{z\\}\\) \\(\\qquad\\qquad\\)} $\\qquad\\qquad$**if** (\\(|Z|=1\\)) { \\(\\qquad\\qquad\\qquad z^{\\star}_w \\leftarrow z^{\\star}_w + n_w\\) \\(\\qquad\\qquad\\qquad z^{\\star}_n \\leftarrow z^{\\star}_n + n_n\\) \\(\\qquad\\qquad\\)} else { $\\qquad\\qquad\\qquad$Filter(\\(n_{left}, Z\\)) $\\qquad\\qquad\\qquad$Filter(\\(n_{right}, Z\\)) \\(\\qquad\\qquad\\)} }\nTo illustrate the assignment of data points to the centres, we will consider the previous bivariate Gaussian data along with two centres, \\(z_1 = \\{0,0\\}\\) and \\(z_2 = \\{3, 3\\}\\). Figure 11 shows the process of splitting the dataset \\(\\mathcal{D}\\) into two clusters, namely the subsets of data points closer to \\(z_1\\) or \\(z_2\\).\nFigure 11. Assignment of points in \\(\\mathcal{D}\\) to \\(Z\\). Data points coloured according to the assigned center. Lines represent the distance from the cells midpoint to \\(Z\\).\nWe can see in Figure 12 the final cluster assignment of the data points. With a \\(\\mathbb{R}^2\\) dataset and only two centres the organisation of points follows a simple perpendicular bisection of the segment connecting the centres, as expected.\nFigure 12. Final \\(\\mathcal{D}\\) point assignment to clusters centred in \\(z_1\\) and \\(z_2\\).\nIn Figure 13 we can see more clearly the dataset clusters changing when center \\(z_1\\) is moving around the plane. BBD-trees can play an important role in improving $k$-means performance, as described inÂ [^kanungo2002].\nFigure 13. Dynamic assignment of points to a cluster using a BBD-tree.\nThis concludes a (short) introduction to BBD-trees, I hope you enjoyed it. If you have any comments or suggestions, please let me know at Mastodon.\n[fn2] This would be a k-means problem. I intend to write a blog post on k-means clustering (and the role BBD-trees can play) in the future.\n  The \\(L_m\\) distance may be pre-computed in this method to avoid recalculation for each query. \\[ L_m = \\left(\\sum_{i=1}^d |p_i - q_i|^m\\right)^{\\frac{1}{m}},\\qquad p,q \\in X : \\mathbb{R}^d. \\] A potential solution for this problem would be to use kd-trees, which for low dimension scenarios provide \\(\\mathcal{O}(\\log n)\\) query timesÂ [^friedman1977]. However, as the number of dimensions increase (as quickly as \\(d\u0026gt;2\\)) the query times also increase as \\(2^d\\). The case can be made then for approximate nearest neighbour (NN) algorithms and that\u0026rsquo;s precisely what we will discuss here, namely the Balanced Box-Decomposition Tree (BBD,Â [^arya1998]). The definition of approximate NN for a query point \\(q\\) can be given as \\[ \\text{dist}(p, q) \\leq (1+\\epsilon)\\text{dist}(p^{\\star},q),\\qquad \\epsilon \u0026gt; 0, \\] where \\(p\\) is the approximate NN and \\(p^{\\star}\\) is the true NN. Let\u0026rsquo;s consider, for the sake of visualisation, a small two dimensional dataset \\(\\mathcal{D} \\to \\mathbb{R}^2\\) as shown in Figure 1. Figure 1. A small test dataset in \\(\\mathbb{R}^2, n=7\\).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : Kanungo, T., Mount, D. M., Netanyahu, N. S., Piatko, C. D., Silverman, R., \u0026amp; Wu, A. Y. (2002). An efficient k-means clustering algorithms: Analysis and implementation. IEEE Transactions on Pattern Analysis and Machine Intelligence, _24_(7), 881â892. https://doi.org/10.1109/TPAMI.2002.1017616\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/introduction-to-balanced-box-decomposition-trees.html","tags":null,"title":"Introduction to Balanced Box-Decomposition Trees"},{"categories":null,"contents":"Isolation Forests (IFs), presented in Liu1 et. al (2012), are a popular algorithm used for outlier classification. In a very simplified way, the method consists of building an ensemble of Isolation Trees (ITs) for a given data set and observations are deemed anomalies if they have short adjusted average path lengths on the ITs.\nITs, which will be covered shortly, have several properties in common with a fundamental data structure: the Binary Search Tree (BSTs). In a very simplified way, BSTs are a special instance of tree structures where keys are kept in such an order that a node search is performed by iteratively (or recursively) choosing a left or right branch based on a quantitative comparison (e.g. lesser or greater). Node insertion is performed by doing a tree search, using the method described previously, until reaching an external node, where the new node will be inserted. This allows for efficient node searches since, on average, half the tree will not be visited. To illustrate this assume the values \\(x=[1, 10, 2, 4, 3, 5, 26, 9, 7, 54]\\) and the respective insertion on a BST. The intermediate steps would then be as shown below.\n)\nOne of the properties of BSTs is that, with randomly generated data, the path between the root node and the outliers will typically be shorter. We can see from the illustration below that, with our example data, the path length for (say) 7 is twice the length than for the suspicious value of 54. This property will play an important role in the IF algorithm, as we will see further on.\n Isolation Trees Since ITs are the fundamental component of IFs, we will start by describing their building process. We start by defining \\(t\\) as the number of trees in the IF, \\(\\mathcal{D}\\) as the training data (contained in an $n$-dimensional feature space, \\(\\mathcal{D} \\subset \\mathbb{R}^n\\)) and \\(\\psi\\) as the subsampling size. The building of a IT consists then in recursively partitioning the data \\(\\mathcal{D}\\) by sampling (without replacement) a subsample \\(\\mathcal{D}^{\\prime}\\) of size \\(\\psi\\). We then build an isolation tree \\(\\mathcal{T}^{\\prime}\\) with this subsample (in order to later add it to the isolation forest \\(\\mathcal{F}\\)) and the process is repeated \\(t\\) times.\nTo build an isolation tree \\(\\mathcal{T}^{\\prime}\\) from the subsample we proceed as follows: if the data subsample \\(\\mathcal{D}^{\\prime}\\) is indivisible, a tree is returned containing a single external node corresponding to the feature dimensions, \\(n\\). If it can be divided, a series of steps must be performed. Namely, if we consider \\(Q = \\lbrace q_1,\\dots,q_n\\rbrace\\) as the list of features in \\(\\mathcal{D}^{\\prime}\\), we select a random feature \\(q \\in Q\\) and a random split point \\(p\\) such that\n\\[ \\min(q) \u0026lt; p \u0026lt; \\max(q), \\qquad q \\in Q. \\]\nBased on the cut-off point \\(p\\), we filter the features into a BSTâs left and right nodes according to\n\\[ \\mathcal{D}_l := \\lbrace \\mathcal{D}^{\\prime} : q \\in Q, q\u0026lt;p\\rbrace \\\\ \\mathcal{D}_r := \\lbrace \\mathcal{D}^{\\prime} : q \\in Q, q \\geq p\\rbrace, \\]\nand return an internal node having an isolation tree with left and right nodes as respectively \\(\\mathcal{D}_l\\) and \\(\\mathcal{D}_r\\).\nTo illustrate this (and the general method of identifying anomalies in a two dimensional feature space, \\(x\\in\\mathbb{R}^2\\)) we will look at some simulated data and its processing. We start by simulating two clusters of data from a multivariate normal distribution, one centred in \\(x_a=[-10, 10]\\) and another centred in \\(x_b=[10, 10]\\), with a variance of \\(\\Sigma=\\text{diag}(2, 2)\\), that is\n\\[ X_a \\sim \\mathcal{N}\\left([-10, -10], \\text{diag}(2, 2)\\right) \\\\ X_b \\sim \\mathcal{N}\\left([10, 10], \\text{diag}(2, 2)\\right). \\]\nThe particular realisation of this simulation looks like this:\n Below we illustrate the building of a single IT (given the data), illustrating the feature split point \\(p\\) and respective division of the feature list into left or right IT nodes. The process is conducted recursively until the feature list is no longer divisible. As mentioned previously, this process, the creation of an IT, is repeated \\(t\\) times in order to create the IF.\n  In order to perform anomaly detection (e.g. observation scoring) we will then use the IT equivalent of the BST unsuccessful search heuristics. An external node termination in an IT is equivalent to a BST unsuccessful search. Given an observation \\(x\\), our goal is then to calculate the score for this observation, given our defined subsampling size, that is, \\(s(x,\\psi)\\).\nThis technique amounts to partitioning the feature space randomly until feature points are âisolatedâ. Intuitively, points in high density regions will need more partitioning steps, whereas anomalies (by definition away from high density regions) will need fewer splits. Since the building of the ITs is performed in a randomised fashion and using a subsample of the data, this density predictor can be average over a number of ITs, the Isolation Forest.\nIntuitively, this could be done by calculating the average path length for our \\(\\mathcal{T}n, n=1,\\dots,t\\) ITs, \\(\\overline{h}(x)\\). However, as pointed in Liu[^Liu] et. al (2012), a problem with calculating this is that maximum possible height of each \\(\\mathcal{T}_n\\) grows as \\(\\mathcal{O}(\\log(\\psi))\\). To compare \\(h(x)\\) given different subsampling sizes, a normalisation factor, \\(c(\\psi)\\) must be established. This can be calculated by\n\\[ c(\\psi) = \\begin{cases} 2H(\\psi-1)-2\\frac{\\psi-1}{n},\\text{if}\\ \\psi \u0026gt;2,\\\\ 1, \\text{if}\\ \\psi=2,\\\\ 0, \\text{otherwise}, \\end{cases} \\]\nwhere \\(H(i)\\) is the harmonic number estimated by \\(H(i)\\approx\\log(i) + e\\).\nDenoting \\(h_{max}\\) as the tree height limit and e as the current path length, initialised as \\(e=0\\) we can then calculate \\(h(x)\\) recursively as:\n\\[ h(x,\\mathcal{T},h_{max},e) = \\begin{cases} h(x,\\mathcal{T}_{n,left},h_{max},e+1) \\text{if}\\ x_a \u0026lt; q_{\\mathcal{T}} \\\\ h(x,\\mathcal{T}_{n,right},h_{max},e+1) \\text{if}\\ x_a \\geq q_{\\mathcal{T}} \\\\ e+c(\\mathcal{T_{n,s}}) \\text{if}\\ \\mathcal{T} \\text{is a terminal node or}\\ e \\geq h_{max}. \\end{cases} \\]\nGiven these quantities we can then, finally, calculate the anomaly score, \\(s\\) as\n\\[ s(x,\\psi) = 2^{-\\frac{\\text{E}[h(x)]}{c(\\psi)}} \\]\nwith \\(\\text{E}[h(x)]\\) being the average \\(h(x)\\) for a collection of ITs.\nParameters As mentioned in Liu1 et. al (2012), the empirical subsampling size \\(\\psi=2^8\\) is typically enough to perform anomaly detection in a wide range of data. Regarding the number of trees, \\(t\\) no considerable accuracy gain is usually observed with \\(t\u0026gt;100\\). In the plots below, we can see the score calculation for two point in our data, namely an outlier (\\(x_o=[3.10, -12.69])\\) and a normal observation (\\(x_n=[8.65, 9.71]\\)) with a varying number of trees and \\(\\psi=2^8\\) (left) and a varying subsample size and \\(t=100\\) (right). We can see that the score value stabilised quite early on when using \\(\\psi=2^8\\) and that very low subsampling sizes can lead to problems when classifying anomalies.\n Now that we know how to implement an IF algorithm and calculate an anomaly score, we will try to visualise the anomaly score distribution in the vicinity of the simulated data. To do so, we simply create a two dimensional lattice enclosing our data an iteratively calculate \\(s(\\cdot, \\psi)\\). The result is show below:\n The above steps fully define a naive isolation forest algorithm, which when applied to the previously simulated data, result in 88% of the anomalies being correctly identified.\n Thanks for reading! If you have any questions or comments, please let me know on Mastodon or Twitter.\n   Liu, F. T., Ting, K. M., \u0026amp; Zhou, Z. (2012). Isolation-based anomaly detection. ACM Transactions on Knowledge Discovery from Data (TKDD), 6(1), 1â39.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/introduction-to-isolation-forests.html","tags":null,"title":"Introduction to Isolation Forests"},{"categories":null,"contents":"Summary This page contains links to most Java topics.\nTools  Java build systems  Includes Maven    Concepts  Java Completable Futures Java consumer Extending JUnit  Reference Get user home directory System.getProperty(\u0026#34;user.home\u0026#34;); List files recursively try (Stream\u0026lt;Path\u0026gt; walk = Files.walk(Paths.get(input))) {  List\u0026lt;String\u0026gt; result =  walk.filter(Files::isRegularFile)  .map(x -\u0026gt;x.toString())  .collect(Collectors.toList());  result.forEach(System.out::println); } catch (IOException e) {  e.printStackTrace(); } In case we want the file subset with a specific extension, txt we can filter the stream with\n List\u0026lt;String\u0026gt; result = walk.filter(Files::isRegularFile) \t.filter(x -\u0026gt; x.toString().endsWith(\u0026#34;.txt\u0026#34;)) \t.map(x -\u0026gt; x.toString()) \t.collect(Collectors.toList()); Setting the logger level From the CLI specify it with, for instance to set the logger level to info:\n$ mvn test -Dorg.slf4j.simpleLogger.defaultLogLevel=info ","permalink":"https://ruivieira.dev/java.html","tags":null,"title":"Java"},{"categories":null,"contents":"Summary Notes on Java build systems.\n Maven  ","permalink":"https://ruivieira.dev/java-build-systems.html","tags":null,"title":"Java build systems"},{"categories":null,"contents":"Running in parallel import java.util.concurrent.CompletableFuture; import java.lang.InterruptedException; import java.util.concurrent.ExecutionException;  public static void main(String[] args) throws InterruptedException, ExecutionException {  CompletableFuture\u0026lt;String\u0026gt; future1 = CompletableFuture.supplyAsync(() -\u0026gt; \u0026#34;Hello\u0026#34;);  CompletableFuture\u0026lt;String\u0026gt; future2 = CompletableFuture.supplyAsync(() -\u0026gt; \u0026#34;Beautiful\u0026#34;);  CompletableFuture\u0026lt;String\u0026gt; future3 = CompletableFuture.supplyAsync(() -\u0026gt; \u0026#34;World\u0026#34;);   CompletableFuture\u0026lt;Void\u0026gt; combinedFuture = CompletableFuture.allOf(future1, future2, future3);  CompletableFuture\u0026lt;String\u0026gt; result = combinedFuture.thenApply(v -\u0026gt; future1.join() + future2.join() + future3.join());  System.out.println(result.get()); } HelloBeautifulWorld Waiting for all Lets assume we have a completable future, \\(f\\). This future, in turn, create \\(N\\) additional completable futures, \\(f_1, f_2, \\dots, f_N\\). How can we set \\(f\\) to complete only when all \\(f_1, f_2, \\dots, f_N\\) are also completed?\nThe answer is to use a combination of allOf1 with thenRun2. According to the documentation, allOf returns a new CompletableFuture that is completed when all of the given CompletableFutures complete. In turn, thenRun will execute the given action. Let\u0026rsquo;s look at an example:\nimport java.util.concurrent.CompletableFuture; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.lang.InterruptedException; import java.util.concurrent.ExecutionException;  public static void main(String[] args) throws InterruptedException, ExecutionException {  CompletableFuture\u0026lt;String\u0026gt; f = new CompletableFuture\u0026lt;\u0026gt;();   int N = 10;   CompletableFuture\u0026lt;String\u0026gt; f1 = CompletableFuture.completedFuture(\u0026#34;f1\u0026#34;);  CompletableFuture\u0026lt;String\u0026gt; f2 = CompletableFuture.completedFuture(\u0026#34;f2\u0026#34;);  CompletableFuture\u0026lt;String\u0026gt; f3 = CompletableFuture.completedFuture(\u0026#34;f3\u0026#34;);   ExecutorService executor = Executors.newSingleThreadExecutor();   executor.submit(() -\u0026gt; {  CompletableFuture.allOf(f1, f2, f3).thenRun(() -\u0026gt; f.complete(\u0026#34;f1,f2,f3 completed.\\nProceed to finish f.\u0026#34;));  });   f.thenAccept(v -\u0026gt; {  System.out.println(v);  });   Thread.sleep(100);  executor.shutdown(); } f1,f2,f3 completed. Proceed to finish f.   https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#allOf-java.util.concurrent.CompletableFuture\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#thenRun-java.lang.Runnable\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/java-completable-futures.html","tags":null,"title":"Java Completable Futures"},{"categories":null,"contents":"Introduction Applying Introduced in Java 8, the Consumer interface aims at providing additional functional programming capabilities for Java.\nConsumer defined functions do not return any value and they consist mainly of two methods:\nvoid accept(T t); default Consumer\u0026lt;T\u0026gt; andThen(Consumer\u0026lt;? super T\u0026gt; after); Let\u0026rsquo;s look at an example:\nimport java.util.ArrayList; import java.util.function.Consumer;  public static void main(String[] args) {  Consumer\u0026lt;String\u0026gt; say = a -\u0026gt; System.out.println(\u0026#34;Hello, \u0026#34; + a + \u0026#34;!\u0026#34;);   say.accept(\u0026#34;World\u0026#34;); } Hello, World! A Consumer can be applied in a functional way, since applying a consumer is equivalent to applying the accept method. For instance:\nimport java.util.ArrayList; import java.util.List; import java.util.function.Consumer;  public static void main(String[] args) {   Consumer\u0026lt;String\u0026gt; say = a -\u0026gt; System.out.println(\u0026#34;Hello, \u0026#34; + a + \u0026#34;!\u0026#34;);   List\u0026lt;String\u0026gt; musketeers = new ArrayList\u0026lt;String\u0026gt;();  musketeers.add(\u0026#34;D\u0026#39;Artagnan\u0026#34;);  musketeers.add(\u0026#34;Athos\u0026#34;);  musketeers.add(\u0026#34;Aramis\u0026#34;);  musketeers.add(\u0026#34;Porthos\u0026#34;);  musketeers.stream().forEach(say); } Hello, D\u0026#39;Artagnan! Hello, Athos! Hello, Aramis! Hello, Porthos! Consumer functions can also modify reference objects. For instance:\nimport java.util.ArrayList; import java.util.List; import java.util.function.Consumer;  public static void main(String[] args) {  List\u0026lt;Double\u0026gt; numbers = new ArrayList\u0026lt;Double\u0026gt;();  numbers.add(1d);  numbers.add(2d);  numbers.add(3d);   Consumer\u0026lt;List\u0026lt;Double\u0026gt;\u0026gt; square = list -\u0026gt; {  for (int i = 0; i \u0026lt; list.size(); i++) {  double x = list.get(i);  list.set(i, x*x);  };  };   System.out.println(numbers);  square.accept(numbers);  System.out.println(numbers); } [1.0, 2.0, 3.0] [1.0, 4.0, 9.0] Composing Let\u0026rsquo;s now look at how to create a chain of Consumers by composing them with the andThen method. Let\u0026rsquo;s first create a consumer which converts a string to uppercase in-place:\nimport java.util.ArrayList; import java.util.List; import java.util.function.Consumer;  public static void main(String[] args) {  Consumer\u0026lt;String\u0026gt; say = a -\u0026gt; System.out.println(\u0026#34;Hello, \u0026#34; + a + \u0026#34;!\u0026#34;);  Consumer\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; upperCaseConsumer = list -\u0026gt; {  for(int i=0; i\u0026lt; list.size(); i++){  String value = list.get(i).toUpperCase();  list.set(i, value);  }  };  Consumer\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; sayAll = list -\u0026gt; list.stream().forEach(say); } We will now create a chain by first applying upperCaseConsumer and the say to our list.\nimport java.util.ArrayList; import java.util.List; import java.util.function.Consumer;  public static void main(String[] args) {  Consumer\u0026lt;String\u0026gt; say = a -\u0026gt; System.out.println(\u0026#34;Hello, \u0026#34; + a + \u0026#34;!\u0026#34;);  Consumer\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; upperCaseConsumer = list -\u0026gt; {  for(int i=0; i\u0026lt; list.size(); i++){  String value = list.get(i).toUpperCase();  list.set(i, value);  }  };  Consumer\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; sayAll = list -\u0026gt; list.stream().forEach(say);  upperCaseConsumer.andThen(sayAll).accept(musketeers); } ","permalink":"https://ruivieira.dev/java-consumer.html","tags":null,"title":"Java consumer"},{"categories":null,"contents":"Flat mapping Nested maps import java.util.Map; import java.util.HashMap;  public static void main(String[] args) {  final Map\u0026lt;String, Object\u0026gt; client = new HashMap\u0026lt;\u0026gt;();  client.put(\u0026#34;Age\u0026#34;, 43);  client.put(\u0026#34;Salary\u0026#34;, 1950);  client.put(\u0026#34;Existing payments\u0026#34;, 100);  final Map\u0026lt;String, Object\u0026gt; loan = new HashMap\u0026lt;\u0026gt;();  loan.put(\u0026#34;Duration\u0026#34;, 15);  loan.put(\u0026#34;Installment\u0026#34;, 100);  final Map\u0026lt;String, Object\u0026gt; contextVariables = new HashMap\u0026lt;\u0026gt;();  contextVariables.put(\u0026#34;Client\u0026#34;, client);  contextVariables.put(\u0026#34;Loan\u0026#34;, loan);  System.out.println(contextVariables); } {Loan={Installment=100, Duration=15}, Client={Salary=1950, Existing payments=100, Age=43}} ","permalink":"https://ruivieira.dev/java-streams.html","tags":null,"title":"Java streams"},{"categories":null,"contents":"Notes on the JPype Python library.\nConversion Numpy arrays ","permalink":"https://ruivieira.dev/jpype.html","tags":null,"title":"JPype"},{"categories":null,"contents":"Introduction K-means is still one of the fundamental clustering algorithms. It is used in such diverse fields as Natural Language Processing (NLP), social sciences and medical sciences.\nThe core idea behind K-means is that we want to group data in clusters. Data points will be assigned to a specific cluster depending on it\u0026rsquo;s distance to a cluster\u0026rsquo;s center, usually called the centroid.\nIt is important to note that typically, the mean distance to a centroid is used to partition the clusters, however, difference distances can be used and different pivot points. An example is the K-medoids clustering algorithm.\nWe will define the two main steps of a generic K-means clustering algorithm, namely the data assignement and the centroid update step.\nData assignement The criteria to determine whether a point is closer to one centroid is typically an Euclidean distance (\\(L^2\\)) . If we consider a set of \\(n\\) centroids \\(C\\), such that\n\\[ C = \\lbrace c_1, c_2, \\dots, c_n \\rbrace \\]\nWe assign each data point in \\(\\mathcal{D}=\\lbrace x_1, x_2, \\dots, x_n \\rbrace\\) to the nearest centroid according to its distance, such that\n\\[ \\underset{c_i \\in C}{\\arg\\min} \\; dist(c_i,x)^2 \\]\nAs mentioned previously \\(dist(\\cdot)\\) is typically the standard (\\(L^2\\)) Euclidean distance. We define the subset of points assigned to a centroid \\(i\\) as \\(S_i\\).\nCentroid update step This step corresponds to updating the centroids using the mean of add points assign to a cluster, \\(S_i\\). That is\n\\[ c_i=\\frac{1}{|S_i|}\\sum_{x_i \\in S_i} x_i \\]\nPartitioning Different algorithms can be used for cluster partitioning, for instance:\n PAM CLARA CLARANS  PAM To illustrate the PAM partitioning method, we will use a synthetic dataset created along the guidelines in synthetic data generation.\nIn order to use the \u0026ldquo;Elbow method\u0026rdquo; we calculate the Within-Cluster Sum of Squares (WCSS) for a varying number of clusters, \\(K\\).\ndataset = pd.read_csv(\u0026#39;data/mall-customers.zip\u0026#39;) X = dataset.iloc[:, [3, 4]].values from sklearn.cluster import KMeans wcss = [] for i in range(1, 11):  kmeans = KMeans(n_clusters = i, init = \u0026#39;k-means++\u0026#39;, random_state = 42)  kmeans.fit(X)  wcss.append(kmeans.inertia_)  kmeans = KMeans(n_clusters = 5, init = \u0026#34;k-means++\u0026#34;, random_state = 42) y_kmeans = kmeans.fit_predict(X)  ","permalink":"https://ruivieira.dev/k-means-clustering.html","tags":null,"title":"K-means clustering"},{"categories":null,"contents":"Introduction Some requirements to run KNative:\n Minikube kubectl  Architecture  ","permalink":"https://ruivieira.dev/knative.html","tags":null,"title":"KNative"},{"categories":null,"contents":"Notes on Kubernetes\nArchitecture  Concepts Custom Resource Definitions A Custom Resource Definiton (CRD) is an endpoint in the Kubernetes API that stores a collection of API objects. This abstraction permits an expanding the Kubernetes API with new resource definitions.\nIngress service A service1 designed to allow external network traffic in.\nMinikube   https://kubernetes.io/docs/concepts/services-networking/ingress/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/kubernetes.html","tags":null,"title":"Kubernetes"},{"categories":null,"contents":"Notes on Kustomize1.\nInstallation kubectl is a Kustomize requirement. To install the binary version of Kustomize use\n\t$ curl -s \u0026#34;https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh\u0026#34; | bash   https://kustomize.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/kustomize.html","tags":null,"title":"Kustomize"},{"categories":null,"contents":" Last week, at the North East Functional Programming meet up, we were given a code Kata consisting of the Langton\u0026rsquo;s ant algorithm.\nI\u0026rsquo;ve had a go at Scala but decided later on to put a live version in this blog.\nI considered several implementation options, such as scala.js and Elm, but in the end decided to implement it in plain Javascript.\n\n Add ant\n","permalink":"https://ruivieira.dev/langtons-ant.html","tags":null,"title":"Langton's ant"},{"categories":null,"contents":"Summary In statistics, least-angle regression (LARS) is an algorithm for fitting linear regression models to high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani.[1]\nSuppose we expect a response variable to be determined by a linear combination of a subset of potential covariates. Then the LARS algorithm provides a means of producing an estimate of which variables to include, as well as their coefficients.\nInstead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the L1 norm of the parameter vector. The algorithm is similar to forward stepwise regression, but instead of including variables at each step, the estimated parameters are increased in a direction equiangular to each one\u0026rsquo;s correlations with the residual.\n","permalink":"https://ruivieira.dev/lars-path.html","tags":null,"title":"LARS path"},{"categories":null,"contents":"Notes on LaTeX.\nImages side-by-side Use the subfig package.\n\\documentclass[10pt,a4paper]{article} \\usepackage[demo]{graphicx} \\usepackage{subfig} \\begin{document} \\begin{figure}%  \\centering  \\subfloat[\\centering label 1]{{\\includegraphics[width=5cm]{img1} }}%  \\qquad  \\subfloat[\\centering label 2]{{\\includegraphics[width=5cm]{img2} }}%  \\caption{2 Figures side by side}%  \\label{fig:example}% \\end{figure} \\end{document} ","permalink":"https://ruivieira.dev/latex.html","tags":null,"title":"LaTeX"},{"categories":null,"contents":"Notes on Linux admin.\n","permalink":"https://ruivieira.dev/linux-admin.html","tags":null,"title":"Linux admin"},{"categories":null,"contents":"Introduction Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture.\nResources   Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen netzen [in german] diploma thesis. TU Munich, (https://people.idsia.ch//~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf).  Bengio, Y., Simard, P., \u0026amp; Frasconi, P. (1994). Learning long-term dependencies with gradient descent is difficult. IEEE transactions on neural networks, 5(2), 157â166.  Hochreiter, S., \u0026amp; Schmidhuber, Jurgen (1997). Long short-term memory. Neural computation, 9(8), 1735â1780. http://www.bioinf.jku.at/publications/older/2604.pdf  Gers, F. A., \u0026amp; Schmidhuber, Jurgen (2000). Recurrent nets that time and count. In , Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium (pp. 189â194). : . ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf  Cho, K., Van Merrenboer, Bart, Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., \u0026amp; Bengio, Y. (2014). Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, (), . http://arxiv.org/pdf/1406.1078v3.pdf  Yao, K., Cohn, T., Vylomova, K., Duh, K., \u0026amp; Dyer, C. (2015). Depth-Gated Lstm. http://arxiv.org/pdf/1508.03790v2.pdf  KoutnÃ­k, J., Greff, K., Gomez, F., \u0026amp; Schmidhuber, J. (2014). A Clockwork Rnn. http://arxiv.org/pdf/1402.3511v1.pdf  Greff, K., Srivastava, R. K., Koutnik, J., Steunebrink, B. R., \u0026amp; Schmidhuber, J. (2017). Lstm: a search space odyssey. IEEE Transactions on Neural Networks and Learning Systems, 28(10), 2222â2232. http://dx.doi.org/10.1109/tnnls.2016.2582924 http://arxiv.org/pdf/1503.04069.pdf  Jozefowicz, R., Zaremba, W., \u0026amp; Sutskever, I. (2015). An empirical exploration of recurrent network architectures. In , International conference on machine learning (pp. 2342â2350). : . http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf  Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R., \u0026hellip; (2016). Show, attend and tell: neural image caption generation with visual attention. http://arxiv.org/pdf/1502.03044v2.pdf  Kalchbrenner, N., Danihelka, I., \u0026amp; Graves, A. (2016). Grid Long Short-Term Memory. http://arxiv.org/pdf/1507.01526v1.pdf  Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., \u0026amp; Wierstra, D. (2015). Draw: a recurrent neural network for image generation. http://arxiv.org/pdf/1502.04623.pdf  Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A., \u0026amp; Bengio, Y. (2016). A recurrent latent variable model for sequential data. http://arxiv.org/pdf/1506.02216v3.pdf  Bayer, J., \u0026amp; Osendorfer, C. (2015). Learning Stochastic Recurrent Networks. http://arxiv.org/pdf/1411.7610v3.pdf  ","permalink":"https://ruivieira.dev/lstm.html","tags":null,"title":"LSTM"},{"categories":null,"contents":"Notes on machine learning.\nTopics Synthetic data Generation  Using Synthetic data with SDV and Gaussian copulas, Synthetic data with SDV and CTGAN and Synthetic data with SDV and CopulaGAN.  Explainability Time-series  Time-series analysis  Clustering  K-means clustering  Fairness  Fairness in machine learning Model fairness  Metrics  Error metrics Distance metrics  Optimisation  Gradient descent Stochastic Gradient Descent Stochastic Gradient descent with momentum Mini-Batch Gradient Descent Adagrad RMSProp AdaDelta Adam Gradient-free optimisation  RNN  LSTM  Statistics  Streaming statistics  Unsupervised methods  Self-organising maps  Frameworks  Cookiecutter Data Science Scikit-learn  ","permalink":"https://ruivieira.dev/machine-learning.html","tags":null,"title":"Machine learning"},{"categories":null,"contents":"Summary Notes on the Maven build system.\nArtifacts Ãber JARs There are many ways to build Ã¼ber JARs, but we will talk about two, maven-assembly-plugin and maven-shade-plugin.\nAssembly The maven-assembly-pluginiÂ 1 adds all dependencies inside the final fat JAR and can be used by adding the following to your pom.xml:\n\u0026lt;plugin\u0026gt;  \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;  \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt;  \u0026lt;configuration\u0026gt;  \u0026lt;descriptorRefs\u0026gt;  \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt;  \u0026lt;/descriptorRefs\u0026gt;  \u0026lt;archive\u0026gt;  \u0026lt;manifest\u0026gt;  \u0026lt;mainClass\u0026gt;{your.package.main.class}\u0026lt;/mainClass\u0026gt;  \u0026lt;/manifest\u0026gt;  \u0026lt;/archive\u0026gt;  \u0026lt;/configuration\u0026gt;  \u0026lt;executions\u0026gt;  \u0026lt;execution\u0026gt;  \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;  \u0026lt;goals\u0026gt;  \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt;  \u0026lt;/goals\u0026gt;  \u0026lt;/execution\u0026gt;  \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; Shade The maven-shade-pluginÂ 2 also adds all dependencies inside the final fat JAR, but additionally executes shading. Add the following to your pom.xml:\n\u0026lt;plugin\u0026gt;  \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;  \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;  \u0026lt;configuration\u0026gt;  \u0026lt;transformers\u0026gt;  \u0026lt;transformer implementation=\u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt;  \u0026lt;mainClass\u0026gt;{your.package.main.class}\u0026lt;/mainClass\u0026gt;  \u0026lt;/transformer\u0026gt;  \u0026lt;/transformers\u0026gt;  \u0026lt;/configuration\u0026gt;  \u0026lt;executions\u0026gt;  \u0026lt;execution\u0026gt;  \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;  \u0026lt;goals\u0026gt;  \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;  \u0026lt;/goals\u0026gt;  \u0026lt;/execution\u0026gt;  \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt;   https://maven.apache.org/plugins/maven-assembly-plugin/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://maven.apache.org/plugins/maven-shade-plugin/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/maven.html","tags":null,"title":"Maven"},{"categories":null,"contents":"It is said that patience is a virtue but the truth is that no one likes waiting (especially waiting around: this interesting article explores why people prefer walking 8 minutes to the airportâs baggage claim and having the bags ready rather than waiting the same amount of time entirely in the claim area).\nAnyone performing computationally heavy work, such as Monte Carlo methods, will know that these are usually computationally expensive algorithms which, even in modern hardware, can result in waiting times in the magnitude of hours, days and even weeks.\nThese long running times coupled with the fact that in certain cases it is not easy to accurately predict how long a certain number of iterations will take, usually leads to a tiresome behaviour of constantly checking for good (or bad) news.\nAlthough it is perfectly possible to specify that your simulation should stop after a certain amount of time (especially valid for very long simulations), this doesnât seem to be the standard practice.\nIn this post Iâll detail my current setup for being notified exactly of when simulations are finished. To implement this setup, the following stack is required:\n A JDK Apache Maven A messaging service Pushbullet A smartphone, tablet, smartwatch (or any other internet enabled device)  To start, we can create an account in Pushbullet, which will involve, in the simplest case, signing up using some authentication service such as Google.\nNext, we will install the client application (available for Android, iOS and most modern browsers after which we can enable notifications (at least in the Android client, Iâm not familiar with the iPhone version).\nSince my current work started as a plain Java project which in time evolved mainly to Scala, it consists of an unholy mixture of Maven as a build tool for Scala code.\nThis shouldn\u0026rsquo;t be a problem for other setups, but Iâll just go through my specific setup (i.e. using Maven dependencies to a Scala project).\nTo implement communication between the code and the messaging service, we can use a simple library such as jpushbullet.\nThe library works well enough, although at the time of writing it only supports Pushbulletâs v1 API but not the newer v2 API.\nSince the project, unfortunately, is not in Maven central, you should build it from scratch. Fortunately, in a sensibly configured machine, this is trivial.\nIn the machine where you plan to perform the simulations, clone and build jpushbullet.\n$ git clone git@github.com:silk8192/jpushbullet.git $ mvn clean install Once the build is complete, you can add it as a local dependency in your projectâs `pom.xml`:\n\u0026lt;dependencies\u0026gt;  \u0026lt;dependency\u0026gt;  \u0026lt;groupId\u0026gt;com.shakethat.jpushbullet\u0026lt;/groupId\u0026gt;  \u0026lt;artifactId\u0026gt;jpushbullet\u0026lt;/artifactId\u0026gt;  \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; For the purpose of this example, lets assume that you have the following Object as the entry point of your simulation. The next step is to add a call to the Pushbullet service before the exit point. Please keep in mind that it is very bad practice to include your personal API key in your committed code. I strongly suggest you keep this information in a separate file (e.g. in resources), read it at runtime and add it to .gitignore.\nThat being said, place the messaging code as such:\npackage benchmarks import com.shakethat.jpushbullet.PushbulletClient  object MCMC { \tdef main(args:Array[String]):Unit = { \t// Your MCMC code \tval client = new PushbulletClient(api\\_key) \tval devices = client.getDevices \tval title = \u0026#34;MCMC simulation finished\u0026#34; \tval body = \u0026#34;Some summary can be included\u0026#34;  \t// n is the preferred device number \tclient.sendNote(true, \tdevices \t.getDevices \t.get(n) \t.getIden(), title, body) \t}  } Usually, I would call this code via ssh into my main machine from Maven (using Scala Maven) as:\n$ nohup mvn scala:run -DmainClass=benchmarks.MCMC \u0026amp; Finally, when the simulation is completed, you will be notified in the client devices (you can select which ones by issuing separate sendNote calls) and include a result summary, as an example.\n My current setup generates an R script from a template which is run by Rscript in order to produce a PDF report. However, be careful, since file quotas in Pushbullet are limited, so text notifications should be used without worry of going over the free usage tier.\nKeep in mind that there are other alternatives to jpushbullet, such as send-notification, a general notification library for Java for which the setup is quite similar.\nHope this was helpful.\n","permalink":"https://ruivieira.dev/mcmc-notifications.html","tags":null,"title":"MCMC notifications"},{"categories":null,"contents":"Recently I\u0026rsquo;ve been following (but not very closely, I admit) the development of the GraalVM project. The project has many interesting goals (such as Project Metropolis, increased JIT performance and others).\nHowever, having dabbled with projects such as Scala native and Kotlin native, one of the aspects of GraalVM that caught my attention was the SubstrateVM, which allegedly allows for a simple, straight-forward compilation of any Java bytecode into a native binary.\nI specifically wanted to compare the performance and memory consumption of simple scientific computing tasks when using the JVM and native executables. To do this, I picked two simple numerical simulations in the form of toy Gibbs samplers, in order to keep the cores busy for a while.\nBinomial-Beta case The first problem chosen was the one of sampling from a Beta-Binomial distribution where we have\n\\[ X \\sim \\text{Binom}\\left(n,\\theta\\right) \\\\\\\\ \\theta \\sim \\text{B}\\left(a,b\\right). \\]\nSince we know that\n\\[ \\pi\\left(\\theta|x\\right) \\propto \\theta^x \\left(1-\\theta\\right)^{n-x}\\theta^{a-1}\\left(1-\\theta\\right)^{b-1}, \\]\nWe calculate the joint density\n\\[ p(x,\\theta) = \\begin{pmatrix} n \\\\\\ x \\end{pmatrix} \\theta^x \\left(1-\\theta\\right)^{n-x}\\frac{\\Gamma\\left(a+b\\right)}{\\Gamma(a)\\Gamma(b)}\\theta^{a-1}\\left(1-\\theta\\right)^{b-1} \\]\nThe marginal distribution is a Binomial-Beta:\n\\[ p\\left(x\\right)=\\begin{pmatrix} n \\\\\\ x \\end{pmatrix}\\frac{\\Gamma\\left(a+b\\right)}{\\Gamma(a)\\Gamma(b)}\\frac{\\Gamma\\left(a+b\\right)\\Gamma\\left(b+n-x\\right)}{\\Gamma\\left(a+b+n\\right)},\\qquad x=0,1,\\cdots,n. \\]\nThe code for this simulation is available here.\nThe project is setup so that Maven produces an assembly Jar file, since I\u0026rsquo;ve found that to be the easier artifact we can offer to the GraalVM\u0026rsquo;s native compiler. To enable assembly Jars we add the maven-assembly-plugin to pom.xml and specify a main class. The assembly can then be produced simply by executing\nmvn package An assembly Jar should be available in the target folder and named benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies.jar. Both the Jar and the native executable allow to specify how many iterations the Gibbs sampler should run for (as well as the thinning factor). If nothing is specified, the default will be used, which is \\(50000\\) iterations thinned by \\(100\\).\nThis particular Gibbs sampler was implemented in two variants. One variant stores the samples draws of \\(x\\) and \\(\\theta\\) in arrays double[] while the other one simply calculates the Gibbs steps by using the previous value, that is \\(x_i=f(x_{i-1},\\theta_{i-1})\\) and then discarding the previous values. The latter has a constant memory cost in \\(\\mathcal{O}(1)\\) in terms of number of iterations, while the former clearly doesn\u0026rsquo;t.\nWe can them proceed with the first test, first benchmarking it under the JVM by running (for both sample history variants):\n$ /usr/bin/time -v java -jar target/benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies.jar store 50000 100 $ /usr/bin/time -v java -jar target/benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies.jar nostore 50000 100 (It is important to note that the time command is the executable under /usr/bin and not your shell\u0026rsquo;s builtin.) The next step is to build the native image using GraalVM\u0026rsquo;s compiler. This is also quite straight-forward and simply a matter of calling:\n$GRAALVM_BIN/native-image target/benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies.jar where $GRAALVM_BIN is simply the location where you installed the GraalVM binaries. If the compilation is successful, you should see some information about the compilation steps, such as parsing, inlining, compiling and writing the image. Finally, if using the default, you should have a native executable available in your current directory. Again, the benchmark command is similar to the JVM step, that is:\n$ /usr/bin/time -v ./benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies store 50000 100 $ /usr/bin/time -v ./benchmark-gibbs-1.0-SNAPSHOT-jar-with-dependencies nostore 50000 100 The results from the runs which saved the sampling history on both platforms (JVM and native) were consistent as we can see from the plots below:\n The (peak) memory consumption and execution time for each version is presented in the table below:\n    Time(s) Peak (Mb)     JVM (no sample history) 110.09 320.913   native (no sample history) 130.52 273.747   JVM (sample history) 112.51 324.796   native (sample history) 130.62 274.239    Another bivariate case The second problem chosen is another bivariate model, a Gibbs sampler in this blog. The code is included in the same repositoty as the Beta-Binomial case and the setup for the benchmarks is similar. The only step needed to run this example is to change the main class in the assemply plugin section of the pom.xml from BinomialBet~a to ~Bivariate. The benchmark results are in the table below:\n    Time(s) Peak (Mb)     JVM 106.92 176.541   native 121.29 273.383    Now, in this case, the results are much more interesting. The JVM version outperforms the native version in both execution time and memory consumption. I don\u0026rsquo;t have an explanation for this, but if you think you have (or have any other questions) please let me know on Mastodon or Twitter.\nThanks for reading!\n","permalink":"https://ruivieira.dev/mcmc-performance-on-substrate-vm.html","tags":null,"title":"MCMC performance on substrate VM"},{"categories":null,"contents":"Introduction Page on Minikube.\nSetup Most of the configuration settings can be set using the config subcommand.\nKubernetes version Set the Kubernetes cluster version (e.g 1.19).\n$ minikube config set kubernetes-version v1.19.0 Memory Set the available amount of memory.\n$ minikube config set memory 8000 ","permalink":"https://ruivieira.dev/minikube.html","tags":null,"title":"Minikube"},{"categories":null,"contents":" Unfairness detection  ","permalink":"https://ruivieira.dev/model-fairness.html","tags":null,"title":"Model fairness"},{"categories":null,"contents":"Monotonic Cubic Spline interpolation (MCSI) is a popular and useful method which fits a smooth, continuous function through discrete data. MCSI has several applications in the field of computer vision and trajectory fitting. MCSI further guarantees monotonicity of the smoothed approximation, something which a cubic spline approximation alone cannot. In this post I\u0026rsquo;ll show how to implement the method developed by F. N. Fritsch and R. E. Carlson1 in the Rust programming language.\nRust Why Rust? Definitely this is a type of solution so simple that it can be implemented in practically any programming language we can think of. However, I do find that the best way to get acquainted with a new language and its concepts is precisely to try to implement a simple and well-know solution. Although this post does not intend to be an introduction to the Rust language, some of the fundamentals will be presented as we go along.\nIdiomatic Rust Object-Oriented Programming (OOP) has several characteristics which differ significantly from \u0026ldquo;traditional\u0026rdquo; OOP languages. Rust achieves data and behaviour encapsulation by means of defining data structure blueprints (called struct) and then defining their behaviour though a concrete implementation (through impl). As an example, a simple \u0026ldquo;class\u0026rdquo; Foo would consist of:\nstruct Foo{}implFoo{fn new()-\u0026gt; Foo{returnFoo{};}fn method(\u0026amp;mutself){}fn static_method(){}}pubfn main(){letmutf=Foo::new();f.method();Foo::static_method();}The \u0026ldquo;constructor\u0026rdquo; is defined typically as new(), but any \u0026ldquo;static\u0026rdquo; method which returns an initialised struct can be a constructor and \u0026ldquo;object\u0026rdquo; methods include the passing of the self instance not unlike languages such as Python. The \u0026amp;mut self refers to the control or exclusive access to self and it is not directly related to mut mutability control. These concepts touch on Rust\u0026rsquo;s borrowing and ownership model which, unfortunately, are way beyond the scope of this blog post. A nice introduction is provided by the \u0026ldquo;Rust programming book\u0026rdquo; available here. Our implementation aims at building a MCSI class MonotonicCubicSpline by splitting the algorithm into the slope calculation at construction time, a Hermite interpolation function and a partial application function generator. This will follow the general structure\npubstruct MonotonicCubicSpline{m_x: Vec\u0026lt;f64\u0026gt;,m_y: Vec\u0026lt;f64\u0026gt;,m_m: Vec\u0026lt;f64\u0026gt;}implMonotonicCubicSpline{pubfn new(x: \u0026amp;Vec\u0026lt;f64\u0026gt;,y: \u0026amp;Vec\u0026lt;f64\u0026gt;)-\u0026gt; MonotonicCubicSpline{// ... }pubfn hermite(point: f64,x: (f64,f64),y: (f64,f64),m: (f64,f64))-\u0026gt; f64 {// ... }pubfn interpolate(\u0026amp;mutself,point: f64)-\u0026gt; f64 {// ... }fn partial(x: Vec\u0026lt;f64\u0026gt;,y: Vec\u0026lt;f64\u0026gt;)-\u0026gt; implFn(f64)-\u0026gt; f64 {// ... }}Vec is a vector, a typed growable collection available in Rust\u0026rsquo;s standard library with documentation available here.\nMonotonic Cubic Splines MCSI hinges on the concept of cubic Hermite interpolators. The Hermite interpolation for the unit interval for a generic interval \\((x_k,x_{k+1})\\) is\n\\[ p(x)=p_k h_{00}(t)+ h_{10}(t)(x_{k+1}-x_k)m_k + \\\\ h_{01}(t)p_{k+1} + h_{11}(t)(x_{k+1}-x_{k})m_{k+1}. \\]\nThe \\(h_{\\star}\\) functions are usually called the Hermite basis functions in the literature and here we will use the factorised forms of:\n\\begin{aligned} h_{00}(t) \u0026amp;= (1+2t)(1-t)^2 \\\\ h_{10}(t) \u0026amp;= t(1-t)^2 \\\\ h_{01}(t) \u0026amp;= t^2 (3-2t) \\\\ h_{11}(t) \u0026amp;= t^2 (t-1). \\end{aligned}\nThis can be rewritten as\n\\[ p(x) = (p_k(1 + 2t) + \\Delta x_k m_k t)(1-t)(1-t) + \\\\ (p_{k+1} (3 -2t) + \\Delta x_k m_{k+1} (t-1))t^2 \\]\nwhere\n\\begin{aligned} \\Delta x_k \u0026amp;= x_{k+1} - x_k \\\\ t \u0026amp;= \\frac{x-x_k}{h}. \\end{aligned}\nThis associated Rust method is the above mentioned \u0026ldquo;static\u0026rdquo; MonotonicCubicSpline::hermite():\npubfn hermite(point: f64,x: (f64,f64),y: (f64,f64),m: (f64,f64))-\u0026gt; f64 {leth=x.1-x.0;lett=(point-x.0)/h;return(y.0(1.0+2.0t)+hm.0t)(1.0-t)(1.0-t)+(y.1(3.0-2.0t)+hm.1(t-1.0))tt;}where the tuples correspond to \\(x \\to (x_k, x_{k+1})\\), \\(t \\to (y_k, y_{k+1})\\) and \\(m \\to (m_k, m_{k+1})\\)\nFor a series of data points \\((x_k, y_k)\\) with \\(k=1,\\dots,n\\) we then calculate the slopes of the secant lines between consecutive points, that is:\n\\[ \\Delta_k = \\frac{\\Delta y_{k}}{\\Delta x_k},\\qquad \\text{for}\\ k=1,\\dots,n-1 \\]\nwith \\(Delta y_k = y_{k+1}-y_k\\) and \\(\\Delta x_k\\) as defined previously.\n Since the data is represented by the vectors x : Vec\u0026lt;f64\u0026gt; and y : Vec\u0026lt;f64\u0026gt; we implement this in the \u0026ldquo;constructor\u0026rdquo;:\nletmutsecants=vec![0.0;n-1];letmutslopes=vec![0.0;n];foriin0..(n-1){letdx=x[i+1]-x[i];letdy=y[i+1]-y[i];secants[i]=dy/dx;}The next step is to average the secants in order to get the tangents, such that\n\\[ m_k = \\frac{\\Delta_{k-1}+\\Delta_k}{2},\\qquad \\text{for}\\ k=2,\\dots,n-1. \\]\nThis is achieved by the code:\nslopes[0]=secants[0];foriin1..(n-1){slopes[i]=(secants[i-1]+secants[i])*0.5;}slopes[n-1]=secants[n-2];By definition, we want to ensure monotonicity of the interpolated points, but to guarantee this we must avoid the interpolation spline to go too far from a certain radius of the control points. If we define \\(\\alpha_k\\) and \\(\\beta_k\\) as\n\\begin{aligned} \\alpha_k \u0026amp;= \\frac{m_k}{\\Delta_k} \\\\ \\beta_k \u0026amp;= \\frac{m_{k+1}}{\\Delta_k}, \\end{aligned}\nto ensure the monotonicity of the interpolation we can impose the following constraint on the above quantities:\n\\[ \\phi(\\alpha, \\beta) = \\alpha - \\frac{(2\\alpha+\\beta-3)^2}{3(\\alpha+\\beta-2)}\\geq 0, \\]\nthat is\n\\[ \\alpha + 2\\beta - 3 \\leq 0, \\text{or}\\ 2\\alpha+\\beta-3 \\leq 0 \\]\nTypically the vector \\((\\alpha_k, \\beta_k)\\) is restricted to a circle of radius 3, that is\n\\[ \\alpha^2_l + \\beta_k^2\u0026gt;9, \\]\nand then setting\n\\[ m_{k+1} = t\\beta_k\\Delta_k, \\]\nwhere\n\\begin{aligned} h \u0026amp;= \\sqrt{\\alpha^2_k + \\beta^2_k} \\\\ t \u0026amp;= \\frac{3}{h}. \\end{aligned}\nOne of the ways in which Rust implements polymorphism is through method dispatch. The f64 primitive provides a shorthand for the quantity \\(\\sqrt{\\alpha^2_k + \\beta^2_k}\\) as \\(\\alpha.\\text{hypot}(\\beta)\\). The relevant Rust code will then be:\nforiin0..(n-1){ifsecants[i]==0.0{slopes[i]=0.0;slopes[i+1]=0.0;}else{letalpha=slopes[i]/secants[i];letbeta=slopes[i+1]/secants[i];leth=alpha.hypot(beta);ifh\u0026gt;3.0{lett=3.0/h;slopes[i]=t*alpha*secants[i];slopes[i+1]=t*beta*secants[i];}}}We are now able to define a \u0026ldquo;smooth function\u0026rdquo; generator using MCSI. We generate a smooth function \\(g(\\cdot)\\) given a set of \\((x_k, y_k)\\) points, such that\n\\[ f(x_k, y_k, p) \\to g(p). \\]\nPartial application Before anything, it is important to recall the difference between partial application and currying, since the two are (incorrectly) used interchangeably quite often. Function currying allows to factor functions with multiple arguments into a chain of single-argument functions, that is\n\\[ f(x, y, z) = h(x)(y)(z) \\]\nThe concept is prevalent in functional programming, since its initial formalisation2. Partial application, however, generally aims at using an existing function conditioned on some argument as a basis to build functions with a reduced arity. In this case this would be useful since ultimately we want to create a smooth, continuous function based on the control points \\((x_k, y_k)\\). The partial application implementation is done in Rust as\npubfn partial(x: Vec\u0026lt;f64\u0026gt;,y: Vec\u0026lt;f64\u0026gt;)-\u0026gt; implFn(f64)-\u0026gt; f64 {move|p|{letmutspline=MonotonicCubicSpline::new(\u0026amp;x,\u0026amp;y);spline.interpolate(p)}}An example of how to generate a concrete smoothed continuous function from a set of control points can be:\nletx=vec![0.0,2.0,3.0,10.0];lety=vec![1.0,4.0,8.0,10.5];letg=partial(x,y);// calculate an interpolated point letpoint=g(0.39); The full code can be found here.\n   Fritsch, F. N., \u0026amp; Carlson, R. E. (1980). Monotone piecewise cubic interpolation. SIAM Journal on Numerical Analysis, 17(2), 238â246.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n :  Curry, H. B., Feys, R., Craig, W., Hindley, J. R., \u0026amp; Seldin, J. P. (1958). Combinatory logic. : North-Holland Amsterdam.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/monotonic-cubic-spline-interpolation-with-some-rust.html","tags":null,"title":"Monotonic Cubic Spline interpolation (with some Rust)"},{"categories":null,"contents":"To instal navi1 on Linux you can use\n$ bash \u0026lt;(curl -sL https://raw.githubusercontent.com/denisidoro/navi/master/scripts/install) When installing navi on Ubuntu 20 you will get the error\ninvalid preview window layout: up:2:nohidden invalid preview window layout: up:2:nohidden invalid preview window layout: up:2:nohidden This is very likely due to the fact that the fzf[fn:fzf] version is too old (perhaps 0.20).\nTo upgrade to the latest version of fzf use:\n$ git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf $ ~/.fzf/install Importing cheatsheets You can import cheatsheets from any git repository that includes .cheat files:\n$ navi repo add https://github.com/ruivieira/cheatsheets External variables It is possible to populate variables with external data in navi. To do so, specify how fzf will extract the data. For instance, the command\ndocker stop \u0026lt;container_id\u0026gt; will stop the container \u0026lt;container_id\u0026gt;, which we could extract from the output of\n$ docker ps We can then specify docker ps and the input of docker stop and instruct fzf on the data\u0026rsquo;s format. For instance, here (line 2) we say that from the command of docker ps we should extract the first column, delimited by spaces and remove the first line, since it is the header.\ndocker stop \u0026lt;container_id\u0026gt; $ container_id: docker ps --- --column 1 --header-lines 1 --delimiter \u0026#39;\\s\\s+\u0026#39;   https://github.com/denisidoro/navi\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/navi.html","tags":null,"title":"Navi"},{"categories":null,"contents":"Notes on the Oil shell and language.\nInstallation macOS Linux The instructions to install on Linux are available in the Oil INSTALL document. Basically, download the release and run a make installation:\n$ wget # latest release $ tar -x --xz \u0026lt; oil-$VERSION.tar.xz $ cd oil-$VERSION $ ./configure $ make $ sudo ./install ","permalink":"https://ruivieira.dev/oil-shell.html","tags":null,"title":"Oil shell"},{"categories":null,"contents":"In the Random Forest algorithm, we build a decision tree (DT) based on a certain training dataset. This tree will be split in order to minimise some criteria function.\nHowever, it is not desirable that individual DTs get too large with too many splits, so a common approach is to train each tree with a subset of the training data (sampled with replacement). This will ensure that individual tree maintain a manageable size, while the variance of the tree ensemble is reduced and the overall bias is not altered.\nThis training subset is usually called the bootstrap samples. In the image below, we can see an illustration of the sampling with replacement.\n","permalink":"https://ruivieira.dev/oob-score-in-random-forests.html","tags":null,"title":"OOB score in random forests"},{"categories":null,"contents":"Example We will be using OptaPlanner to find the roots for a polynomial. We start by defining our planning entity, PolynomialEntity, which will calculate the polynomial value for a specific value. The polynomial we will use is\n\\[ f(x) = 2x^3 + 3x^2 + x + 6 \\]\nThis polynomial has a root for \\(x=-2\\). The entity is then\nDefine the Lesson:\nimport org.optaplanner.core.api.domain.entity.PlanningEntity; import org.optaplanner.core.api.domain.valuerange.ValueRange; import org.optaplanner.core.api.domain.valuerange.ValueRangeFactory; import org.optaplanner.core.api.domain.valuerange.ValueRangeProvider; import org.optaplanner.core.api.domain.variable.PlanningVariable;  @PlanningEntity  public class PolynomialEntity {  private double value;   private PolynomialEntity() {  }   public PolynomialEntity(double i) {  this.value = i;  }   @Override public String toString() {  return \u0026#34;PolynomialEntity{\u0026#34; +  \u0026#34;value=\u0026#34; + value +  \u0026#39;}\u0026#39;;  }   @PlanningVariable(valueRangeProviderRefs = { \u0026#34;polynomialRange\u0026#34; })  public Double getValue() {  return value;  }   public void setValue(Double value) {  this.value = value;  }   @ValueRangeProvider(id = \u0026#34;polynomialRange\u0026#34;)  public ValueRange\u0026lt;Double\u0026gt; getCountValue() {  return ValueRangeFactory.createDoubleValueRange(-100, 100);  }   public double calculate() {  return 2.0 * Math.pow(this.value, 3) + 3 * Math.pow(this.value, 2) + this.value + 6;  }  } We now define the solution PolynomialSolution:\nimport org.optaplanner.core.api.domain.solution.PlanningEntityProperty; import org.optaplanner.core.api.domain.solution.PlanningScore; import org.optaplanner.core.api.domain.solution.PlanningSolution; import org.optaplanner.core.api.score.buildin.simplebigdecimal.SimpleBigDecimalScore;  @PlanningSolution public class PolynomialSolution {   @PlanningEntityProperty  PolynomialEntity polynomialEntity;   @PlanningScore  private SimpleBigDecimalScore score;   public PolynomialSolution() {  this.polynomialEntity = new PolynomialEntity(0.0);  }   public PolynomialSolution(PolynomialEntity polynomialEntity) {  this.polynomialEntity = polynomialEntity;  }   public PolynomialEntity getPolynomialEntity() {  return polynomialEntity;  }   public void setPolynomialEntity(PolynomialEntity polynomialEntity) {  this.polynomialEntity = polynomialEntity;  }   public SimpleBigDecimalScore getScore() {  return score;  }  } And the score calculator:\nimport java.math.BigDecimal;  import org.optaplanner.core.api.score.buildin.simplebigdecimal.SimpleBigDecimalScore; import org.optaplanner.core.api.score.calculator.EasyScoreCalculator;  public class PolynomialEasyScoreCalculator implements EasyScoreCalculator\u0026lt;PolynomialSolution, SimpleBigDecimalScore\u0026gt; {   @Override  public SimpleBigDecimalScore calculateScore(PolynomialSolution polynomialSolution) {  PolynomialEntity entity = polynomialSolution.getPolynomialEntity();  double y = -Math.abs(entity.calculate());  return SimpleBigDecimalScore.of(BigDecimal.valueOf(y));  }  } Finally we run it\nimport org.optaplanner.core.api.solver.Solver; import org.optaplanner.core.api.solver.SolverFactory; import org.optaplanner.core.config.solver.SolverConfig; import org.optaplanner.core.config.solver.termination.TerminationConfig;  SolverFactory\u0026lt;PolynomialSolution\u0026gt; solverFactory = SolverFactory.create(new SolverConfig()  .withSolutionClass(PolynomialSolution.class)  .withEntityClasses(PolynomialEntity.class)  .withEasyScoreCalculatorClass(PolynomialEasyScoreCalculator.class)  .withTerminationConfig(new TerminationConfig().withSecondsSpentLimit(5L)));  // Load the problem PolynomialSolution problem = new PolynomialSolution();  // Solve the problem Solver\u0026lt;PolynomialSolution\u0026gt; solver = solverFactory.buildSolver(); PolynomialSolution solution = solver.solve(problem); System.out.println(solution.getPolynomialEntity()); PolynomialEntity{value=-2.0000069627535737} ","permalink":"https://ruivieira.dev/optaplanner.html","tags":null,"title":"Optaplanner"},{"categories":null,"contents":"Typically the hyper-parameters which will have the most significant impact on the behaviour of a random forest are the following:\n The number of decision trees in a random forest The split criteria Maximum depth of individual trees Minimum samples per internal node Maximum number of leaf nodes Random features per split Number of samples in bootstrap dataset  We will look at each of these hyper-parameters individually with examples of how to select them.\nData To understand how we can optimise the hyperparameters in a random forest model, we will use [Scikit-learn|scikit-learn\u0026rsquo;s]] RandomForestClassifier and a subset of Titanic1 dataset.\nFirst, we will import the features and labels using [Pandas]].\nimport pandas as pd  train_features = pd.read_csv(\u0026#34;data/svm-hyperparameters-train-features.csv\u0026#34;) train_label = pd.read_csv(\u0026#34;data/svm-hyperparameters-train-label.csv\u0026#34;) Let\u0026rsquo;s look at a random sample of entries from this dataset, both for features and labels.\ntrain_features.sample(10)  Pclass Sex Age SibSp Parch Fare 404 3 0 20.0 0 0 8.6625 813 3 0 6.0 4 2 31.2750 790 3 1 30.0 0 0 7.7500 18 3 0 31.0 1 0 18.0000 331 1 1 45.5 0 0 28.5000 99 2 1 34.0 1 0 26.0000 311 1 0 18.0 2 2 262.3750 815 1 1 30.0 0 0 0.0000 44 3 0 19.0 0 0 7.8792 665 2 1 32.0 2 0 73.5000 Some of the available features are:\n Pclass, ticket class Sex Age, age in years Sibsp, number of siblings/spouses aboard Parch, number of parents/children aboard Fare, passenger fare   train_label.sample(10)  Survived 694 0 230 1 600 1 4 0 552 0 815 0 564 0 859 0 724 1 173 0 The outcome label indicates whether a passenger survived the disaster.\nAs part of the typical initial steps for model training, we will prepare the data by splitting it into a training and testing subset.\nfrom sklearn.model_selection import train_test_split  X_train, X_test, y_train, y_test = train_test_split(train_features, train_label, test_size=0.33, random_state=23) Naive model First we will train a \u0026ldquo;naive\u0026rdquo; model, that is a model using the defaults provided by RandomForestClassifier2. These defaults are:\n n_estimators = 10 criterion=âginiâ max_depth=None min_samples_split=2 min_samples_leaf=1 min_weight_fraction_leaf=0.0 max_features=âautoâ max_leaf_nodes=None min_impurity_decrease=0.0 min_impurity_split=None bootstrap=True oob_score=False n_jobs=1 random_state=None verbose=0 warm_start=False class_weight=None  We will instantiate a random forest classifier:\nfrom sklearn.ensemble import RandomForestClassifier  rf = RandomForestClassifier() And training it using the X_train and y_train subsets using the appropriate fit method3.\ntrue_labels = train_label.values.ravel()  rf.fit(X_train, y_train.values.ravel()) RandomForestClassifier() We can now evaluate trained naive model\u0026rsquo;s score.\nfrom sklearn.metrics import precision_score  predicted_labels = rf.predict(X_test)  precision_score(y_test, predicted_labels) 0.7522935779816514 Hyperparameter search A simple example of a generic hyperparameter search using the GridSearchCV method in scikit-learn. The score used to measure the \u0026ldquo;best\u0026rdquo; model is the mean_test_score, but other metrics could be used, such as the [OOB score in random forests|Out-of-bag (OOB)]] error.\nparameters = {  \u0026#34;n_estimators\u0026#34;:[5,10,50,100,250],  \u0026#34;max_depth\u0026#34;:[2,4,8,16,32,None]  } rfc = RandomForestClassifier() from sklearn.model_selection import GridSearchCV cv = GridSearchCV(rfc,parameters,cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5, estimator=RandomForestClassifier(),  param_grid={\u0026#39;max_depth\u0026#39;: [2, 4, 8, 16, 32, None],  \u0026#39;n_estimators\u0026#39;: [5, 10, 50, 100, 250]}) def display(results):  print(f\u0026#39;Best parameters are: {results.best_params_}\u0026#39;)  print(\u0026#34;\\n\u0026#34;)  mean_score = results.cv_results_[\u0026#39;mean_test_score\u0026#39;]  std_score = results.cv_results_[\u0026#39;std_test_score\u0026#39;]  params = results.cv_results_[\u0026#39;params\u0026#39;]  for mean,std,params in zip(mean_score,std_score,params):  print(f\u0026#39;{round(mean,3)}+ or -{round(std,3)}for the {params}\u0026#39;) display(cv) Best parameters are: {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 250}   0.762 + or -0.039 for the {\u0026#39;max_depth\u0026#39;: 2, \u0026#39;n_estimators\u0026#39;: 5} 0.767 + or -0.016 for the {\u0026#39;max_depth\u0026#39;: 2, \u0026#39;n_estimators\u0026#39;: 10} 0.782 + or -0.03 for the {\u0026#39;max_depth\u0026#39;: 2, \u0026#39;n_estimators\u0026#39;: 50} 0.787 + or -0.035 for the {\u0026#39;max_depth\u0026#39;: 2, \u0026#39;n_estimators\u0026#39;: 100} 0.775 + or -0.021 for the {\u0026#39;max_depth\u0026#39;: 2, \u0026#39;n_estimators\u0026#39;: 250} 0.815 + or -0.025 for the {\u0026#39;max_depth\u0026#39;: 4, \u0026#39;n_estimators\u0026#39;: 5} 0.802 + or -0.028 for the {\u0026#39;max_depth\u0026#39;: 4, \u0026#39;n_estimators\u0026#39;: 10} 0.815 + or -0.019 for the {\u0026#39;max_depth\u0026#39;: 4, \u0026#39;n_estimators\u0026#39;: 50} 0.812 + or -0.021 for the {\u0026#39;max_depth\u0026#39;: 4, \u0026#39;n_estimators\u0026#39;: 100} 0.809 + or -0.023 for the {\u0026#39;max_depth\u0026#39;: 4, \u0026#39;n_estimators\u0026#39;: 250} 0.805 + or -0.011 for the {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 5} 0.804 + or -0.014 for the {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 10} 0.815 + or -0.012 for the {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 50} 0.819 + or -0.008 for the {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 100} 0.822 + or -0.016 for the {\u0026#39;max_depth\u0026#39;: 8, \u0026#39;n_estimators\u0026#39;: 250} 0.772 + or -0.036 for the {\u0026#39;max_depth\u0026#39;: 16, \u0026#39;n_estimators\u0026#39;: 5} 0.804 + or -0.039 for the {\u0026#39;max_depth\u0026#39;: 16, \u0026#39;n_estimators\u0026#39;: 10} 0.805 + or -0.019 for the {\u0026#39;max_depth\u0026#39;: 16, \u0026#39;n_estimators\u0026#39;: 50} 0.819 + or -0.023 for the {\u0026#39;max_depth\u0026#39;: 16, \u0026#39;n_estimators\u0026#39;: 100} 0.805 + or -0.024 for the {\u0026#39;max_depth\u0026#39;: 16, \u0026#39;n_estimators\u0026#39;: 250} 0.8 + or -0.025 for the {\u0026#39;max_depth\u0026#39;: 32, \u0026#39;n_estimators\u0026#39;: 5} 0.799 + or -0.024 for the {\u0026#39;max_depth\u0026#39;: 32, \u0026#39;n_estimators\u0026#39;: 10} 0.807 + or -0.022 for the {\u0026#39;max_depth\u0026#39;: 32, \u0026#39;n_estimators\u0026#39;: 50} 0.81 + or -0.027 for the {\u0026#39;max_depth\u0026#39;: 32, \u0026#39;n_estimators\u0026#39;: 100} 0.809 + or -0.022 for the {\u0026#39;max_depth\u0026#39;: 32, \u0026#39;n_estimators\u0026#39;: 250} 0.779 + or -0.041 for the {\u0026#39;max_depth\u0026#39;: None, \u0026#39;n_estimators\u0026#39;: 5} 0.789 + or -0.023 for the {\u0026#39;max_depth\u0026#39;: None, \u0026#39;n_estimators\u0026#39;: 10} 0.807 + or -0.026 for the {\u0026#39;max_depth\u0026#39;: None, \u0026#39;n_estimators\u0026#39;: 50} 0.805 + or -0.033 for the {\u0026#39;max_depth\u0026#39;: None, \u0026#39;n_estimators\u0026#39;: 100} 0.81 + or -0.024 for the {\u0026#39;max_depth\u0026#39;: None, \u0026#39;n_estimators\u0026#39;: 250} Parameters Number of decision trees This is specified using the n_estimators hyper-parameter on the random forest initialisation.\nTypically, a higher number of trees will lead to greater accuracy at the expense of model size and training time.\ncv = GridSearchCV(rfc,{\u0026#34;n_estimators\u0026#34;:[2, 4, 8, 16, 32, 64, 128, 256, 512]},cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5, estimator=RandomForestClassifier(),  param_grid={\u0026#39;n_estimators\u0026#39;: [2, 4, 8, 16, 32, 64, 128, 256, 512]}) results = pd.DataFrame({\u0026#34;n_estimators\u0026#34;: [param[\u0026#34;n_estimators\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results  n_estimators mean_score std_score 0 2 0.775126 0.033603 1 4 0.773515 0.022884 2 8 0.807003 0.032551 3 16 0.802017 0.025230 4 32 0.802031 0.028781 5 64 0.805378 0.017020 6 128 0.810420 0.022129 7 256 0.815462 0.032160 8 512 0.810420 0.017894 from plotnine import *  (  ggplot(results) + geom_boxplot(aes(x=\u0026#39;factor(n_estimators)\u0026#39;, y=\u0026#39;mean_score\u0026#39;)) +  geom_errorbar(aes(x=\u0026#39;factor(n_estimators)\u0026#39;, ymin=\u0026#39;mean_score - std_score\u0026#39;, ymax=\u0026#39;mean_score + std_score\u0026#39;)) +  theme_classic() + xlab(\u0026#39;Number of trees\u0026#39;) + ylab(\u0026#39;Mean score\u0026#39;) )  \u0026lt;ggplot: (326732746)\u0026gt; The split criteria At each node, a random forest decides, according to a specific algorithm, which feature and value split the tree. Therefore, the choice of splitting algorithm is crucial for the random forest\u0026rsquo;s performance.\nSince, in this example, we are dealing with a classification problem, the choices of split algorithm are, for instance:\n Gini Entropy  If we were dealing with a random forest for regression, other methods (such as [Error metrics|MSE]]) would be a possible choice. We will now compare both split algorithms as specified above, in training a random forest with our data:\nrfc = RandomForestClassifier(n_estimators=256)  cv = GridSearchCV(rfc,{\u0026#34;criterion\u0026#34;: [\u0026#34;gini\u0026#34;, \u0026#34;entropy\u0026#34;]},cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=256),  param_grid={\u0026#39;criterion\u0026#39;: [\u0026#39;gini\u0026#39;, \u0026#39;entropy\u0026#39;]}) results = pd.DataFrame({\u0026#34;criterion\u0026#34;: [param[\u0026#34;criterion\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results  criterion mean_score std_score 0 gini 0.815462 0.025828 1 entropy 0.812087 0.025764 Maximum depth of individual trees In theory, the \u0026ldquo;longer\u0026rdquo; the tree, the more splits it can have and better accommodate the data. However, at the tree level can this can lead to overfitting. Although this is a problem for decision trees, it is not necessarily a problem for the ensemble, the random forest. Although the key is to strike a balance between trees that aren\u0026rsquo;t too large or too short, there\u0026rsquo;s no universal heuristic to determine the size. Let\u0026rsquo;s try a few option for maximum depth:\nrfc = RandomForestClassifier(n_estimators=256,  criterion=\u0026#34;entropy\u0026#34;)  cv = GridSearchCV(rfc,{\u0026#39;max_depth\u0026#39;: [2, 4, 8, 16, 32, None]},cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5,  estimator=RandomForestClassifier(criterion=\u0026#39;entropy\u0026#39;,  n_estimators=256),  param_grid={\u0026#39;max_depth\u0026#39;: [2, 4, 8, 16, 32, None]}) results = pd.DataFrame({\u0026#34;max_depth\u0026#34;: [param[\u0026#34;max_depth\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results = results.dropna() results  max_depth mean_score std_score 0 2.0 0.780224 0.022550 1 4.0 0.812143 0.020297 2 8.0 0.817143 0.024915 3 16.0 0.810434 0.023838 4 32.0 0.810406 0.016414 from plotnine import *  (  ggplot(results) + geom_boxplot(aes(x=\u0026#39;factor(max_depth)\u0026#39;, y=\u0026#39;mean_score\u0026#39;)) +  theme_classic() + xlab(\u0026#39;Max tree depth\u0026#39;) + ylab(\u0026#39;Mean score\u0026#39;) )  \u0026lt;ggplot: (326878576)\u0026gt; Maximum number of leaf nodes This hyperparameter can be of importance to other topics, such as [Explainability]].\nIt is specified in scikit-learn using the max_leaf_nodes parameter. Let\u0026rsquo;s try a few different values:\nrfc = RandomForestClassifier(n_estimators=256,  criterion=\u0026#34;entropy\u0026#34;,  max_depth=8)  cv = GridSearchCV(rfc,{\u0026#39;max_leaf_nodes\u0026#39;: [2**i for i in range(1, 8)]},cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5,  estimator=RandomForestClassifier(criterion=\u0026#39;entropy\u0026#39;, max_depth=8,  n_estimators=256),  param_grid={\u0026#39;max_leaf_nodes\u0026#39;: [2, 4, 8, 16, 32, 64, 128]}) results = pd.DataFrame({\u0026#34;max_leaf_nodes\u0026#34;: [param[\u0026#34;max_leaf_nodes\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results = results.dropna() results  max_leaf_nodes mean_score std_score 0 2 0.755042 0.016142 1 4 0.778557 0.015940 2 8 0.810462 0.022316 3 16 0.813796 0.013894 4 32 0.810420 0.017087 5 64 0.817115 0.015382 6 128 0.813754 0.012408 from plotnine import *  (  ggplot(results) + geom_boxplot(aes(x=\u0026#39;factor(max_leaf_nodes)\u0026#39;, y=\u0026#39;mean_score\u0026#39;)) +  geom_errorbar(aes(x=\u0026#39;factor(max_leaf_nodes)\u0026#39;, ymin=\u0026#39;mean_score - std_score\u0026#39;, ymax=\u0026#39;mean_score + std_score\u0026#39;)) +  theme_classic() + xlab(\u0026#39;Maximum leaf nodes\u0026#39;) + ylab(\u0026#39;Mean score\u0026#39;) )  \u0026lt;ggplot: (326892069)\u0026gt; Random features per split This is an important hyperparameter that will depend on how noisy the original data is. Typically, if the data is not very noisy, the number of used random features can be kept low. Otherwise, it needs to be kept high.\nAn important consideration is also the following trade-off:\n A low number of random features decrease the forest\u0026rsquo;s overall variance A low number of random features increases the bias A high number of random features increases computational time  In scikit-learn this is specified with the max_features parameter. Assuming \\(N_f\\) is the total number of features, some possible values for this parameter are:\n sqrt, this will take the max_features as the rounded \\(\\sqrt{N_f}\\) log2, as above, takes the \\(\\log_2(N_f)\\) The actual maximum number of features can be directly specified  Let\u0026rsquo;s try a simple benchmark, even though our data does not have many features to begin with:\nrfc = RandomForestClassifier(n_estimators=256,  criterion=\u0026#34;entropy\u0026#34;,  max_depth=8)  cv = GridSearchCV(rfc,{\u0026#39;max_features\u0026#39;: [\u0026#34;sqrt\u0026#34;, \u0026#34;log2\u0026#34;, 1, 2, 3, 4, 5, 6]},cv=5) cv.fit(X_train, y_train.values.ravel()) results = pd.DataFrame({\u0026#34;max_features\u0026#34;: [param[\u0026#34;max_features\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results from plotnine import *  (  ggplot(results) + geom_boxplot(aes(x=\u0026#39;factor(max_features)\u0026#39;, y=\u0026#39;mean_score\u0026#39;)) +  geom_errorbar(aes(x=\u0026#39;factor(max_features)\u0026#39;, ymin=\u0026#39;mean_score - std_score\u0026#39;, ymax=\u0026#39;mean_score + std_score\u0026#39;)) +  theme_classic() + xlab(\u0026#39;Maximum number of features\u0026#39;) + ylab(\u0026#39;Mean score\u0026#39;) ) Bootstrap dataset size This hyperparameter relates to the proportion of the training data to be used by decision trees.\nIt is specified in scikit-learn by max_samples and can take the value of either:\n None, take the entirety of the samples An integer, representing the actual number of samples A float, representing a proportion between 0 and 1 or the samples to take.  Let\u0026rsquo;s try a hyperparameter search with some values:\nrfc = RandomForestClassifier(n_estimators=256,  criterion=\u0026#34;entropy\u0026#34;,  max_depth=8,  max_features=6)  cv = GridSearchCV(rfc,{\u0026#39;max_samples\u0026#39;: [i/10.0 for i in range(1, 10)]},cv=5) cv.fit(X_train, y_train.values.ravel()) GridSearchCV(cv=5,  estimator=RandomForestClassifier(criterion=\u0026#39;entropy\u0026#39;, max_depth=8,  max_features=6,  n_estimators=256),  param_grid={\u0026#39;max_samples\u0026#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,  0.9]}) results = pd.DataFrame({\u0026#34;max_samples\u0026#34;: [param[\u0026#34;max_samples\u0026#34;] for param in cv.cv_results_[\u0026#39;params\u0026#39;]],  \u0026#34;mean_score\u0026#34;: list(cv.cv_results_[\u0026#39;mean_test_score\u0026#39;]),  \u0026#34;std_score\u0026#34;: cv.cv_results_[\u0026#39;std_test_score\u0026#39;]}) results  max_samples mean_score std_score 0 0.1 0.803754 0.026864 1 0.2 0.818824 0.013165 2 0.3 0.817143 0.015923 3 0.4 0.822157 0.017840 4 0.5 0.815434 0.013033 5 0.6 0.827185 0.019558 6 0.7 0.825518 0.016969 7 0.8 0.827199 0.015364 8 0.9 0.830546 0.021439 from plotnine import *  (  ggplot(results) + geom_boxplot(aes(x=\u0026#39;factor(max_samples)\u0026#39;, y=\u0026#39;mean_score\u0026#39;)) +  geom_errorbar(aes(x=\u0026#39;factor(max_samples)\u0026#39;, ymin=\u0026#39;mean_score - std_score\u0026#39;, ymax=\u0026#39;mean_score + std_score\u0026#39;)) +  theme_classic() + xlab(\u0026#39;Proportion bootstrap samples\u0026#39;) + ylab(\u0026#39;Mean score\u0026#39;) )  \u0026lt;ggplot: (327014903)\u0026gt;   : Titanic Dataset - https://www.kaggle.com/c/titanic-dataset/data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://sklearn.org/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/optimising-random-forest-hyperparamaters.html","tags":null,"title":"Optimising random forest hyperparameters"},{"categories":null,"contents":" Pandas basics  ","permalink":"https://ruivieira.dev/pandas.html","tags":null,"title":"Pandas"},{"categories":null,"contents":"Dataframe operations Create a random dataframe import pandas as pd import numpy as np import warnings  warnings.filterwarnings(\u0026#39;ignore\u0026#39;)  N=100  df = pd.DataFrame({  \u0026#39;a\u0026#39;:np.random.randn(N),  \u0026#39;b\u0026#39;:np.random.choice( [5,7,np.nan], N),  \u0026#39;c\u0026#39;:np.random.choice( [\u0026#39;foo\u0026#39;,\u0026#39;bar\u0026#39;,\u0026#39;baz\u0026#39;], N),  }) df.head()  a b c 0 0.301155 NaN foo 1 -0.529756 7.0 bar 2 0.977581 5.0 foo 3 -1.407260 NaN foo 4 -1.788117 7.0 baz Concatenate dataframes Row-wise To concatenate dataframes row-wise (i.e. to append more rows to dataframes with the same structure) we can use the .concat() method. For instance, if we create a new random dataframe:\ndf_extra = pd.DataFrame({  \u0026#39;a\u0026#39;:np.random.randn(N),  \u0026#39;b\u0026#39;:np.random.choice( [11,12,13], N),  \u0026#39;c\u0026#39;:np.random.choice( [\u0026#39;zombie\u0026#39;,\u0026#39;woof\u0026#39;,\u0026#39;nite\u0026#39;], N),  }) df_extra.head()  a b c 0 -0.052050 11 nite 1 -1.323742 12 woof 2 -0.762396 13 zombie 3 -0.117442 11 zombie 4 0.431727 11 nite We can now concatenate an arbitray number of dataframes by passing them as a list:\ndf_all = pd.concat([df, df_extra]) df_all.sample(9)  a b c 46 -0.471327 13.0 nite 22 0.823330 13.0 woof 91 0.072806 5.0 foo 28 -0.981730 12.0 zombie 73 0.011169 13.0 zombie 19 -0.459916 12.0 zombie 92 1.245264 5.0 bar 7 0.892997 12.0 nite 42 0.455248 7.0 bar Column operations Check column existence The in keyword can be used directly to check column existence.\n\u0026#39;b\u0026#39; in df True Renaming columns df.rename(columns={\u0026#34;a\u0026#34;: \u0026#34;new_name\u0026#34;}, inplace=True) df.columns Index([\u0026#39;new_name\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;], dtype=\u0026#39;object\u0026#39;) Using a mapping function. In this case str.upper():\ndf.rename(columns=str.upper, inplace=True) df.columns Index([\u0026#39;NEW_NAME\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;], dtype=\u0026#39;object\u0026#39;) We can also use a lambda. For instance, using lambda x: x.capitalize() would result:\ndf.rename(columns=lambda x: x.capitalize(), inplace=True) df.columns Index([\u0026#39;New_name\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;], dtype=\u0026#39;object\u0026#39;) A list of column names can be passed directly to columns.\ndf.columns = [\u0026#34;first\u0026#34;, \u0026#34;second\u0026#34;, \u0026#34;third\u0026#34;] df.columns Index([\u0026#39;first\u0026#39;, \u0026#39;second\u0026#39;, \u0026#39;third\u0026#39;], dtype=\u0026#39;object\u0026#39;) Dropping columns A column can be dropped using the .drop() method along with the column keyword. For instance in the dataframe df: We can drop the second column using:\ndf.drop(columns=\u0026#39;second\u0026#39;)  first third 0 0.301155 foo 1 -0.529756 bar 2 0.977581 foo 3 -1.407260 foo 4 -1.788117 baz .. ... ... 95 0.067086 bar 96 -1.446142 baz 97 -1.986560 baz 98 0.765054 bar 99 -0.582712 baz  [100 rows x 2 columns] The del keyword is also a possibility. However, del changes the dataframe in-place, therefore we will make a copy of the dataframe first.\ndf_copy = df.copy() df_copy  first second third 0 0.301155 NaN foo 1 -0.529756 7.0 bar 2 0.977581 5.0 foo 3 -1.407260 NaN foo 4 -1.788117 7.0 baz .. ... ... ... 95 0.067086 5.0 bar 96 -1.446142 5.0 baz 97 -1.986560 5.0 baz 98 0.765054 5.0 bar 99 -0.582712 5.0 baz  [100 rows x 3 columns] del df_copy[\u0026#39;second\u0026#39;] df_copy  first third 0 0.301155 foo 1 -0.529756 bar 2 0.977581 foo 3 -1.407260 foo 4 -1.788117 baz .. ... ... 95 0.067086 bar 96 -1.446142 baz 97 -1.986560 baz 98 0.765054 bar 99 -0.582712 baz  [100 rows x 2 columns] Yet another possibility is to drop the column by index. For instance:\ndf.drop(columns=df.columns[1])  first third 0 0.301155 foo 1 -0.529756 bar 2 0.977581 foo 3 -1.407260 foo 4 -1.788117 baz .. ... ... 95 0.067086 bar 96 -1.446142 baz 97 -1.986560 baz 98 0.765054 bar 99 -0.582712 baz  [100 rows x 2 columns] Or we could use ranges, for instance:\ndf.drop(columns=df.columns[0:2])  third 0 foo 1 bar 2 foo 3 foo 4 baz .. ... 95 bar 96 baz 97 baz 98 bar 99 baz  [100 rows x 1 columns] ","permalink":"https://ruivieira.dev/pandas-basics.html","tags":null,"title":"Pandas basics"},{"categories":null,"contents":"Notes on Pikchr1.\nInstallation Download pikchr from the downloads page To create the CLI command, compile using\n$ gcc -DPIKCHR_SHELL -o pikchr pikchr.c -lm And add it to your path.\nExamples    https://pikchr.org/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/pikchr.html","tags":null,"title":"Pikchr"},{"categories":null,"contents":"Last year (2020) we spent Christmas in \u0026ldquo;lockdown\u0026rdquo; and we tried to make ourselves our full traditional Portuguese Christmas recipes from scratch \u0026ndash; while not being in Portugal. Herein lies the first issue: there are many different \u0026ldquo;traditions\u0026rdquo;, but these are the ones that me and my partner are used to.\nTraditionally, Christmas celebrations in Portugal start on the night of Christmas eve and carry on during Christmas day. The main meals are then dinner on the 24th December and lunch on the 25th December.\nChristmas eve dinner As mentioned, we will follow two separate traditions. From my family\u0026rsquo;s side, originally from the north of Portugal (Porto), we typically have boiled salted cod with vegetables (cabbage, onion and carrots), seasoned with olive oil, vinegar and garlic. From my partner\u0026rsquo;s side, the meal typically consists of octopus rice, accompanied with salted cod fishcakes (\u0026quot;bolinhos de bacalhau\u0026quot;) and pan-fried octopus (\u0026quot;filetes de polvo\u0026quot;).\nSalted cod Salted cod is a staple from Portuguese cuisine, with possible origins in the cod salt-curing methods of Basque fishermen that ventured into Newfoundland in the 1500s1. Going through the centuries, even as recently as 1884, Portuguese writer EÃ§a de Queiroz wrote in a letter to Oliveira Martins about his love of a \u0026ldquo;bacalhau de cebolada\u0026rdquo;2.\n The salted cod needs to be soaked in water for at least four days to remove the excess salt (picture above, on the left).\n It\u0026rsquo;s a really simple dish: just put everything on a pot and let it boil for approximately one hour. Since the salted cod has a really firm fleshy texture, it won\u0026rsquo;t fall apart like fresh fish when boiled for a long time. Usually there\u0026rsquo;s no need to add salt, since the cod will probably still have quite a lot of salt in it, but it never hurts to double check.\nWe will cook around two to three times the amount of cod and vegetables that we need for the actual meal. The reason for this is that the starter for the next day (Roupa-velha) is made from the left-overs of the Christmas eve\u0026rsquo;s dinner. So essentially, we have to make sure we have plenty of left-overs!\n And here it is: ready to tuck in. As you can see, I like my salted cod with a very generous amount of olive oil and vinegar.\nOctopus rice Octopus is another northern Portuguese tradition, especially in the Minho and TrÃ¡s-os-Montes, possibly due to the proximity with Galiza (Galicia) where octopus fishing has been historically a very important activity.\n Next it\u0026rsquo;s the octopus rice. Boil the octopus with just some salt for seasoning. Knowing when the octopus is ready is really an art. Make sure its not undercooked, but don\u0026rsquo;t overcook it either since it will be quite chewy. Brown chopped onions in olive oil and add the water from boiling the octopus along with rice, the octopus and chopped parsley. The rice should have a fair amount of water and not end up dry.\n Part of the octopus goes into the rice and the rest is pan-fried (\u0026quot;filetes de polvo\u0026quot;). They are battered, with eggs and flour, and deep-fried.\n We then proceed to the cod fishcakes (\u0026quot;bolinhos de bacalhau\u0026quot;). These are done by shredding some salted code and mixing it with mashed potato, salt and parsley and then deep-fried.\nChristmas day lunch Roupa-velha  The reason why we cook way more quantities than we need for the salted cod, is to make something called \u0026ldquo;roupa-velha\u0026rdquo; (literal translation \u0026ldquo;old clothes\u0026rdquo;) as a starter on the 25th. This a left-over dish and we use all the left-overs from the Christmas Eve dinner.\n Start by shredding the cooked salted cod and removing all the fish bones and skin.\n We then add a good amount of garlic (two or three cloves at least), and prepare a pan with some olive oil. We put first the garlic and let it brown.\n When the garlic is brown we add all the left-overs (potato, sliced egg, carrot, cabbage and shredded code). We stir it for at least 15 minutes and add vinegar. Lots of vinegar.\n And here it is. Must be eaten while pipping hot.\nLamb roast Usually on the 25th of December we eat a roast (turkey, lamb, goat or pork). We went for a lamb roast. It was seasoned with lemon, rosemary, garlic, paprika, olive oil and salt for four days.\n It is accompanied by roast potatoes and carrots and (optionally) some white rice.\n And here it is!\nDesserts Aletria and arroz doce Aletria is a typical Christmas dessert which is quite similar to rice pudding in taste, but instead of rice, it is done with vermicelli pasta.\n The preparation is quite similar to rice pudding, but adding some lemon peels to the milk mix.\n A cinnamon decoration is a must, here shown with a festive \u0026ldquo;Feliz Natal\u0026rdquo; (Merry Christmas).\n \u0026ldquo;Arroz doce\u0026rdquo; (literal translation Sweet Rice) is very similar to rice pudding, also with the addition of some lemon.\nFilhÃ³s FilhÃ³s are a type of slightly sweet doughy pancake, usually sprinkled with sugar and cinnamon, traditional during Christmas. These are specific type of filhÃ³ called \u0026ldquo;FilhÃ³ tendida no joelho\u0026rdquo;, traditional from the Beiras Portuguese region, where the dough is stretched on top of the knee.\n The dough has to be proven at a certain temperature. Here is the contraption we\u0026rsquo;ve used: a heating fan, heater and an Hibernate (!) book.\n The dough must be proved (in our case at least 10 hours) so it can be stretched and fried lightly in olive oil on both sides. After draining any excess oil, they are sprinkled with a sugar and cinnamon mix.\nRabanadas \u0026ldquo;Rabanadas\u0026rdquo; are in essence very similar to \u0026ldquo;French toast\u0026rdquo;. The way to prepare them is to leave dried bread soaking in milk and drained before deep-frying. After draining, until they are mostly dry and without much excess oil, they are sprinkled (generously) with a mixture of sugar and cinnamon.\n Bolo-Rei Bolo-Rei (literal translation \u0026ldquo;King cake\u0026rdquo;) is a traditional Portuguese Christmas cake. A similar recipe to the modern one can be traced to the 19th century in Loire, southern France, sold for the first time around 1869 at the Confeitaria Nacional, in Lisboa3. Since then it has become very popular and a common sight at Portuguese Christmas tables.\nAlthough it is perfectly possible to do it at home, the one we had was store-bought.\n 2021 update This year (2021) we did another take on the \u0026ldquo;Portuguese Christmas abroad\u0026rdquo; theme. The recipes are still same as last year, so I\u0026rsquo;ve decided to just update with some of the 2021 photos.\nOctopus Last year I didn\u0026rsquo;t include a photo of the octopus being cooked before preparing the Octopus rice, so here it is:\n And here is the fried octopus for this year\u0026rsquo;s Christmas eve dinner:\n FilhÃ³s Something I\u0026rsquo;ve also forgot to add last year was a picture of the FilhÃ³s dough after proving. This year it grew a lot more than last year because we added raw bread dough instead of baker\u0026rsquo;s yeast. Using raw bread dough is actually the proper way to do it, but we didn\u0026rsquo;t have it last year.\n Last year I also didn\u0026rsquo;t include photos of the actual frying of the FilhÃ³s. They are deep-fried in olive oil, (not other vegetable oils) so for this amount of dough a considerable amount was needed. Something between 500-750ml.\n As here is the final product for 2021:\n Rabanadas The 2021 rabanadas. The full story on rabanadas is above:\n Codfish cakes Here are the 2021 bolinhos de bacalhau (salted cod fishcakes):\n Salted cod Cabbage, carrots, onions and eggs waiting for their turn:\n The salted cod draining a little bit, after soaking in water to remove the excess salt for two days.\n Cooking everything!\n And the final product (before a very generous portion of olive oil, as usual)\n Aletria and arroz doce This year\u0026rsquo;s aletria and arroz doce, with the typical \u0026ldquo;Feliz Natal\u0026rdquo; (\u0026quot;Happy Christmas\u0026quot;)\n Roupa-velha And this year\u0026rsquo;s roupa-velha. With a huge amount of vinegar, of course!\n   Silva, AntÃ³nio JosÃ© Marques da (2015), \u0026ldquo;The fable of the cod and the promised sea: About Portuguese traditions of bacalhau\u0026rdquo;, in Barata, Filipe Themudo; Rocha, JoÃ£o MagalhÃ£es (eds.), Heritages and Memories from the Sea, Ãvora, Portugal: 1st International Conference of the UNESCO Chair in Intangible Heritage and Traditional Know-How: Linking Heritage\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n \u0026ldquo;A comida como hÃ¡bito e identidade: o bacalhau e os portugueses\u0026rdquo;, (ISCTE-IUL, Departamento de Antropologia, Escola de CiÃªncias Humanas e Sociais), em 28 de fevereiro de 2013\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n de Lurdes Modesto, Maria, Afonso PraÃ§a, and Nuno Calvet. \u0026ldquo;Festas e comeres do povo portuguÃªs\u0026rdquo;. 1999.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/portuguese-christmas-recipes.html","tags":null,"title":"Portuguese Christmas recipes"},{"categories":null,"contents":"Problem 1 If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n (require \u0026#39;cl)   (apply \u0026#39;+ (remove-if-not  \u0026#39;(lambda (x) (or (zerop (% x 3)) (zerop (% x 5))))  (loop for i from 1 to 999 collect i))) 233168 ","permalink":"https://ruivieira.dev/project-euler-in-elisp.html","tags":null,"title":"Project Euler in Elisp"},{"categories":null,"contents":"Summary Main page for all things Python. Other pages cover specific topics, such as:\n Python environments Python collections Python Pweave Pandas Notes on Python grammar of graphics  Installation Anaconda An option to install Python is to use Anaconda1. Download the appropriate installation file from https://www.anaconda.com/products/individual. And then run the installer with, e.g., sh ./Anaconda3-2021.11-Linux-x86_64.sh. The installation would typically be under $HOME/anaconda3. There is a page dedicated to configuring and using Anaconda.\nLanguage changes In 2021, the Python steering council accepted the proposal to add a pattern-matching primitive to the language. The proposal consists of PEP634 along with PEP635 and PEP636.\nModules Relative import in Python 3 If a relative import is present inside a Python 3 file (e.g. file1) inside a module (e.g. mymod), say\n from .foo import bar We will encounter the error\nImportError: attempted relative import with no known parent package A possible solution is to include the following in your module\u0026rsquo;s __init__.py:\n import os, sys   sys.path.append(os.path.dirname(os.path.realpath(__file__))) Ternary operator Ternary operators help reduce the amount of very small if-else blocks. Python does not have a ternary operator like other languages. However, conditionals can be used to the same effect:\n y = 7  x = 0 if (y == 1) else 1  print(x) for \u0026hellip; else for-else blocks allow to capture if a condition was met inside a for-loop. For instance, consider the following for-loop:\n locations = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;f\u0026#39;]  treasure = False  for location in locations:  if location == \u0026#39;x\u0026#39;:  treasure = True  break  if not treasure:  print(\u0026#34;X marks the spot, but not found\u0026#34;) We can simplify the above logic using a for-else loop:\n for location in locations:  if location == \u0026#39;x\u0026#39;:  break  else:  print(\u0026#34;X marks the spot, but not found\u0026#34;) Boolean unravelling and unravelling the and boolean operator. The operation can be rewritten as the function u_and:\n def u_and(a, b):  result = a  if a:  result = b  return result For instance:\n a = True ; b = None  print(a and b, u_and(a, b))  a = True ; b = True  print(a and b, u_and(a, b))  a = False ; b = True  print(a and b, u_and(a, b)) or On the other hand, `or` cand be unravelled as:\n def u_or(a, b):  result = a  if not a:  result = b  return result As an example:\n a = True ; b = None  print(a or b, u_or(a, b))  a = True ; b = True  print(a or b, u_or(a, b))  a = False ; b = True  print(a or b, u_or(a, b)) The many faces of `print` Concatenating arguments  var1 = \u0026#34;Foo\u0026#34;  var2 = \u0026#34;Bar\u0026#34;  print(\u0026#34;I am \u0026#34;, var1, \u0026#34; not \u0026#34;, var2) It is also possible to use separators by using the `sep` argument:\n var1 = \u0026#34;Foo\u0026#34;  var2 = \u0026#34;Bar\u0026#34;  print(\u0026#34;I am\u0026#34;, var1, \u0026#34;not\u0026#34;, var2, sep=\u0026#34;!\u0026#34;) String termination The `end` argument allows to specify the suffix of the whole string.\n print(\u0026#34;This is on radio\u0026#34;, end=\u0026#34; (over)\u0026#34;) This is on radio (over)\nFilesystem operations Get home directory For Python +3.5:\n from pathlib import Path   home = str(Path.home()) List files recursively For Python +3.5, use glob:\n import glob  # root_dir with trailing slash (i.e. /root/dir/) root_dir = \u0026#34;./tmp\u0026#34; for filename in glob.iglob(root_dir + \u0026#39;**/*.md\u0026#39;, recursive=True):  print(filename) Date operations Offset-aware operations Let\u0026rsquo;s say you have a date without timezone (offset naive), for instance:\nfrom datetime import datetime, timezone  ts = datetime.now().replace(tzinfo=None) print(ts) And you want to calculate the \\(\\delta\\) with a datetime which has a time (offset aware). We\u0026rsquo;ll get an error.\ndelta = datetime.now(timezone.utc) - ts The solution is to add a timezone to the offset naive date. For instance:\nts = datetime.now(timezone.utc)  delta = datetime.now(timezone.utc) - ts print(delta)   https://www.anaconda.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/python.html","tags":null,"title":"Python"},{"categories":null,"contents":"Interpreters To install different Python interpreters I strongly recommend asdf1.\nmacOS To install asdf on a macOS, first install the general dependencies with\n$ brew install coreutils curl git then install asdf itself with\n$ brew install asdf #+end_sr  Add to the shell, in our case [zsh]] with:  #+begin_src bash $ echo -e \u0026#34;\\n. $(brew --prefix asdf)/asdf.sh\u0026#34; \u0026gt;\u0026gt; ~/.zshrc Add a plugin, in our case Python, with\n$ asdf plugin add Python You can list all available versions with\n$ asdf list all Python Install a specific version, say,\n$ asdf install Python 3.9.0 Fedora To install asdf on a Fedora, first install the general dependencies\n$ sudo dnf install curl git Clone the repository\n$ git clone https://github.com/asdf-vm/asdf.git \\  ~/.asdf --branch v0.8.0 Add to zsh with\n$ . $HOME/.asdf/asdf.sh` pyenv Compiling on macOS pyenv can be notoriously problematic on macOS. For instance, running pyenv doctor on my laptop2 will result in:\nCloning ~/.pyenv/plugins/pyenv-doctor/bin/..... Installing python-pyenv-doctor... python-build: use readline from homebrew python-build: use zlib from xcode sdk  BUILD FAILED (OS X 10.15.7 using python-build 20180424)  Inspect or clean up the working tree at /var/folders/c2/9d2fsqt57t10zn1f2ylp1jxw0000gn/T/python-build.20210128094523.17091 Results logged to /var/folders/c2/9d2fsqt57t10zn1f2ylp1jxw0000gn/T/python-build.20210128094523.17091.log  Last 10 log lines: checking readline/readline.h, presence... no checking for readline/readline.h,... no checking readline/rlconf.h usability... yes checking readline/rlconf.h presence... yes checking for readline/rlconf.h... yes checking for SSL_library_init in -lssl... no configure: WARNING: OpenSSL \u0026lt;1.1 not installed. Checking v1.1 or beyond... checking for OPENSSL_init_ssl in -lssl... no configure: error: OpenSSL is not installed. make: *** No targets specified and no makefile found. Stop. Problem(s) detected while checking system.  See https://github.com/pyenv/pyenv/wiki/Common-build-problems for known solutions. The problem in this case is that pyenv can\u0026rsquo;t find the relevant C headers for compilation of new versions. This can be fixed by using:\n$ CFLAGS=\u0026#34;-I$(brew --prefix openssl)/include \\ -I$(brew --prefix readline)/include \\ -I$(xcrun --show-sdk-path)/usr/include\u0026#34; \\  LDFLAGS=\u0026#34;-L$(brew --prefix openssl)/lib \\ -L$(brew --prefix readline)/lib \\ -L$(xcrun --show-sdk-path)/usr/lib\u0026#34; \\  pyenv doctor and the output will be:\nCloning ~/.pyenv/plugins/pyenv-doctor/bin/..... Installing python-pyenv-doctor... python-build: use readline from homebrew python-build: use zlib from xcode sdk Installed python-pyenv-doctor to /var/folders/c2/9d2fsqt57t10zn1f2ylp1jxw0000gn/T/pyenv-doctor.20210128095003.18889/prefix Congratulations! You are ready to build pythons! Poetry Poetry as Jupyter kernel To register a poetry environment (named foo) as a Jupyter kernel, run:\npoetry run python -m ipykernel install --user --name foo venv Create a new venv with the command:\n$ virtualenv venv and activate it using (under Bash or zsh) with:\n$ source venv/bin/activate Anaconda First download Anaconda (or Miniconda). Once installed you can proceed to create environments3.\nCreating environments An environment foo can be created using\nconda create --name foo One it is created, it can be activated using\nconda activate foo   : https://asdf-vm.com/ Let\u0026rsquo;s look at to install Python in two different OSes, macOS and Fedora.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : I\u0026rsquo;m running Big Sur at the moment of writing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n : The remainder will assume that you have installed Anaconda, rather than Miniconda.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/python-environments.html","tags":null,"title":"Python environments"},{"categories":null,"contents":"import pandas as pd  mpg = pd.read_csv(\u0026#34;data/mpg.csv\u0026#34;)  mpg.head()  mpg cylinders displacement horsepower weight acceleration model_year origin name 0 18.000 8 307.000 130 3504 12.000 70 1 chevrolet chevelle malibu 1 15.000 8 350.000 165 3693 11.500 70 1 buick skylark 320 2 18.000 8 318.000 150 3436 11.000 70 1 plymouth satellite 3 16.000 8 304.000 150 3433 12.000 70 1 amc rebel sst 4 17.000 8 302.000 140 3449 10.500 70 1 ford torino from plotnine import * from plotnine.data import *  ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337986928)\u0026gt; ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;, color=\u0026#34;class\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337543711)\u0026gt; ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;, size=\u0026#34;class\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337640355)\u0026gt; # Left ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;, alpha=\u0026#34;manufacturer\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337826997)\u0026gt; # Right ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;, shape=\u0026#34;manufacturer\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337589245)\u0026gt; ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;), color=\u0026#34;blue\u0026#34;) + theme_classic()  \u0026lt;ggplot: (338617082)\u0026gt; ggplot(data=mpg) +\\ geom_smooth(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (332495029)\u0026gt; ggplot(data=mpg) +\\ geom_smooth(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;, linetype=\u0026#34;drv\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (337513662)\u0026gt; ggplot(data=mpg) +\\ geom_point(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;)) +\\ geom_smooth(mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;)) + theme_classic()  \u0026lt;ggplot: (332499978)\u0026gt; ggplot(data=mpg, mapping=aes(x=\u0026#34;displ\u0026#34;, y=\u0026#34;hwy\u0026#34;)) +\\ geom_point(mapping=aes(color=\u0026#34;class\u0026#34;)) +\\ geom_smooth() + theme_classic()  \u0026lt;ggplot: (337996743)\u0026gt; ","permalink":"https://ruivieira.dev/python-grammar-of-graphics.html","tags":null,"title":"Python grammar of graphics"},{"categories":null,"contents":"When preparing a Jupyter notebook for a workshop on recommendation engines which I\u0026rsquo;ve presented with a colleague, I was faced with the following problem:\n \u0026ldquo;How to break a large class definition into several cells so it can be presented step-by-step.\u0026rdquo;\n Having the ability to declare a rather complex (and large) Python class in separate cells has several advantages, the obvious one being the ability to fully document each method\u0026rsquo;s functionality with Markdown, rather than comments. Python does allow for functionality to be added to classes after their declaration via the assignment of methods through attributes. This is commonly known as \u0026ldquo;monkey patching\u0026rdquo; and hinges on the concepts of bound and unbound methods.\nI will show a quick and general overview of the methods that Python puts at our disposal for dynamic runtime object manipulation, but for a more in-depth please consult the official Python documentation.\nBound and unbound methods Let\u0026rsquo;s first look at bound methods. If we assume a class called Class and an instance instance, with an instance method bound and class method unbound such that\nclass Class:  def bound(self):  return \u0026#34;I\u0026#39;m a bound method\u0026#34;   @staticmethod  def unbound():  return \u0026#34;I\u0026#39;m an unbound method\u0026#34;   instance = Class() Then foo is a bound method and bar is an unbound method. This definition, in practice, can be exemplified by the standard way of calling .foo(), which is\ninstance.bound() which in turn is equivalent to\nClass.bound(instance) The standard way of calling unbound is , similarly\ninstance.unbound() This, however, is equivalent to\nClass.unbound() In the unbound case, we can see there\u0026rsquo;s no need to pass the class instance. unbound is not bound to the class instance.\nAs mentioned before, Python allow us to change the class attributes at runtime. If we consider a method such as\ndef newBound(self):  return \u0026#34;I\u0026#39;m a (new!) bound method\u0026#34; we can then add it to the class, even after declaring it. For instance:\n Class.newBound = newBound  instance = Class()  instance.newBound() # Class.newBound(instance) It is interesting to note that any type of function definition will work, since functions are first class objects in Python. As such, if the method can be written as a single statement, a lambda could also be used, i.e.\nClass.newBound = lambda self: \u0026#34;I\u0026#39;m a lambda\u0026#34;  instance.newBound() A limitation of the \u0026ldquo;monkey patching\u0026rdquo; method, is that attributes can only be changed at the class definition level. As an example, although possible, it is not trivial to add the .newBound() method to instance.\nA solution is to either call the descriptor methods (which allow for instance attribute manipulation), or declare the instance attribute as a `MethodType`.\nTo illustrate this in our case:\nimport types  instance.newBound = types.MethodType(newBound, instance)  instance.newBound() # Prints \u0026#34;I\u0026#39;m a lambda\u0026#34; This method is precisely, as mentioned, to change attributes for a specific instance, so in this case, if we try to access the bound method from another instance `anotherInstance`, it would fail\nanotherInstance = Class() anotherInstance.newBound() # fails with AttributeError Abstract classes Python supports abstract classes, i.e. the definition of \u0026ldquo;blueprint\u0026rdquo; classes for which we delegate the concrete implementation of abstract methods to subclasses. In Python 3.x this is done via the @abstractmethod annotation. If we declare a class such as\nfrom abc import ABC, abstractmethod class AbstractClass(ABC): \t@abstractmethod \tdef abstractMethod(self): \tpass we can then implement abstractMethod in all of AbstractClass\u0026rsquo;s subclasses:\nclass ConcreteClass(AbstractClass): \tdef abstractMethod(self): \tprint(\u0026#34;Concrete class abstract method\u0026#34;) We could, obviously, do this in Python without abstract classes, but this mechanism allows for a greater safety, since implementation of abstract methods is mandatory in this case. With regular classes, not implementing abstractMethod would simply assume we were using the parent\u0026rsquo;s definition.\nUnfortunately, monkey patching of abstract methods is not supported in Python. We could monkey patch the concrete class:\nConcreteClass.newBound = lambda self: print(\u0026#34;New \u0026#39;child\u0026#39; bound\u0026#34;) c = ConcreteClass() c.newBound() # prints \u0026#34;New \u0026#39;child\u0026#39; bound\u0026#34; And we could even add a new bound method to the superclass, which will be available to all subclasses:\n AbstractClass.newBound = lambda self: print(\u0026#34;New \u0026#39;parent\u0026#39; bound\u0026#34;)  c = ConcreteClass()  c.newBound() # prints \u0026#34;New \u0026#39;parent\u0026#39; bound\u0026#34; However, we can\u0026rsquo;t add abstract methods with monkey patching. This is a documented exception of this functionality with the specific warning that\n Dynamically adding abstract methods to a class, or attempting to modify the abstraction status of a method or class once it is created, are not supported. The abstractmethod() only affects subclasses derived using regular inheritance; \u0026ldquo;virtual subclasses\u0026rdquo; registered with the ABC\u0026rsquo;s register() method are not affected.\n Private methods We can dynamically add and replace inner methods, such as:\nclass Class: \tdef _inner(self): \tprint(\u0026#34;Inner bound\u0026#34;) \tdef __private(self): \tprint(\u0026#34;Private bound\u0026#34;) \tdef callNewPrivate(self): \tself.__newPrivate()  Class._newInner = lambda self: print(\u0026#34;New inner bound\u0026#34;) c = Class() c._inner() # prints \u0026#34;Inner bound\u0026#34; c._newInner() # prints \u0026#34;New inner bound\u0026#34; However, private methods behave differently. Python enforces name mangling for private methods. As specified in the documentation:\n Since there is a valid use-case for class-private members (namely to avoid name clashes of names with names defined by subclasses), there is limited support for such a mechanism, called name mangling. Any identifier of the form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with _classname__spam, where classname is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, as long as it occurs within the definition of a class.\n We can then still access the private methods (although we probably shouldn\u0026rsquo;t), but monkey patching won\u0026rsquo;t work as before due to the above.\nc._Class__private() # Private bound Class.__newPrivate = lambda self: print(\u0026#34;New private bound\u0026#34;) c = Class() c._Class__newPrivate() # fails with AttributeError We have defined a new method called __newPrivate() but interestingly, this method is not private. We can see this by calling it directly (which is allowed) and by calling the new \u0026ldquo;private\u0026rdquo; method from inside the class as self.__newPrivate():\nc.__newPrivate() # prints \u0026#34;New private bound\u0026#34; c.callNewPrivate() # fails with AttributeError (can\u0026#39;t find _Class_NewPrivate) It is possible to perform some OOP abuse and declare the private method by mangling the name ourselves. In this case we could then do:\nClass._Class__newPrivate = lambda self: print(\u0026#34;New private bound\u0026#34;) c = Class() c._Class__newPrivate() # prints \u0026#34;New private bound\u0026#34; c.callNewPrivate() # prints \u0026#34;New private bound\u0026#34; Builtins Is it possible to monkey patch builtin classes in Python, e.g. int or float? In short, yes, it is.\nAlthough the usefulness is arguable and I strongly urge not to do this in any production scenario, we\u0026rsquo;ll look at how to achieve this, for the sake of completeness. A very interesting and educational read is available from the Forbidden Fruit Python module.\nPrimitive (or builtin) classes in Python are typically written in C and as such some of these meta-programming facilities require jumping through extra hoops (as well as being a Very Bad Ideaâ¢). Let\u0026rsquo;s first look at the integer class representation, int.\nA int doesn\u0026rsquo;t allow bound methods to be added dynamically as previously. For instance:\np = 5 type(p) # int We can try to add a method to int to square the value of the instance:\nint.square = lambda self: self ** 2 This fails with the error TypeError: can't set attributes of built-in/extension type 'int'. The solution (as presented in Forbidden Fruit) is to first create classes to hold the ctype information of a builtin (C) class. We subclass ctypes Python representation of a C struct in native byte order and hold the signed int size and pointer to PyObject.\nimport ctypes class PyObject(ctypes.Structure): \tpass  PyObject.fields = [ \t(\u0026#39;ob_refcnt\u0026#39;, ctypes.c_int), \t(\u0026#39;ob_type\u0026#39;, ctypes.POINTER(PyObject)), ] Next we create a holder for Python objects slots, containing a reference to the ctype structure:\nclass SlotsProxy(PyObject): \t_fields_ = [(\u0026#39;dict\u0026#39;, ctypes.POINTER(PyObject))] The final step is extract the `PyProxyDict` from the object referenced by the pointer. Ideally, we should get the builtin\u0026rsquo;s namespace so we can freely set attributes as we did previously. A helper function to retrieve the builtins (mutable) namespace can then be:\ndef patch(klass): \tname = klass.__name__ \ttarget = klass.__dict__ \tproxy_dict = SlotsProxy.from_address(id(target)) \tnamespace = {}  \tctypes.pythonapi.PyDict_SetItem( \tctypes.py_object(namespace), \tctypes.py_object(name), \tproxy_dict.dict, \t) \treturn namespace[name] We can now easily patch builtin classes. Let\u0026rsquo;s try to add the square method again by first retrieving the namespace (stored below in `d`) and setting it directly\nd = patch(int) d[\u0026#34;square\u0026#34;] = lambda self: self ** 2  p.square() # 25 All future instance of int will also contain the square method now:\n(2 + p).square() # 49 Conclusion \u0026ldquo;Monkey patching\u0026rdquo; is usually, and rightly so, considered a code smell, due to the increased indirection and potential source of unwanted surprises. However, having the ability to \u0026ldquo;monkey patch\u0026rdquo; classes in Python allows us to write Jupyter notebooks in a more literate, fluid way rather than presenting the user with a \u0026ldquo;wall of code\u0026rdquo;. Thank you for reading. If you have any comments or suggestions please drop me a message on Mastodon.\n","permalink":"https://ruivieira.dev/python-monkey-patching-for-readability.html","tags":null,"title":"Python monkey patching (for readability)"},{"categories":null,"contents":"Subsetting and indexing Indexing performance Let\u0026rsquo;s assume the case where you a column BOOL with values Y or N that you want to replace with an integer 1 or 0 value. The inital1 instinct would be to do something like:\ndf[\u0026#34;BOOL\u0026#34;] = df[\u0026#34;BOOL\u0026#34;].eq(\u0026#34;Y\u0026#34;).mul(1) This will result in the warning\nSettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead Pandas documentation recommends the usage of the following idiom, since it can be considerably faster:\ndf.loc[:, (\u0026#34;BOOL\u0026#34;)] = df.loc[:, (\u0026#34;BOOL\u0026#34;)].eq(\u0026#34;Y\u0026#34;).mul(1)   : and Pythonic?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/python-pandas.html","tags":null,"title":"Python Pandas"},{"categories":null,"contents":"Installing Installing pweave is a matter of simply running1:\npip3 install pweave At the moment of writing, the editor which, IMO, has the best support for pweave is Atom (using Hydrogen). To install the necessary packages run:\napm install language-weave Hydrogen apm install language-markdown atom-html-preview pdf-view   I recommend using a separate pyenv for this.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/python-pweave.html","tags":null,"title":"Python Pweave"},{"categories":null,"contents":"Page for Quarkus.\nCreating projects An example on how to create a Quarkus project:\nmvn io.quarkus:quarkus-maven-plugin:2.5.1.Final:create \\  -DprojectGroupId=com.okta.rest \\  -DprojectArtifactId=quarkus \\  -DclassName=\u0026#34;com.okta.rest.quarkus.HelloResource\u0026#34; \\  -Dpath=\u0026#34;/hello\u0026#34; \\  -Dextensions=\u0026#34;smallrye-jwt,resteasy-reactive\u0026#34; ","permalink":"https://ruivieira.dev/quarkus.html","tags":null,"title":"Quarkus"},{"categories":null,"contents":"Introduction A random walk is a stochastic process which describes a path made of consecutive random steps.\nGaussian In Gaussian random walk the steps follow a continous Gaussian distribution. We will look at two different types, the univariate and multivariate kind.\nUnivariate A univariate Gaussian Random Walk, is a series of i.i.d. \\(\\mathcal{N}(0,1)\\) random variables such that\n\\begin{align*} X_0\u0026amp;=0 \\\\ X_t\u0026amp;=X_{tâ1}+\\epsilon_t \\end{align*}\nWhere \\(t=1,2,\\dots\\) and \\(\\epsilon_t\\) is a series of i.i.d. \\(\\mathcal{N}(0,1)\\) random variables.\nLet\u0026rsquo;s illustrate a simple univariate Gaussian random walk in Python, by plotting 1000 realisations.\nimport numpy as np  N = 1000 np.random.seed(23) realisations = [] for i in range(N):  realisations.append(np.cumsum(np.random.normal(size=100)))  ","permalink":"https://ruivieira.dev/random-walk.html","tags":null,"title":"Random walk"},{"categories":null,"contents":"What I\u0026rsquo;m reading now and what I\u0026rsquo;ve read in the past.\nReading now Hospital Station, by James White (1962)\n Past readings Books I have read recently (most recently first).\n Retief: Envoy to New Worlds, by Keith Laumer (1972)    The Ballad of Beta-2, by Samuel R. Delany (1965)    Damnation Alley, by Roger Zelazny (1977)    The Practicing Stoic: A Philosophical User\u0026rsquo;s Manual. (May 2021)   ","permalink":"https://ruivieira.dev/reading-list.html","tags":null,"title":"Reading list"},{"categories":null,"contents":"Receiver operating characteristic ROC (Receiver operating characteristic).\nimport pandas as pd  data = pd.read_csv(\u0026#34;./data/credit-bias.zip\u0026#34;) ","permalink":"https://ruivieira.dev/roc.html","tags":null,"title":"ROC"},{"categories":null,"contents":"A typical way of measuring the difference between observations and results from a predictor.\nThe formal definition is:\n\\begin{aligned} RMSE(\\hat{\\theta}) \u0026amp;= \\sqrt{\\operatorname{MSE}(\\hat{\\theta})} \\\\ \u0026amp;= \\sqrt{\\operatorname{E}((\\hat{\\theta}-\\theta)^2)}. \\end{aligned}\nFor \\(N\\) observations \\(Y=\\{y_1,\\dots,y_N\\}\\) we can express it as:\n\\[ RMSE=\\sqrt{\\frac{\\sum_{n=1}^{N}(\\hat{y}_{n}-y_{n})^{2}}{N}}. \\]\nExample import numpy as np  X = 2 * np.random.rand(1000,1) X_b = np.c_[np.ones((1000,1)), X]  Y = 1 + 2.5 * X + np.random.randn(1000,1) ","permalink":"https://ruivieira.dev/root-mean-squared-error.html","tags":null,"title":"Root Mean Squared Error"},{"categories":null,"contents":"Install $ curl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh $ source $HOME/.cargo/env Create a new project using $ cargo new hello_world --bin # for a binary $ cargo new hello_world # for a library Exercises  Rust exercises, resolution of the rustlings exercises  Reference Uploading to crates.io Use\ncargo publish Static constants \u0026ldquo;Lazy\u0026rdquo; static constants can be defined using the lazy_static macro from the lazy_static crate.\nThe crate can be added to the dependencies with\n[dependencies] lazy_static = \u0026#34;1.4.0\u0026#34; and by adding to the Rust source code:\n#[macro_use]externcratelazy_static;Static \u0026ldquo;global\u0026rdquo; constants can then be added via:\nlazy_static!{staticrefHASHMAP: HashMap\u0026lt;u32,\u0026amp;\u0026#39;staticstr\u0026gt;={letmutm=HashMap::new();m.insert(0,\u0026#34;foo\u0026#34;);m.insert(1,\u0026#34;bar\u0026#34;);m.insert(2,\u0026#34;baz\u0026#34;);m};}List folders recursively Using the glob crate:\nuseglob::glob;fn main(){forentryinglob(\u0026#34;./**/*.md\u0026#34;).expect(\u0026#34;Failed to read glob pattern\u0026#34;){matchentry{Ok(path)=\u0026gt;println!(\u0026#34;{:?}\u0026#34;,path.display()),Err(e)=\u0026gt;println!(\u0026#34;{:?}\u0026#34;,e),}}}Duration between two times Using Rust\u0026rsquo;s standard SystemTime1, a duration between the present moment and a specific time can be calculated using:\nletduration=SystemTime::now().duration_since(another_system_time).ok().unwrap();  : https://doc.rust-lang.org/std/time/struct.SystemTime.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/rust.html","tags":null,"title":"Rust"},{"categories":null,"contents":"Variables Problem 1 fn main(){x=5;println!(\u0026#34;x has the value {}\u0026#34;,x);}Solution 1 fn main(){letx=5;println!(\u0026#34;x has the value {}\u0026#34;,x);}x has the value 5 Problem 2 fn main(){letx;ifx==10{println!(\u0026#34;Ten!\u0026#34;);}else{println!(\u0026#34;Not ten!\u0026#34;);}}Solution 2 fn main(){letx=10;ifx==10{println!(\u0026#34;Ten!\u0026#34;);}else{println!(\u0026#34;Not ten!\u0026#34;);}}Ten! Problem 3 fn main(){letx=3;println!(\u0026#34;Number {}\u0026#34;,x);x=5;// don\u0026#39;t change this line println!(\u0026#34;Number {}\u0026#34;,x);}Solution 3 fn main(){letmutx=3;println!(\u0026#34;Number {}\u0026#34;,x);x=5;// don\u0026#39;t change this line println!(\u0026#34;Number {}\u0026#34;,x);}Number 3 Number 5 Problem 4 fn main(){letx: i32;println!(\u0026#34;Number {}\u0026#34;,x);}Solution 4 fn main(){letx: i32 =1;println!(\u0026#34;Number {}\u0026#34;,x);}Problem 5 fn main(){letnumber=\u0026#34;T-H-R-E-E\u0026#34;;println!(\u0026#34;Spell a Number : {}\u0026#34;,number);number=3;println!(\u0026#34;Number plus two is : {}\u0026#34;,number+2);}Solution 5 fn main(){letmutnumber=\u0026#34;T-H-R-E-E\u0026#34;.len();println!(\u0026#34;Spell a Number : {}\u0026#34;,number);number=3;println!(\u0026#34;Number plus two is : {}\u0026#34;,number+2);}Spell a Number : 9 Number plus two is : 5 Problem 6 constNUMBER=3;fn main(){println!(\u0026#34;Number {}\u0026#34;,NUMBER);}Solution 6 constNUMBER:i32 =3;fn main(){println!(\u0026#34;Number {}\u0026#34;,NUMBER);}Number 3 ","permalink":"https://ruivieira.dev/rust-exercises.html","tags":null,"title":"Rust exercises"},{"categories":null,"contents":"Notes on the Scala language.\n Scala cookbook  ","permalink":"https://ruivieira.dev/scala.html","tags":null,"title":"Scala"},{"categories":null,"contents":"val a = (0 until 10) a: Range = Range(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) println(a.map(i =\u0026gt; i + 10)) Vector(10, 11, 12, 13, 14, 15, 16, 17, 18, 19) ","permalink":"https://ruivieira.dev/scala-cookbook.html","tags":null,"title":"Scala cookbook"},{"categories":null,"contents":"Collection of notes on Python\u0026rsquo;s scikit-learn machine learning library.\n Optimising random forest hyperparamaters  ","permalink":"https://ruivieira.dev/scikit-learn.html","tags":null,"title":"Scikit-learn"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://ruivieira.dev/search.html","tags":null,"title":"Search Results"},{"categories":null,"contents":"Page on self-organising maps ","permalink":"https://ruivieira.dev/self-organising-maps.html","tags":null,"title":"Self-organising maps"},{"categories":null,"contents":"Deploying machine learning models in production comes with several requirements. We must manage the model lifecycle. We need reproducibility and typically use containerised workflows.\nSeldon is a tool which aims at providing a production workflow for machine learning models, allowing to build model serving containers which expose well-defined APIs.\nIn this post, I\u0026rsquo;ll show how to create a simple model and how to deploy it with Seldon. The model is a customer segmentation one. The goal is to classify a customer according to a segment (0, 1 or 2), according to its age, income, whether they engaged with previous campaigns and the campaign type.\nOnce we train the model, we deploy it with Seldon in a container orchestration platform such as Kubernetes and OpenShift.\nCreate data We use the Python\u0026rsquo;s `scikit-learn` to train our model. However, we must first simulate some data to train it. We start by simulating the users age (\\(a\\)) and income (\\(c\\)). We assume income is correlated with age.\n\\begin{aligned} c|a \u0026amp;\\sim \\mathcal{N}\\left(a + 20, 100\\right) \\\\\\\\ a|k \u0026amp;\\sim \\mathcal{U}\\left(A_k, B_k\\right),\\quad A=\\left\\lbrace16, 25, 50, 61\\right\\rbrace,B=\\left\\lbrace24, 49, 60, 90\\right\\rbrace \\\\\\\\ k \u0026amp;\\sim \\mathcal{M}\\left(4, \\left\\lbrace 0.15, 0.4, 0.2, 0.25\\right\\rbrace\\right) \\end{aligned}\n Let\u0026rsquo;s assume we have eight distinct events (\\(e=\\left(0, 1, \\dots, 7\\right)\\)). We sample them from a multinomial distribution and also assume that two different age bands have different distributions, just to add some variation.\n\\[ e = \\begin{cases} \\mathcal{M}\\left(7, \\left\\lbrace 0.026, 0.195, 0.156, 0.208, 0.130, 0.205, 0.078 \\right\\rbrace\\right) \u0026amp; \\text{if}\\ a \u0026lt; 50 \\\\\\\\ \\mathcal{M}\\left(7, \\left\\lbrace 0.052, 0.143, 0.169, 0.182, 0.164, 0.182, 0.104 \\right\\rbrace\\right) \u0026amp; \\text{if}\\ a \\geq 50 \\end{cases} \\]\n The responses are calculated as `0` or `1`, representing \u0026ldquo;true\u0026rdquo; or \u0026ldquo;false\u0026rdquo;, and sampled from Bernoulli distributions, with different distributions depending on the event, again just to add some variation.\n\\[ r = \\begin{cases} \\text{Bernoulli}\\left(0.6\\right) \u0026amp; \\text{if}\\ e \\in \\left(2, 3, 4, 6\\right) \\\\\\\\ \\text{Bernoulli}\\left(0.4\\right) \u0026amp; \\text{if}\\ e \\in \\left(1, 5, 7\\right) \\end{cases} \\]\nTo predict the response of a customer, we use a logistic model, with coefficients \\(\\beta_{age}=-0.0004\\) and \\(\\beta_{income}=0.0001\\). For the customer level, we use a negative binomial model with coefficients \\(\\beta_{age}=-0.0233\\) and \\(\\beta_{income}=0.0054\\). This results in the following distribution of customer levels:\n Finally, we create the response according to negative binomial model with coefficients \\(\\beta_{level}=0.1862\\) and \\(\\beta_{response}=0.2076\\). We get the following segments, stratified by age and income:\n Train model Now that we have our simulated data, we can train a model. Generally, it is straightforward to train model data when in `pandas` data frame format. Let\u0026rsquo;s proceed with creating a data frame with the data we\u0026rsquo;ve just generated:\nimport pandas as pd  data = {  \u0026#34;age\u0026#34;: age,  \u0026#34;income\u0026#34;: income,  \u0026#34;class\u0026#34;: _class,  \u0026#34;response\u0026#34;: response,  \u0026#34;segment\u0026#34;: segment,  \u0026#34;events\u0026#34;: events, }  df = pd.DataFrame(data) We now create the training and testing datasets. The first thing is to define the classifier\u0026rsquo;s `inputs` and `outputs` and then splitting each of them into training and testing. Here I have used a split of 60%/40% for training and testing respectively.\nfrom sklearn.model_selection import train_test_split  cols = [\u0026#34;age\u0026#34;, \u0026#34;income\u0026#34;, \u0026#34;response\u0026#34;, \u0026#34;events\u0026#34;] inputs = df[cols] outputs = df[\u0026#34;segment\u0026#34;]  # split dataset X_train, X_test, y_train, y_test = train_test_split(  inputs, outputs, test_size=0.4, random_state=23 ) We use a Random Forest classifier as the underlying algorithm for our model. These are available in `sciki-learn` with the `RandomForestClassifier` class. However, `scikit-learn` does not support categorical variables out of the box1. To deal with them, we build a `Pipeline`, which allows to chain multiple transformations to our data, including a categorical variable processor, such as `OrdinalEncoder`2. We use `DataFrameMapper` to apply the encoder to the `response` and `events` columns and leave the remaining unchanged.\nfrom sklearn.ensemble import RandomForestClassifier from sklearn import preprocessing from sklearn.pipeline import Pipeline   def build_RF_pipeline(inputs, outputs, rf=None):  if not rf:  rf = RandomForestClassifier()   pipeline = Pipeline(  [  (  \u0026#34;mapper\u0026#34;,  DataFrameMapper(  [  ([\u0026#34;response\u0026#34;, \u0026#34;events\u0026#34;], preprocessing.OrdinalEncoder()),  ([\u0026#34;age\u0026#34;, \u0026#34;income\u0026#34;], None),  ]  ),  ),  (\u0026#34;classifier\u0026#34;, rf),  ]  )  pipeline.fit(inputs, outputs)  return pipeline The actual training involves a simple hyper-parameter estimation using `RandomizedSearchCV`. This method performs a type of parameter grid search but restricting the search to only the specified values. For the scope of this post, it is not necessary to perform an exhaustive hyperparameter estimation. The `RF_estimation` function returns the best-fitted model after searching with the test dataset.\ndef RF_estimation(  inputs,  outputs,  estimator_steps=10,  depth_steps=10,  min_samples_split=None,  min_samples_leaf=None, ):  # hyper-parameter estimation  n_estimators = [  int(x) for x in np.linspace(start=50, stop=100, num=estimator_steps)  ]  max_depth = [int(x) for x in np.linspace(3, 10, num=depth_steps)]  max_depth.append(None)  if not min_samples_split:  min_samples_split = [1, 2, 4]  if not min_samples_leaf:  min_samples_leaf = [1, 2, 4]  bootstrap = [True, False]  random_grid = {  \u0026#34;n_estimators\u0026#34;: n_estimators,  \u0026#34;max_depth\u0026#34;: max_depth,  \u0026#34;min_samples_split\u0026#34;: min_samples_split,  \u0026#34;min_samples_leaf\u0026#34;: min_samples_leaf,  \u0026#34;bootstrap\u0026#34;: bootstrap,  }   rf_random = RandomizedSearchCV(  estimator=RandomForestClassifier(),  param_distributions=random_grid,  n_iter=100,  scoring=\u0026#34;neg_mean_absolute_error\u0026#34;,  cv=3,  verbose=1,  random_state=42,  n_jobs=-1,  )  rf_random.fit(inputs, outputs)  best_random = rf_random.best_estimator_   return best_random After applying the parameter estimation, we take the best scoring model and calculate the MSE. Unsurprisingly (given the simple model and simulated data), we get a very good fit.\nrf_predictions = random_forest_pipeline.predict(X_test) print(f\u0026#34;MSE: {random_forest_pipeline.score(X_test, y_test)*100}%\u0026#34;) # MSE: 99.95% The final step is serialising the model. Serialisation is necessary since we only serve the pre-trained model. To do so, we use the `joblib` library and save the model to a `model.pkl` file.\nimport joblib  # save mode in filesystem joblib.dump(random_forest_pipeline, \u0026#34;model.pkl\u0026#34;) Deploy model It is important to note that we don\u0026rsquo;t need the model training code included in the Seldon server. The purpose of Seldon is not to train models, but to deploy them and manage their lifecycle. This workflow means that a typical Seldon deployment would only include the prediction endpoint implementation and a serialised model. This provision is made by firstly create a wrapper for our model which implements the Seldon endpoints.\nSimple model We create a Python script called `Model.py`Â 3. The primary prediction endpoint uses the following signature:\ndef predict(self, X: np.ndarray, names: Iterable[str], meta: Dict = None) The wrapper is straightforward, in this example. We use the `joblib` library again, to load the serialised model `model.pkl`, and then pass through any JSON payload as inputs (`X`) to the model to get a prediction as well as using Python\u0026rsquo;s default logging to provide some feedback.\nimport joblib import logging   class Model(object):  def __init__(self):  logger.info(\u0026#34;Initializing.\u0026#34;)  logger.info(\u0026#34;Loading model.\u0026#34;)  self.model = joblib.load(\u0026#34;model.pkl\u0026#34;)   def predict(self, X, features_names):  return self.model.predict_proba(X) We now build the model using the `s2i` (source-to-image). As the name implies, `s2i`\u0026rsquo;s allow to create a container image from source code, taking care of any necessary intermediate steps. Seldon support several types of builds (such as Python, R and Java)4.\nTypically `s2i`\u0026rsquo;s rely on certain conventions (over configuration) on your application structure. A requirement when building a Seldon model using its `s2i` is to provide some specific environment variables. These are usually stored in a file located in `$REPO/.s2i/environment`. For instance, for this model we use:\nMODEL_NAME=Model API_TYPE=REST SERVICE_TYPE=MODEL PERSISTENCE=0 The `MODEL_NAME` corresponds to the script we\u0026rsquo;ve created previously, `Model.py` and instructs Seldon to use it as the REST endpoint provider. `API_TYPE` defines the endpoint interface. We use the REST interface, other possibilities include gRPC, for instance.\n To build the container image using the `s2i`, assuming you want an image named `$NAME` and tagged with `$TAG`, we simply need to run:\n$ s2i build $REPO \\  seldonio/seldon-core-s2i-python36:0.18 \\  $NAME:$TAG You can provide the location of your source code either by specifying a remote Git repository or by passing a local one. Once the container image builds, you can now run it using, for instance:\ndocker run -i --rm -p 5000:5000 $NAME:$TAG Let\u0026rsquo;s get a prediction from the model:\n$ curl --header \u0026#34;Content-Type: application/json\u0026#34; \\  --request POST \\  --data \u0026#39;{\u0026#34;data\u0026#34;:{\u0026#34;ndarray\u0026#34;:[[34.0, 100.0, 1, 2]]}}\u0026#39; \\  http://localhost:5000/predict This will return a prediction:\n{  \u0026#34;data\u0026#34;: {  \u0026#34;names\u0026#34;: [\u0026#34;t:0\u0026#34;,\u0026#34;t:1\u0026#34;,\u0026#34;t:2\u0026#34;],  \u0026#34;ndarray\u0026#34;: [[0.0,0.9980208571211083,0.00197914287889168]]},  \u0026#34;meta\u0026#34;: {} } This response corresponds to the probability of each segment (`0`, `1` and `2`), respectively. We can see that a customer with this profile is classified as a segment `1` with an associated probability of 99.8%.\nWith metrics Seldon provides basic metrics by default, covering service, predictor and model name, version and image. However, you can directly add custom metrics. Going back to our `Model` wrapper class, we add a new method called `metrics` which returns custom metrics. The metrics are compatible with Prometheus and, therefore, the metric type should be familiar if you have dealt with Prometheus before. These include, for instance:\n Counters Gauges Timers  Let\u0026rsquo;s add to the wrapper:\nimport joblib import logging   class Model(object):  def __init__(self):  logger.info(\u0026#34;Initializing.\u0026#34;)  logger.info(\u0026#34;Loading model.\u0026#34;)  self.model = joblib.load(\u0026#34;model.pkl\u0026#34;)   def predict(self, X, features_names):  return self.model.predict_proba(X)   # new custom metrics endpoint  def metrics(self):  return [  # a counter which will increase by the given value  {\u0026#34;type\u0026#34;: \u0026#34;COUNTER\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;mycounter\u0026#34;, \u0026#34;value\u0026#34;: 1},  # a gauge which will be set to given value  {\u0026#34;type\u0026#34;: \u0026#34;GAUGE\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;mygauge\u0026#34;, \u0026#34;value\u0026#34;: 10},  # a timer which will add sum and count metrics - assumed millisecs  {\u0026#34;type\u0026#34;: \u0026#34;TIMER\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;mytimer\u0026#34;, \u0026#34;value\u0026#34;: 1.1},  ] If we now request a new prediction, as previously, we can see the custom metrics included in the model\u0026rsquo;s response.\n{  \u0026#34;data\u0026#34;: {  \u0026#34;names\u0026#34;: [\u0026#34;t:0\u0026#34;,\u0026#34;t:1\u0026#34;,\u0026#34;t:2\u0026#34;],  \u0026#34;ndarray\u0026#34;:[[0.0,0.9980208571211083,0.00197914287889168]]},  \u0026#34;meta\u0026#34;: {  \u0026#34;metrics\u0026#34;: [  {\u0026#34;key\u0026#34;:\u0026#34;mycounter\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;COUNTER\u0026#34;,\u0026#34;value\u0026#34;:1},  {\u0026#34;key\u0026#34;:\u0026#34;mygauge\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;GAUGE\u0026#34;,\u0026#34;value\u0026#34;:10},  {\u0026#34;key\u0026#34;:\u0026#34;mytimer\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;TIMER\u0026#34;,\u0026#34;value\u0026#34;:1.1}]  } } These values are available via the Prometheus endpoint.\nThe model can also be easily deployed in a container platform, for instance, OpenShift. Assuming you are logged to a cluster and your image is a registry accessible by OpenShift, you can simply deploy it using:\n$ oc new-app $NAME:$TAG I hope this was useful to you. Happy coding!\n  As of the time of writing.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Other encoders are available in `scikit-learn`. I recommend you experiment with some of them.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n You can use any file name, as long as it\u0026rsquo;s consistent with `.s2i/environment`, which we\u0026rsquo;ll look at soon.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n More information can be found here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/serving-models-with-seldon.html","tags":null,"title":"Serving models with Seldon"},{"categories":null,"contents":"Summary  Stands for SHapley Additive exPlanations First published in 2017 by Lundberg and Lee (here) Based on the game theory concept of Shapley values Local interpretability The model\u0026rsquo;s outcome is the \u0026ldquo;game\u0026rdquo; The features are the \u0026ldquo;players\u0026rdquo; A \u0026ldquo;game\u0026rdquo; is a single observation The outcome of each possible players (features) combination (coalition) is considered to establish the importance of a single player (feature)  Consider a set of features\n\\[ F = \\{f_0, \\dots, f_F\\} \\]\n   ","permalink":"https://ruivieira.dev/shap.html","tags":null,"title":"SHAP"},{"categories":null,"contents":"According to Bash\u0026rsquo;s man:\n /bin/bash The bash executable /etc/profile The system-wide initialization file, executed for login shells ~/.bash_profile The personal initialization file, executed for login shells ~/.bashrc The individual per-interactive-shell startup file ~/.bash_logout The individual login shell cleanup file, executed when a login shell exits ~/.inputrc Individual readline initialization file  With zsh, .zshrc is always read for an interactive shell, whether it\u0026rsquo;s a login one or not.\n","permalink":"https://ruivieira.dev/shell-configurations.html","tags":null,"title":"Shell configurations"},{"categories":null,"contents":"Reset cursor Sometimes, especially when using ANSI escape code heavy applications, your terminal state might get mangled. If that\u0026rsquo;s the case, it\u0026rsquo;s just a matter of performing a VT320 escape sequence to reset the state. For instance, in [zsh]], using the unhide command:\necho -en \u0026#34;\\e[?25h\u0026#34; ","permalink":"https://ruivieira.dev/shell-tricks.html","tags":null,"title":"Shell tricks"},{"categories":null,"contents":"Assets This site\u0026rsquo;s CSS size is 84.1Kb. This, however, includes the following dependencies:\n LaTeX processor (MathJax) custom monospaced font (Jetbrains Mono) custom serif font (ET Book, Edward Tufte\u0026rsquo;s Book font)  The base CSS is heavily inspired by 58 bytes of css to look great nearly everywhere.\nThe CSS evolution (size, number of rules, etc) can be tracked over at Project Wallace.\nThe site is generated from a set of org-mode files using Emacs, which mainly performs the following tasks:\n Gather backlinks to each page Build the client-side search index convert the org-mode files to HTML1  Navigation Search The site is searchable from here. The search page also allows for query string searches using the q keyword, for instance:\n/search.html?q=statistics This allows you to add a custom search engine to most modern browsers, such as Firefox or Chrome.\nSearch is done 100% client-side, so there\u0026rsquo;s absolutely no information collected regarding your search queries.\nHighlighting of terms is also possible just adding the query parameter ?h=... to any page. For instance, to highlight the term privacy on this page, simply go to\n/site-details.html?h=privacy or click here.\nDeep linking This site implements \u0026ldquo;deep links\u0026rdquo;. This means that any section of text selected will generate a new URL which links directly to it. This link can be bookmarked or shared. Please keep in mind that this intented for transitory linking, since long-term structure of the page is not guaranteed.\nKeyword focus Some keywords are clickable and will highlight all occurences of a certain term throughtout the page. The main use case is, for instance, code-heavy pages where a certain variable or term might benefit from standing out to understand the concepts more easily.\nPrivacy No cookies are used on this site.\nAll site traffic statistics are captured using GoatCounter. Goatcounter is an open-source, privacy-friendly analytics site, which doesn\u0026rsquo;t use cookies and collects minimal information, just enough to produce a few useful summaries. In line with the desire for total transparency for all visitors, I\u0026rsquo;ve made the realtime stats dashboard for this site public and available at https://ruivieira-dev.goatcounter.com/. You can see for yourself which data is collected.\nPlease let me know if you have any concerns about this site\u0026rsquo;s privacy policy by dropping me a message at @ruivieira@mastodon.technology.\nAs mentioned previously, search is done 100% client-side, so no information is collected about your search queries.\nThe privacy record of this site can be verified independently by using Blacklight.\nJavascript If you want to disable Javascript for this site, please do! It won\u0026rsquo;t affect any of the main content. All pages will work the same with or without Javascript, except the following:\n The link graph page The search page Deep linking Keyword focus  All of these are simply navigation helpers and the content does not depend on this functionality.\nSome sections are progressively enhanced by Javascript, but will work without it. As an example, many dates are represented by a time tag such as\n\u0026lt;time  datetime=\u0026#34;2021-11-28 15:21:54 +0000 GMT\u0026#34;  itemprop=\u0026#34;datePublished\u0026#34;\u0026gt;2021-11-28\u0026lt;/time\u0026gt; These are converted to a relative date by Javascript resulting in \u0026lt;p\u0026gt; \u0026lt;time datetime=\u0026ldquo;2021-11-28 15:21:54 +0000 GMT\u0026rdquo; itemprop=\u0026ldquo;datePublished\u0026rdquo;\u0026gt;2021-11-28\u0026lt;/time\u0026gt; \u0026lt;/p\u0026gt; However, if no Javascript is available, the former date will still display.\nText mode Apart from the obvious lack of images, the vast majority of this site will also work with a text-based browser (such as lynx).\nEven the code examples are quite readable (for instance, pandas dataframes are properly rendered as text tables).\nGive it a go by installing lynx and running lynx https://ruivieira.dev.\nHere\u0026rsquo;s how this page looks like using lynx:\n To see other \u0026ldquo;supported\u0026rdquo; browsers (such as Internet Explorer 6 and NCA Mosaic 2) see the Brutalist Web Design page.\nKeeping up to date If you want to keep up to date and be notified when new content is added to this site, at the moment the best way is to follow the Mesozoic Mastodon bot.\nThis bot is part of a Git pre-push hook and will \u0026ldquo;toot\u0026rdquo; whenever changes to the site\u0026rsquo;s source are made.\n  Previously this site was written as plain HTML+CSS, this is touched upon at \u0026ldquo;(Semi) handcrafted RSS\u0026rdquo;.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/site-details.html","tags":null,"title":"Site details"},{"categories":null,"contents":"Introduction SMILE is a Machine Learning library for Scala and Java.\nIt implements:\n Classification  ","permalink":"https://ruivieira.dev/smile-library.html","tags":null,"title":"SMILE library"},{"categories":null,"contents":"Introduction Some classification algorithms in the Smile library:\n Random forests  ","permalink":"https://ruivieira.dev/smile-library-classification.html","tags":null,"title":"SMILE library classification"},{"categories":null,"contents":"Introduction import $ivy.`dev.ruivieira::scala-experiments:0.1.0-SNAPSHOT` import ml.smile.data.Loader  val df = Loader.csv(\u0026#34;credit_bias-train.csv\u0026#34;) df.summary() import $ivy.$  import ml.smile.data.Loader   df: smile.data.DataFrame = [NewCreditCustomer: boolean, Amount: double, Interest: double, LoanDuration: int, Education: Double, NrOfDependants: Double, EmploymentDurationCurrentEmployer: Double, IncomeFromPrincipalEmployer: double, IncomeFromPension: double, IncomeFromFamilyAllowance: double, IncomeFromSocialWelfare: double, IncomeFromLeavePay: double, IncomeFromChildSupport: double, IncomeOther: double, ExistingLiabilities: int, RefinanceLiabilities: int, DebtToIncome: Double, FreeCash: Double, CreditScoreEeMini: Double, NoOfPreviousLoansBeforeLoan: Double, AmountOfPreviousLoansBeforeLoan: Double, PreviousRepaymentsBeforeLoan: Double, PreviousEarlyRepaymentsBefoleLoan: Double, PreviousEarlyRepaymentsCountBeforeLoan: Double, PaidLoan: boolean, Council_house: int, Homeless: int, Joint_ownership: int, Joint_tenant: int, Living_with_parents: int, Mortgage: int, Other: int, Owner: int, Owner_with_encumbrance: int, Tenant: int, Entrepreneur: int, Fully: int, Partially: int, Retiree: int, Self_employed: int] +-----------------+------+--------+------------+---------+--------------+---------------------------------+---------------------------+-----------------+-------------------------+-----------------------+------------------+----------------------+-----------+-------------------+--------------------+------------+--------+-----------------+---------------------------+-------------------------------+----------------------------+---------------------------------+--------------------------------------+--------+-------------+--------+---------------+------------+-------------------+--------+-----+-----+----------------------+------+------------+-----+---------+-------+-------------+ |NewCreditCustomer|Amount|Interest|LoanDuration|Education|NrOfDependants|EmploymentDurationCurrentEmployer|IncomeFromPrincipalEmployer|IncomeFromPension|IncomeFromFamilyAllowance|IncomeFromSocialWelfare|IncomeFromLeavePay|IncomeFromChildSupport|IncomeOther|ExistingLiabilities|RefinanceLiabilities|DebtToIncome|FreeCash|CreditScoreEeMini|NoOfPreviousLoansBeforeLoan|AmountOfPreviousLoansBeforeLoan|PreviousRepaymentsBeforeLoan|PreviousEarlyRepaymentsBefoleLoan|PreviousEarlyRepaym... res0_3: smile.data.DataFrame = [column: String, count: long, min: double, avg: double, max: double] +--------------------+-----+----+-----------+------+ | column|count| min| avg| max| +--------------------+-----+----+-----------+------+ | Amount|58003|6.39|2242.612586| 10632| | Interest|58003| 2| 25.123398| 76.08| | LoanDuration|58003| 1| 42.774736| 60| | Education|57943| 1| 3.676958| 5| | NrOfDependants|20031| 0| 0.815486| 11| |EmploymentDuratio...|57261| 1| 4.091511| 7| |IncomeFromPrincip...|58003| 0| 604.457299|133000| | IncomeFromPension|58003| 0| 8.875886| 2600| |IncomeFromFamilyA...|58003| 0| 6.863071| 2006| |IncomeFromSocialW...|58003| 0| 1.425823| 972| +--------------------+-----+----+-----------+------+ 28 more rows... import smile.data.DataFrame  val subset: DataFrame = df.select(\u0026#34;Amount\u0026#34;, \u0026#34;LoanDuration\u0026#34;, \u0026#34;PaidLoan\u0026#34;) subset.summary() import smile.data.DataFrame   subset: DataFrame = [Amount: double, LoanDuration: int, PaidLoan: boolean] +------+------------+--------+ |Amount|LoanDuration|PaidLoan| +------+------------+--------+ | 2125| 60| false| | 3000| 60| false| | 9100| 60| false| | 635| 60| false| | 5000| 60| true| | 2000| 60| true| | 530| 60| true| | 5500| 60| true| | 6900| 60| true| | 3190| 60| false| +------+------------+--------+ 57993 more rows...  res1_2: DataFrame = [column: String, count: long, min: double, avg: double, max: double] +------------+-----+----+-----------+-----+ | column|count| min| avg| max| +------------+-----+----+-----------+-----+ | Amount|58003|6.39|2242.612586|10632| |LoanDuration|58003| 1| 42.774736| 60| +------------+-----+----+-----------+-----+ import smile.data.formula.Formula  val formula: Formula = Formula.lhs(\u0026#34;PaidLoan\u0026#34;) import smile.data.formula.Formula   formula: Formula = PaidLoan ~ . import smile.classification.RandomForest  val a = RandomForest.fit(formula, subset) import smile.classification.RandomForest   a: RandomForest = smile.classification.RandomForest@45554613 import smile.data.`type`.{DataTypes, StructField} import smile.data.Tuple  val schema = DataTypes.struct(  new StructField(\u0026#34;Amount\u0026#34;, DataTypes.DoubleType),  new StructField(\u0026#34;LoanDuration\u0026#34;, DataTypes.DoubleType))  a.predict(Tuple.of(Array(10000000.0, 1000.0), schema)) import smile.data.`type`.{DataTypes, StructField}  import smile.data.Tuple   schema: smile.data.type.StructType = [Amount: double, LoanDuration: double] res4_3: Int = 0  ","permalink":"https://ruivieira.dev/smile-library-random-forest-classification.html","tags":null,"title":"SMILE library random forest classification"},{"categories":null,"contents":"Spearman rank correlation The Spearman correlation coefficient (or Spearman\u0026rsquo;s \\(\\rho\\)) measures rank correlation between two variables.\nAssuming monotonicity, the Spearman\u0026rsquo;s \\(\\rho\\) will take values between \\(-1\\) and \\(1\\), representing completely opposite or identical ranks, respectively1.\nDue to the dependance on ranks, the Spearman\u0026rsquo;s \\(\\rho\\) is used for ordinal value, although discrete and continous values are possible.\nIf we consider a dataset of size \\(n\\), and \\(X_i, Y_i\\) as the scores, we can then calculate the ranks as \\(\\operatorname{R}({X_i}), \\operatorname{R}({Y_i})\\), and \\(\\rho\\) as\n\\[ r_s = \\rho_{\\operatorname{R}(X),\\operatorname{R}(Y)} = \\frac{\\operatorname{cov}(\\operatorname{R}(X), \\operatorname{R}(Y))} {\\sigma_{\\operatorname{R}(X)} \\sigma_{\\operatorname{R}(Y)}}, \\]\nHere \\(\\rho\\) is the Pearson correlation coefficient, but applied to the rank variables, \\(\\operatorname{cov}(\\operatorname{R}(X), \\operatorname{R}(Y))cov(R(X),R(Y))\\) is the covariance of the rank variables, \\(\\sigma_{\\operatorname{R}(X)}\\) and \\(\\sigma_{\\operatorname{R}(Y)}\\) are the standard deviations of the rank variables.\nIf all the ranks are distinct integers, the simplified form can be applied\n\\[ r_s = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}, \\]\nwhere \\(d_i = \\operatorname{R}(X_i) - \\operatorname{R}(Y_i)\\) is the difference between the two ranks of each observation, \\(n\\) is the number of observations.\n  Assuming no repeated ranks.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/spearman-correlation.html","tags":null,"title":"Spearman correlation"},{"categories":null,"contents":"Configuration Config file To add a known server to the config file, use the following syntax:\nHost mymachine  HostName 127.0.0.1  User root  Port 7654 There is no method to specify or provide on the command line the password in a non-interactive manner for ssh authentication using a OpenSSH built-in mechanism.\nServers Alternative An alternative SSH server implementation is tinyssh1\n  https://tinyssh.org/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/ssh.html","tags":null,"title":"SSH"},{"categories":null,"contents":"Situations where streaming statistics are useful:\n Unknown number of observations Online streaming data Dataset too big for local processing  For the remainder, let\u0026rsquo;s consider a set of observations \\(y_i\\), weights \\(w_i\\), such that\n\\[ y_1,\\dots,y_i \\in \\mathbb{R} \\\\ w_1,\\dots,w_i\\quad w_i \\geq 0 \\]\nMean and variances A naive approach to calculating a weighted streaming mean, \\(\\widehat{\\mu}\\) and unbiased streaming variance, \\widehat{\\mathbb{V}}, would be to calculate:\n\\begin{align*} \\widehat{\\mu}\u0026amp;=\\frac{T^{(n)}}{S^{(n)}} \\\\ \\widehat{\\mathbb{V}}\u0026amp;=\\frac{n}{(n-1)S^{(n)}}\\left(U^{(n)}-S^{(n)}\\widehat{\\mu}^2\\right) \\end{align*}\nwhere\n\\begin{align*} S^{(i+1)}\u0026amp;=S^{(i)}+w_i\\\\ T^{(i+1)}\u0026amp;=T^{(i)}+w_i y_i\\\\ U^{(i+1)}\u0026amp;=U^{(i)}+w_i y^2_i \\end{align*}\nThis calculation however does not hold for large \\(n\\) values.\nAn alternative calculation was suggested by West1, where we calculate:\n\\begin{align*} \\widehat{\\mu}\u0026amp;=\\frac{\\sum_i w_i y_i}{\\sum_i w_i} \\\\ \\widehat{\\mathbb{V}}\u0026amp;=\\frac{\\sum_i w_i(X_i-\\mu)^2}{\\frac{n-1}{n}\\sum_i w_i} \\end{align*}\nLet\u0026rsquo;s look at an example in Python.\nimport numpy as np  mu = 10.0 sigma = 20.0 N = 100_000  Y = np.random.normal(loc=mu, scale=sigma, size=N)  As expected, the mean and variance when calculated in \u0026ldquo;batch\u0026rdquo; mode should be equivalent to the original values \\(\\mu\\) and \\(\\sigma\\).\nprint(f\u0026#34;mean: {np.mean(Y)}\u0026#34;) print(f\u0026#34;std: {np.std(Y)}\u0026#34;) mean: 10.101511575087532 std: 20.008596944491394 class StreamingStatistcs:  def __init__(self):  self.sum = 0.0  self.mean = 0.0  self.t = 0  self.n = 0  self.var = None   def calculate(self, y, w):  q = y - self.mean  tmp_sum = self.sum + w  r = q*w / tmp_sum   self.mean += r  self.t += q*r*self.sum  self.sum = tmp_sum  self.n += 1  if (self.sum == 0.0 or self.n \u0026lt; 2):  self.var = 0  else:  self.var = (self.t*self.n)/(self.sum*(self.n-1))  return (self.mean, self.var)  means = [] vars = [] st = StreamingStatistcs() for y in Y:  m, v = st.calculate(y, 1.0)  means.append(m)  vars.append(np.sqrt(v))    \u0026lt;\u0026amp;west1979updating\u0026gt; West, D. (1979). Updating mean and variance estimates: an improved method. Communications of the ACM, 22(9), 532â535.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/streaming-statistics.html","tags":null,"title":"Streaming statistics"},{"categories":null,"contents":":ID: Synthetic Data Generation :CUSTOM_ID: Synthetic Data Generation\nGenerating synthetic data Synthetic data will be used mainly for these scenarios:\n Regression Classification  Here we will mainly look at the methods provided by `scikit-learn` to generate synthetic datasets. For more advanced methods, such as using the SDV library please check the [Synthetic Data Generation with SDV|SDV page]]. It support methods such as [Synthetic data with SDV and Gaussian copulas|Gaussian copulas]], [Synthetic data with SDV and CTGAN|CTGAN]] and [Synthetic data with SDV and CopulaGAN|CopulaGAN]].\nRegression data What does a regression consist of?\nFor this section we will mainly use scikit-learn\u0026rsquo;s make_regression method.\nFor reproducibility, we will set a random_state.\nimport warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;) warnings.simplefilter(\u0026#39;ignore\u0026#39;)  random_state = 23 We will create a dataset using make_regression\u0026rsquo;s random linear regression model with input features \\(x=(f_1,f_2,f_3,f_4)\\) and an output \\(y\\).\nimport matplotlib.pyplot as plt from plotnine import * from plotnine.data import * import numpy as np import pandas as pd from sklearn.datasets import make_regression from scipy.stats import linregress  N_FEATURES = 4 N_TARGETS = 1 N_SAMPLES = 100  dataset = make_regression(  n_samples=N_SAMPLES,  n_features=N_FEATURES,  n_informative=2,  n_targets=N_TARGETS,  bias=0.0,  effective_rank=None,  tail_strength=0.5,  noise=0.0,  shuffle=True,  coef=False,  random_state=random_state, )  print(dataset[0][:10]) print(dataset[1][:10]) [[ 0.87305874 -1.63096187 0.52538404 -0.19035824]  [ 1.00698671 0.79834941 -0.04057655 -0.31358605]  [-0.61464273 1.65110321 0.75791487 -0.0039844 ]  [-1.08536678 1.82337823 0.4612592 -1.72325306]  [-1.67774847 -0.54401341 0.86347869 -0.30250463]  [-0.02427254 0.75537599 -0.04644972 -0.85153564]  [-0.48085576 0.82100952 -0.9390196 -0.25870492]  [-0.66772841 -2.46244005 -0.19855095 -1.85756579]  [-0.29810663 -0.02239635 0.25363492 -1.22688366]  [ 1.48146924 0.38269965 -1.18208819 -1.31062148]] [ 20.00449025 -30.41054677 52.65371365 -119.26376184 33.78805456  -78.12189078 -88.41673748 -177.21674804 -90.13920313 -197.90799195] Let\u0026rsquo;s turn this dataset into a Pandas DataFrame:\ndf = pd.DataFrame(data=dataset[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURES)])  df[\u0026#34;y\u0026#34;] = dataset[1]  df.head()  f1 f2 f3 f4 y 0 0.873059 -1.630962 0.525384 -0.190358 20.004490 1 1.006987 0.798349 -0.040577 -0.313586 -30.410547 2 -0.614643 1.651103 0.757915 -0.003984 52.653714 3 -1.085367 1.823378 0.461259 -1.723253 -119.263762 4 -1.677748 -0.544013 0.863479 -0.302505 33.788055 Let\u0026rsquo;s plot the data:\n Changing the Gaussian noise level The noise parameter in make_regression allows to adjust the scale of the data\u0026rsquo;s gaussian centered noise.\ndataset = make_regression(  n_samples=N_SAMPLES,  n_features=N_FEATURES,  n_informative=2,  n_targets=N_TARGETS,  bias=0.0,  effective_rank=None,  tail_strength=0.5,  noise=2.0,  shuffle=True,  coef=False,  random_state=random_state, )  df = pd.DataFrame(data=dataset[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURES)])  df[\u0026#34;y\u0026#34;] = dataset[1]  plot_regression(df, N_FEATURES)  Visualising increasing noise Let\u0026rsquo;s increase the noise by \\(10^i\\), for \\(i=1, 2, 3\\) and see what the data looks like.\ndf = pd.DataFrame(data=np.zeros((N_SAMPLES, 1)))  def create_noisy_data(noise):  return make_regression(  n_samples=N_SAMPLES,  n_features=1,  n_informative=1,  n_targets=1,  bias=0.0,  effective_rank=None,  tail_strength=0.5,  noise=noise,  shuffle=True,  coef=False,  random_state=random_state,  )   for i in range(3):  data = create_noisy_data(10 ** i)   df[f\u0026#34;f{i+1}\u0026#34;] = data[0]  df[f\u0026#34;y{i+1}\u0026#34;] = data[1]  for i in range(3):  fit = np.polyfit(df[f\u0026#34;f{i+1}\u0026#34;], df[f\u0026#34;y{i+1}\u0026#34;], 1)  fit_fn = np.poly1d(fit)  plt.subplot(1, 3, i + 1)  plt.scatter(df[f\u0026#34;f{i+1}\u0026#34;], df[f\u0026#34;y{i+1}\u0026#34;], s=30, c=colours[1], edgecolor=edges[1])  plt.plot(  df[f\u0026#34;f{i+1}\u0026#34;],  fit_fn(df[f\u0026#34;f{i+1}\u0026#34;]),  ls=\u0026#34;--\u0026#34;,  color=colours[0],  lw=1,  )  plt.xlabel(f\u0026#34;f{i+1}\u0026#34;)  plt.ylabel(f\u0026#34;y{i+1}\u0026#34;)  Classification data To generate data for classification we will use the make_classification method.\nfrom sklearn.datasets import make_classification  N = 4 data = make_classification(  n_samples=N_SAMPLES,  n_features=N,  n_informative=4,  n_redundant=0,  n_repeated=0,  n_classes=2,  n_clusters_per_class=1,  weights=None,  flip_y=0.01,  class_sep=1.0,  hypercube=True,  shift=0.0,  scale=1.0,  shuffle=True,  random_state=random_state, ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N)]) df[\u0026#34;y\u0026#34;] = data[1] df.head()  f1 f2 f3 f4 y 0 -3.216 -0.416 -1.295 -1.882 0 1 -1.426 -1.257 -1.734 -1.804 0 2 2.798 -3.010 -1.085 -3.134 1 3 0.633 2.502 -1.553 1.625 1 4 1.494 0.912 -1.887 -1.457 1  Cluster separation According to the docs1, class_sep is the factor multiplying the hypercube size.\nLarger values spread out the clusters/classes and make the classification task easier.\nN_FEATURES = 4  data = make_classification(  n_samples=N_SAMPLES,  n_features=N_FEATURES,  n_informative=4,  n_redundant=0,  n_repeated=0,  n_classes=2,  n_clusters_per_class=1,  weights=None,  flip_y=0.01,  class_sep=3.0,  hypercube=True,  shift=0.0,  scale=1.0,  shuffle=True,  random_state=None, )  df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURES)])  df[\u0026#34;y\u0026#34;] = data[1]  We can make the cluster separability more difficult, by decreasing the value of class_sep.\n Noise level According to the documentation1, flip_y is the fraction of samples whose class is assigned randomly.\nLarger values introduce noise in the labels and make the classification task harder.\n  It is noteworthy that many paremeters in scikit-learn for synthetic data generation allow inputs per feature or cluster. To do so, we simple pass the parameter value as an array. For instance, to\nSeparability from sklearn.datasets import make_blobs  N_FEATURE = 4  data = make_blobs(  n_samples=60,  n_features=N_FEATURE,  centers=3,  cluster_std=1.0,  center_box=(-5.0, 5.0),  shuffle=True,  random_state=None, ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURE)]) df[\u0026#34;y\u0026#34;] = data[1]  To make a cluster more separable we can change cluster_std.\ndata = make_blobs(  n_samples=60,  n_features=N_FEATURES,  centers=3,  cluster_std=0.3,  center_box=(-5.0, 5.0),  shuffle=True,  random_state=None, ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURES)]) df[\u0026#34;y\u0026#34;] = data[1]  By decreasing cluster_std we make them less separable.\ndata = make_blobs(  n_samples=60,  n_features=N_FEATURES,  centers=3,  cluster_std=2.5,  center_box=(-5.0, 5.0),  shuffle=True,  random_state=None, ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(N_FEATURES)]) df[\u0026#34;y\u0026#34;] = data[1]  Anisotropic data data = make_blobs(n_samples=50, n_features=2, centers=3, cluster_std=1.5) transformation = [[0.5, -0.5], [-0.4, 0.8]] data_0 = np.dot(data[0], transformation) df = pd.DataFrame(data_0, columns=[f\u0026#34;f{i}\u0026#34; for i in range(1, 3)]) df[\u0026#34;y\u0026#34;] = data[1] plt.scatter(  df[\u0026#34;f1\u0026#34;],  df[\u0026#34;f2\u0026#34;],  c=df[\u0026#34;y\u0026#34;].apply(lambda y: colours[y]),  s=50,  edgecolors=df[\u0026#34;y\u0026#34;].apply(lambda y: edges[y]), ) plt.xlabel(\u0026#34;f1\u0026#34;) plt.ylabel(\u0026#34;f2\u0026#34;) plt.show()  Concentric clusters Sometimes we might be interested in creating a non-separable cluster. The simples way is to create concentric clusters with the make_circles method.\nfrom sklearn.datasets import make_circles  data = make_circles(  n_samples=N_SAMPLES, shuffle=True, noise=None, random_state=random_state, factor=0.6 ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(2)]) df[\u0026#34;y\u0026#34;] = data[1]  Adding noise The noise parameter allows to create a concentric noisy dataset.\ndata = make_circles(  n_samples=N_SAMPLES, shuffle=True, noise=0.15, random_state=random_state, factor=0.6 ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(2)]) df[\u0026#34;y\u0026#34;] = data[1]  Moon clusters A shape that can be useful to other methods (such as Counterfactuals, for instance) is the one generated by the make_moons method.\nfrom sklearn.datasets import make_moons  data = make_moons(  n_samples=N_SAMPLES, shuffle=True, noise=None, random_state=random_state ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(2)]) df[\u0026#34;y\u0026#34;] = data[1]  Adding noise As usual, the noise parameter allows to control the noise.\ndata = make_moons(  n_samples=N_SAMPLES, shuffle=True, noise=0.1, random_state=random_state ) df = pd.DataFrame(data[0], columns=[f\u0026#34;f{i+1}\u0026#34; for i in range(2)]) df[\u0026#34;y\u0026#34;] = data[1]  Time-series data Random walk See Random walk\n  https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make%5Fclassification.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/synthetic-data-generation.html","tags":null,"title":"Synthetic Data Generation"},{"categories":null,"contents":"Synthetic data with SDV and Gaussian copulas Synthetic data with SDV and CTGAN Synthetic data with SDV and CopulaGAN ","permalink":"https://ruivieira.dev/synthetic-data-generation-with-sdv.html","tags":null,"title":"Synthetic Data Generation with SDV"},{"categories":null,"contents":"```python data.head() ```\n``` ## Pclass Sex Age SibSp Parch Fare ## 0 3 1 22.0 1 0 7.2500 ## 1 1 0 38.0 1 0 71.2833 ## 2 3 0 26.0 0 0 7.9250 ## 3 1 0 35.0 1 0 53.1000 ## 4 3 1 35.0 0 0 8.0500 ```\n```python data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n``` ## Pclass Sex Age SibSp Parch Fare ## count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 ## mean 2.308642 0.647587 29.758889 0.523008 0.381594 32.204208 ## std 0.836071 0.477990 13.002570 1.102743 0.806057 49.693429 ## min 1.000000 0.000000 0.420000 0.000000 0.000000 0.000000 ## 25% 2.000000 0.000000 22.000000 0.000000 0.000000 7.910400 ## 50% 3.000000 1.000000 30.000000 0.000000 0.000000 14.454200 ## 75% 3.000000 1.000000 35.000000 1.000000 0.000000 31.000000 ## max 3.000000 1.000000 80.000000 8.000000 6.000000 512.329200 ```\n```python from sdv.tabular import CopulaGAN ```\n```python model = CopulaGAN() ```\n```python model.fit(data) ```\n```python new_data = model.sample(200) ```\n```python new_data.head() ```\n``` ## Pclass Sex Age SibSp Parch Fare ## 0 1 0 11.797730 3 2 15.963036 ## 1 2 0 28.135436 2 2 12.701402 ## 2 3 0 26.367627 0 1 10.742400 ## 3 3 1 24.116738 0 1 144.611161 ## 4 2 0 31.368429 3 1 13.659402 ```\n```python new_data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n``` ## Pclass Sex Age SibSp Parch Fare ## count 200.000000 200.000000 200.000000 200.000000 200.000000 200.000000 ## mean 1.990000 0.440000 31.717758 0.945000 1.240000 76.998168 ## std 0.795654 0.497633 14.745161 0.925341 1.487773 82.340578 ## min 1.000000 0.000000 -0.299758 0.000000 0.000000 4.534767 ## 25% 1.000000 0.000000 23.051398 0.000000 0.000000 14.265699 ## 50% 2.000000 0.000000 30.367405 1.000000 1.000000 36.297745 ## 75% 3.000000 1.000000 40.796266 1.000000 2.000000 115.727641 ## max 3.000000 1.000000 77.002768 5.000000 6.000000 350.698375 ```\n```python from sdv.evaluation import evaluate\nevaluate(new_data, data) ```\n``` ## 0.4487854281948458 ```\n```python model = CopulaGAN( field_transformers={ \u0026lsquo;Pclass\u0026rsquo;: \u0026lsquo;categorical\u0026rsquo;, \u0026lsquo;Sex\u0026rsquo;: \u0026lsquo;categorical\u0026rsquo;, \u0026lsquo;Age\u0026rsquo;: \u0026lsquo;float\u0026rsquo;, \u0026lsquo;SibSp\u0026rsquo;: \u0026lsquo;boolean\u0026rsquo;, \u0026lsquo;Parch\u0026rsquo;: \u0026lsquo;integer\u0026rsquo;, \u0026lsquo;Fare\u0026rsquo;: \u0026lsquo;float\u0026rsquo; }, field_distributions={ \u0026lsquo;Fare\u0026rsquo;: \u0026rsquo;truncated_gaussian\u0026rsquo; } ) ```\n```python model.fit(data) ```\n```python new_data = model.sample(200) ```\n```python new_data.head() ```\n```python new_data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n```python evaluate(new_data, data) ```\n```python\n```\n","permalink":"https://ruivieira.dev/synthetic-data-with-svd-and-copulagan.html","tags":null,"title":"Synthetic data with SDV and CopulaGAN"},{"categories":null,"contents":"```python import pandas as pd import warnings\nwarnings.filterwarnings(\u0026lsquo;ignore\u0026rsquo;)\ndata = pd.read_csv(\u0026ldquo;data/svm-hyperparameters-train-features.csv\u0026rdquo;) ```\n```python data.head() ```\n```python data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n```python from sdv.tabular import CTGAN ```\n```python model = CTGAN() ```\n```python model.fit(data) ```\n```python new_data = model.sample(200) ```\n```python new_data.head() ```\n```python new_data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n```python from sdv.evaluation import evaluate\nevaluate(new_data, data) ```\n```python model = CTGAN( epochs=500, batch_size=100, generator_dim=(256, 256, 256), discriminator_dim=(256, 256, 256) ) ```\n```python model.fit(data) ```\n```python new_data = model.sample(200) ```\n```python new_data.head() ```\n```python new_data.describe(include=\u0026lsquo;all\u0026rsquo;) ```\n```python evaluate(new_data, data) ```\n```python\n```\n","permalink":"https://ruivieira.dev/synthetic-data-with-sdv-and-ctgan.html","tags":null,"title":"Synthetic data with SDV and CTGAN"},{"categories":null,"contents":"import pandas as pd  data = pd.read_csv(\u0026#34;data/svm-hyperparameters-train-features.csv\u0026#34;) data.head()  Pclass Sex Age SibSp Parch Fare 0 3 1 22.0 1 0 7.2500 1 1 0 38.0 1 0 71.2833 2 3 0 26.0 0 0 7.9250 3 1 0 35.0 1 0 53.1000 4 3 1 35.0 0 0 8.0500 data.describe(include=\u0026#34;all\u0026#34;)  Pclass Sex Age SibSp Parch Fare count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 mean 2.308642 0.647587 29.758889 0.523008 0.381594 32.204208 std 0.836071 0.477990 13.002570 1.102743 0.806057 49.693429 min 1.000000 0.000000 0.420000 0.000000 0.000000 0.000000 25% 2.000000 0.000000 22.000000 0.000000 0.000000 7.910400 50% 3.000000 1.000000 30.000000 0.000000 0.000000 14.454200 75% 3.000000 1.000000 35.000000 1.000000 0.000000 31.000000 max 3.000000 1.000000 80.000000 8.000000 6.000000 512.329200 from sdv.tabular import GaussianCopula --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) /var/folders/c2/9d2fsqt57t10zn1f2ylp1jxw0000gn/T/ipykernel_62349/3994888440.py in \u0026lt;module\u0026gt; ----\u0026gt; 1 from sdv.tabular import GaussianCopula  ModuleNotFoundError: No module named \u0026#39;sdv\u0026#39; ```python\nmodel = GaussianCopula() ```\n```python\nmodel.fit(data) ```\n```python\nN_SAMPLES = 1000 ```\n```python\nnew_df = model.sample(N_SAMPLES) ```\n```python\nnew_df.head() ```\n```python\nnew_df.describe() ```\n```python\nfrom plotnine import * from plotnine.data import * from plotutils import *  ggplot() + geom_histogram(data=data, mapping=aes(x=\u0026#39;Pclass\u0026#39;), fill=colours[0], bins=3, alpha=0.3) + \\ geom_histogram(data=new_df, mapping=aes(x=\u0026#39;Pclass\u0026#39;), fill=colours[1], bins=3, alpha=0.3) + \\ theme_classic() ```\n```python\nggplot() + geom_histogram(data=data, mapping=aes(x=\u0026#39;Sex\u0026#39;), fill=colours[0], bins=6, alpha=0.3) + \\ geom_histogram(data=new_df, mapping=aes(x=\u0026#39;Sex\u0026#39;), fill=colours[1], bins=6, alpha=0.3) + \\ theme_classic() ```\n```python\nggplot(mapping=aes(x=\u0026#39;Age\u0026#39;)) + \\ geom_density(data=data, fill=colours[0], alpha=0.2) + \\ geom_density(data=new_df, fill=colours[1], alpha=0.2) + \\ geom_vline(xintercept=data.Age.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[0]) + \\ geom_vline(xintercept=new_df.Age.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[1]) + \\ theme_classic() ```\n```python\nggplot(mapping=aes(x=\u0026#39;Fare\u0026#39;)) + \\ geom_density(data=data, fill=colours[0], alpha=0.2) + \\ geom_density(data=new_df, fill=colours[1], alpha=0.2) + \\ geom_vline(xintercept=data.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[0]) + \\ geom_vline(xintercept=new_df.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[1]) + \\ theme_classic() ```\n```python\nmodel = GaussianCopula(  field_transformers={  \u0026#39;Pclass\u0026#39;: \u0026#39;categorical\u0026#39;,  \u0026#39;Sex\u0026#39;: \u0026#39;categorical\u0026#39;,  \u0026#39;Age\u0026#39;: \u0026#39;float\u0026#39;,  \u0026#39;SibSp\u0026#39;: \u0026#39;boolean\u0026#39;,  \u0026#39;Parch\u0026#39;: \u0026#39;integer\u0026#39;,  \u0026#39;Fare\u0026#39;: \u0026#39;float\u0026#39;  } ) ```\n```python\nmodel.fit(data) ```\n```python\nnew_df = model.sample(N_SAMPLES) ```\n```python\nnew_df.head() ```\n```python\nggplot() + geom_histogram(data=data, mapping=aes(x=\u0026#39;Pclass\u0026#39;), fill=colours[0], bins=3, alpha=0.3) + \\ geom_histogram(data=new_df, mapping=aes(x=\u0026#39;Pclass\u0026#39;), fill=colours[1], bins=3, alpha=0.3) + \\ theme_classic() ```\n```python\nggplot() + geom_histogram(data=data, mapping=aes(x=\u0026#39;Sex\u0026#39;), fill=colours[0], bins=6, alpha=0.3) + \\ geom_histogram(data=new_df, mapping=aes(x=\u0026#39;Sex\u0026#39;), fill=colours[1], bins=6, alpha=0.3) + \\ theme_classic() ```\n```python\nggplot(mapping=aes(x=\u0026#39;Age\u0026#39;)) + \\ geom_density(data=data, fill=colours[0], alpha=0.2) + \\ geom_density(data=new_df, fill=colours[1], alpha=0.2) + \\ geom_vline(xintercept=data.Age.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[0]) + \\ geom_vline(xintercept=new_df.Age.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[1]) + \\ theme_classic() ```\n```python\nggplot(mapping=aes(x=\u0026#39;Fare\u0026#39;)) + \\ geom_density(data=data, fill=colours[0], alpha=0.2) + \\ geom_density(data=new_df, fill=colours[1], alpha=0.2) + \\ geom_vline(xintercept=data.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[0]) + \\ geom_vline(xintercept=new_df.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[1]) + \\ theme_classic() ```\n```python\ndata.Fare.describe() ```\n```python\ndistributions = model.get_distributions() ```\n```python\ndistributions ```\n```python\nmodel = GaussianCopula(  field_transformers={  \u0026#39;Pclass\u0026#39;: \u0026#39;categorical\u0026#39;,  \u0026#39;Sex\u0026#39;: \u0026#39;categorical\u0026#39;,  \u0026#39;Age\u0026#39;: \u0026#39;float\u0026#39;,  \u0026#39;SibSp\u0026#39;: \u0026#39;boolean\u0026#39;,  \u0026#39;Parch\u0026#39;: \u0026#39;integer\u0026#39;,  \u0026#39;Fare\u0026#39;: \u0026#39;float\u0026#39;  },  field_distributions={  \u0026#39;Fare\u0026#39;: \u0026#39;truncated_gaussian\u0026#39;  } ) ```\n```python\nmodel.fit(data) ```\n```python\nnew_df = model.sample(N_SAMPLES) ```\n```python\nnew_df.Fare.describe() ```\n```python\nggplot(mapping=aes(x=\u0026#39;Fare\u0026#39;)) + \\ geom_density(data=data, fill=colours[0], alpha=0.2) + \\ geom_density(data=new_df, fill=colours[1], alpha=0.2) + \\ geom_vline(xintercept=data.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[0]) + \\ geom_vline(xintercept=new_df.Fare.mean(), linetype=\u0026#39;dotted\u0026#39;, colour=colours[1]) + \\ theme_classic() ```\n```python\n```\n","permalink":"https://ruivieira.dev/synthetic-data-with-svd-and-gaussian-copulas.html","tags":null,"title":"Synthetic data with SVD and Gaussian copulas"},{"categories":null,"contents":"(Based on Rasmus BÃ¥Ã¥th\u0026rsquo;s post)\nA scaled \\(t\\) distribution, with \\(\\mu\\) mean, \\(s\\) scale and \\(\\nu\\) degrees of freedom, can be simulated\nfrom a mixture of Normals with \\(\\\\mu\\) mean and precisions following a Gamma distribution:\n\\begin{aligned} y \u0026amp;\\sim \\mathcal{N}\\left(\\mu,\\sigma\\right) \\\\\\\\ \\sigma^2 \u0026amp;\\sim \\mathcal{IG}\\left(\\frac{\\nu}{2},s^2\\frac{\\nu}{2}\\right) \\end{aligned}\nSince I\u0026rsquo;ve recently pickep up again the crystal-gsl in my spare time, I\u0026rsquo;ve decided to replicate the previously mentioned post using a Crystal one-liner.\nTo simulate 10,000 samples from \\(t_2\\left(0,3\\right)\\) using the mixture, we can then write:\nsamples = (0..10000).map { |x|  Normal.sample 0.0, 1.0/Math.sqrt(Gamma.sample 1.0, 9.0) } We can see the mixture distribution (histogram) converging nicely to the \\((t_2(0,3)\\) (red):\n\n","permalink":"https://ruivieira.dev/t-as-mixture-of-normals.html","tags":null,"title":"t as mixture of Normals"},{"categories":null,"contents":"Introduction Tikz is a language for vector drawing and producing technical illustrations.\nExamples Random elements \n \\begin{tikzpicture}  \\foreach \\y in {0.0,0.1,...,0.9} {  \\foreach \\x in {0.0,0.1,...,0.9} {  \\pgfmathparse{0.9*rnd+0.3}  \\definecolor{MyColor}{rgb}{\\pgfmathresult,\\pgfmathresult,\\pgfmathresult}  \\path[fill=MyColor] (\\x,\\y) rectangle ++(0.1,0.1);  }  }  \\end{tikzpicture}  Template functions If we want to draw several blocks of random noise (as in Random elements):\n\n\\newcommand\\RandomBlock[8]{% \t\\foreach \\y in {{#1},{#2},...,{#3}} { \t\\foreach \\x in {{#4},{#5},...,{#6}} { \t\\pgfmathparse{0.9*rnd+0.1} \t\\definecolor{Grey}{rgb}{\\pgfmathresult,\\pgfmathresult,\\pgfmathresult} \t\\path[fill=Grey] (\\x,\\y) rectangle ++({#7},{#8}); \t} } }  \\begin{tikzpicture} \t\\RandomBlock{0.0}{0.1}{0.9}{0.0}{0.1}{0.9}{0.1}{0.1} \t\\RandomBlock{0.0}{0.2}{1.8}{2.0}{2.2}{3.8}{0.1}{0.1} \t\\RandomBlock{0.0}{0.2}{1.8}{4.0}{4.2}{5.8}{0.2}{0.2} \\end{tikzpicture}  Computations Performing computations inside a template function (or macro):\n\n\\newcommand\\MyRect[4]{% \t\\draw[draw=black] ({#1},{#2}) rectangle ({(#1+#3)},{(#2+#4)}); }  \\begin{tikzpicture} \t\\MyRect{0.0}{0.0}{1}{2} \t\\MyRect{2.0}{0.0}{2}{2} \t\\MyRect{5.0}{0.0}{2}{1} \\end{tikzpicture}  ","permalink":"https://ruivieira.dev/tikz.html","tags":null,"title":"Tikz"},{"categories":null,"contents":"Peaks and troughs Let\u0026rsquo;s start by creating a random walk.\nimport numpy as np import pandas as pd  N = 10000 step_set = [-1, 0, 1] origin = np.zeros((1, 1)) step_shape = (N, 1) steps = np.random.choice(a=step_set, size=step_shape) path = np.concatenate([origin, steps]).cumsum(0) df = pd.DataFrame(path,  columns =[\u0026#39;y\u0026#39;]) df.head()  from scipy.signal import find_peaks  subset = df.head(100)  peaks = find_peaks(subset[\u0026#34;y\u0026#34;]) troughs = find_peaks(-subset[\u0026#34;y\u0026#34;]) peaks \u0026lt;AxesSubplot:xlabel=\u0026#39;index\u0026#39;, ylabel=\u0026#39;y\u0026#39;\u0026gt;  Autocorrelation Pandas provides an autocorrelation1 plot function.\nfigure(figsize=(14, 7), dpi=80) pd.plotting.autocorrelation_plot(df[\u0026#34;y\u0026#34;]) \u0026lt;AxesSubplot:xlabel=\u0026#39;Lag\u0026#39;, ylabel=\u0026#39;Autocorrelation\u0026#39;\u0026gt;  Differencing Calculating the difference between \\(x_t\\) and \\(x_{t-1}\\).\nstationary = df[\u0026#39;y\u0026#39;].diff() figure(figsize=(14, 7), dpi=80) plt.plot(stationary) plt.show()    https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation%5Fplot.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/time-series-analysis.html","tags":null,"title":"Time-series analysis"},{"categories":null,"contents":"","permalink":"https://ruivieira.dev/transformation-functions.html","tags":null,"title":"Transformation functions"},{"categories":null,"contents":"Summary A collection of notes on typography.\nMonospaced fonts The Monoid font has a post to explain some design decisions1.\n  https://medium.com/larsenwork-andreas-larsen/class-based-contextual-positioning-in-monospaced-fonts-cb6b8b9ffe6f\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/typography.html","tags":null,"title":"Typography"},{"categories":null,"contents":"","permalink":"https://ruivieira.dev/unfairness-detection.html","tags":null,"title":"Unfairness detection"},{"categories":null,"contents":"Copy paste  Press v to select characters, or uppercase V to select whole lines y to copy Press P to paste before the cursor, or p to paste after  ","permalink":"https://ruivieira.dev/vim-keys.html","tags":null,"title":"Vim keys"},{"categories":null,"contents":"Download a file ```javascript saveFile: function() { const data = JSON.stringify(this.myData) const blob = new Blob([data], {type: \u0026rsquo;text/plain\u0026rsquo;}) const e = document.createEvent(\u0026lsquo;MouseEvents\u0026rsquo;), a = document.createElement(\u0026lsquo;a\u0026rsquo;); a.download = \u0026ldquo;myData.json\u0026rdquo;; a.href = window.URL.createObjectURL(blob); a.dataset.downloadurl = [\u0026rsquo;text/json\u0026rsquo;, a.download, a.href].join(\u0026rsquo;:\u0026rsquo;); e.initEvent(\u0026lsquo;click\u0026rsquo;, true, false, window, 0, 0, 0, 0, 0, false, false, false, false, 0, null); a.dispatchEvent(e); } ```\n","permalink":"https://ruivieira.dev/vue.html","tags":null,"title":"Vue"},{"categories":null,"contents":"Backup External media Since I switch OSes frequently1 having a minimum-hassle filesystem for my external drives would be very convenient. exFAT2 seems to me like the best solution. In fact, exFAT is the default FS for SD cards and USB flash drives with more than 32Gb. So perhaps, if have a large-ish USB pen or an external drive, chances are you don\u0026rsquo;t even need to reformat it.\nWorkflow Optimise PNGs To optimise an entired folder of PNGs, you could use optipng. Install it on macOS using\n$ brew install optipng and then apply it recusively with\n$ find . -name \u0026#34;*.png\u0026#34; -exec optipng -o7 {} \\;   I macOS and GNU/Linux (specifically Fedora and Ubuntu) daily, Windows seldomly.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://en.wikipedia.org/wiki/ExFAT\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/workflow.html","tags":null,"title":"Workflow"},{"categories":null,"contents":"Introduction XGBoost1 is a popular regularizing gradient boosting framework.\nInstallation In most systems, installing XGBoost can be done simply by using pip\n$ pip install xgboost Example Training XGBoost with the credit-bias dataset.\nimport pandas as pd  data = pd.read_csv(\u0026#34;data/credit-bias-train.zip\u0026#34;) data.head()  NewCreditCustomer Amount Interest LoanDuration Education \\ 0 False 2125.0 20.97 60 4.0 1 False 3000.0 17.12 60 5.0 2 True 9100.0 13.67 60 4.0 3 True 635.0 42.66 60 2.0 4 False 5000.0 24.52 60 4.0   NrOfDependants EmploymentDurationCurrentEmployer \\ 0 0.0 6.0 1 0.0 6.0 2 1.0 3.0 3 0.0 1.0 4 1.0 5.0   IncomeFromPrincipalEmployer IncomeFromPension IncomeFromFamilyAllowance \\ 0 0.0 301.0 0.0 1 900.0 0.0 0.0 2 600.0 0.0 0.0 3 745.0 0.0 0.0 4 1000.0 0.0 0.0   ... Mortgage Other Owner Owner_with_encumbrance Tenant Entrepreneur \\ 0 ... 0 0 1 0 0 0 1 ... 0 0 1 0 0 1 2 ... 1 0 0 0 0 1 3 ... 0 0 0 0 1 0 4 ... 0 0 0 0 0 0   Fully Partially Retiree Self_employed 0 0 0 1 0 1 0 0 0 0 2 0 0 0 0 3 1 0 0 0 4 1 0 0 0  [5 rows x 40 columns] X_df = data.drop(\u0026#39;PaidLoan\u0026#39;, axis=1) y_df = data[\u0026#39;PaidLoan\u0026#39;] y_df.describe() count 58003 unique 2 top True freq 29219 Name: PaidLoan, dtype: object from sklearn.model_selection import train_test_split train_x, test_x, train_y, test_y = train_test_split(X_df, y_df, test_size=0.25, random_state=42) Hyperparameter estimation Runs a grid search to find the tuning parameters that maxisimise the area under the curve (AUC). train_x is the training data frame with loan details and train_y is the default target column for training. The method returns the best parameters and corresponding AUC score.\nThe objective parameter2 specifies the learning task and the corresponding learning objective. Possible values include:\nObjective function  reg:squarederror, regression with squared loss. reg:squaredlogerror, regression with squared log loss reg:logistic, logistic regression reg:pseudohubererror, regression with Pseudo Huber loss, a twice differentiable alternative to absolute loss. binary:logistic, logistic regression for binary classification, output probability binary:logitraw, logistic regression for binary classification, output score before logistic transformation binary:hinge, hinge loss for binary classification. This makes predictions of 0 or 1, rather than producing probabilities. count:poisson, poisson regression for count data, output mean of Poisson distribution survival:cox, Cox regression for right censored survival time data (negative values are considered right censored). survival:aft, Accelerated failure time model for censored survival time data. See Survival Analysis with Accelerated Failure Time for details. aft_loss_distribution, Probability Density Function used by survival:aft objective and aft-nloglik metric. multi:softmax, set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class (number of classes) multi:softprob, same as softmax, but output a vector of ndata * nclas~s, which can be further reshaped to ~ndata * nclass matrix. The result contains predicted probability of each data point belonging to each class. rank:pairwise, Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized rank:ndcg, Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized rank:map, Use LambdaMART to perform list-wise ranking where Mean Average Precision (MAP) is maximized reg:gamma, gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be gamma-distributed. reg:tweedie, Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be Tweedie-distributed.  Weight balance scale_pos_weight~ (default 1) control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider is sum(negative instances) / sum(positive instances).\nfrom sklearn.model_selection import GridSearchCV from xgboost.sklearn import XGBClassifier from typing import Tuple  def find_best_xgboost_model(train_x: pd.DataFrame, train_y: pd.Series) -\u0026gt; Tuple[dict, float]:  scale_pos_weight = (len(train_y) - train_y.sum()) / train_y.sum()   param_test = {  \u0026#39;max_depth\u0026#39;: [1, 2, 4, 8],  \u0026#39;learning_rate\u0026#39;: [0.05, 0.06, 0.07],  \u0026#39;n_estimators\u0026#39;: [10, 100, 200]  }   gsearch = GridSearchCV(estimator=XGBClassifier(  use_label_encoder=False,  objective=\u0026#39;binary:logistic\u0026#39;,  scale_pos_weight=scale_pos_weight,  seed=27),  param_grid=param_test, scoring=\u0026#39;roc_auc\u0026#39;, n_jobs=-1, cv=8)   gsearch.fit(train_x, train_y)   return gsearch.best_params_, gsearch.best_score_ best_params, best_score = find_best_xgboost_model(train_x, train_y) Using the xgboost model parameters, it predicts the probabilities of defaulting.\n best_params_, best tuning parameters train_x, training dataframe with loan details train_y, default target column for training test_x, testing dataframe with loan details test_y, default target column for testing  The result is a series of probabilities whether loan entry will default or not and corresponding model\u0026rsquo;s AUC score\nfrom sklearn.metrics import roc_auc_score  def xgboost_predict(best_params_: dict, train_x: pd.DataFrame, train_y: pd.Series, test_x: pd.DataFrame,  test_y: pd.Series) -\u0026gt; Tuple[list, float]:  scale_pos_weight = (len(train_y) - train_y.sum()) / train_y.sum()  xgb_model = XGBClassifier(objective=\u0026#39;binary:logistic\u0026#39;,  scale_pos_weight=scale_pos_weight,  seed=27,  max_depth=best_params_[\u0026#39;max_depth\u0026#39;],  learning_rate=best_params_[\u0026#39;learning_rate\u0026#39;],  n_estimators=best_params_[\u0026#39;n_estimators\u0026#39;]  )   xgb_model.fit(train_x, train_y)  predicted_probabilities_ = xgb_model.predict_proba(test_x)[:, 1]  auc_ = roc_auc_score(test_y, predicted_probabilities_)   return predicted_probabilities_, auc_ predicted_probabilities, auc = xgboost_predict(best_params, train_x, train_y, test_x, test_y) print(\u0026#34;AUC: {}\u0026#34;.format(auc)) /Users/rui/.virtualenvs/blog-source/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. [19:39:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective \u0026#39;binary:logistic\u0026#39; was changed from \u0026#39;error\u0026#39; to \u0026#39;logloss\u0026#39;. Explicitly set eval_metric if you\u0026#39;d like to restore the old behavior. AUC: 0.7372207434311429 Filters the original loan dataframe to just include the loans from the test dataframe and then it adds the predicted probabilities.\n loans_df_, original loan dataframe test_index, indices from the test dataframes predicted_probabilities_, the probabilities forecasted by the XGBoost model  Returns the loans dataframe with predictions\nimport numpy as np  def prepare_test_with_predictions(loans_df_: pd.DataFrame, test_index: pd.Index, predicted_probabilities_: np.array)\\  -\u0026gt;pd.DataFrame:  loan_test_df = loans_df_.loc[test_index]  loan_test_df[\u0026#39;predicted_probabilities\u0026#39;] = predicted_probabilities_  return loan_test_df loans_with_predictions_df = prepare_test_with_predictions(data, test_x.index, predicted_probabilities) loans_with_predictions_df.head()  NewCreditCustomer Amount Interest LoanDuration Education \\ 30299 False 530.0 10.68 36 4.0 34126 False 530.0 21.57 24 4.0 11200 False 2300.0 15.62 36 4.0 25133 True 530.0 27.36 36 4.0 42758 True 4250.0 18.94 60 4.0   NrOfDependants EmploymentDurationCurrentEmployer \\ 30299 NaN 5.0 34126 NaN 1.0 11200 0.0 6.0 25133 NaN 6.0 42758 NaN 1.0   IncomeFromPrincipalEmployer IncomeFromPension \\ 30299 0.0 0.0 34126 0.0 0.0 11200 1159.0 0.0 25133 0.0 0.0 42758 0.0 0.0   IncomeFromFamilyAllowance ... Other Owner Owner_with_encumbrance \\ 30299 0.0 ... 0 0 0 34126 0.0 ... 0 0 0 11200 0.0 ... 0 1 0 25133 0.0 ... 0 0 1 42758 0.0 ... 0 0 0   Tenant Entrepreneur Fully Partially Retiree Self_employed \\ 30299 1 0 0 0 0 0 34126 0 0 0 0 0 0 11200 0 0 1 0 0 0 25133 0 0 0 0 0 0 42758 0 0 0 0 0 0   predicted_probabilities 30299 0.662289 34126 0.749224 11200 0.775058 25133 0.423509 42758 0.535847  [5 rows x 41 columns] Visualisation import seaborn as sns  sns.histplot(loans_with_predictions_df[\u0026#39;predicted_probabilities\u0026#39;], stat=\u0026#39;density\u0026#39;) \u0026lt;AxesSubplot:xlabel=\u0026#39;predicted_probabilities\u0026#39;, ylabel=\u0026#39;Density\u0026#39;\u0026gt;  ROC and AUC Based on actuals and predicted values, it calculates their false positive rate (fpr), the true positive rate (tpr). It also returns the corresponding thresholds used as well as the value for the area under the curve.\nactuals, series of actual values indicating whether the loan defaulted or not predicted_probabilities, series of predicted probabilities of the loan defaulting Return a unique series of false and true positive rates with corresponding series of thresholds and value for total area under the curve.\nfrom sklearn.metrics import roc_curve, auc  def get_roc_auc_data(actuals: pd.Series, predicted_probabilities: pd.Series) -\u0026gt; \\  Tuple[np.array, np.array, np.array, float]:  fpr, tpr, thresholds = roc_curve(actuals, predicted_probabilities, pos_label=1)  auc_score = auc(fpr, tpr)  return fpr, tpr, thresholds, auc_score fpr, tpr, thresholds, auc_score = get_roc_auc_data(loans_with_predictions_df[\u0026#39;PaidLoan\u0026#39;], loans_with_predictions_df[\u0026#39;predicted_probabilities\u0026#39;]) sns.lineplot(fpr) /Users/rui/.virtualenvs/blog-source/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. /Users/rui/.virtualenvs/blog-source/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1368: RuntimeWarning: All-NaN slice encountered \u0026lt;AxesSubplot:\u0026gt;    https://github.com/dmlc/xgboost\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ruivieira.dev/xgboost.html","tags":null,"title":"XGBoost"}]