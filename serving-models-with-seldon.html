<!DOCTYPE html>
<head>
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="48x48" href="/favicons/favicon.ico">

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
          integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
            integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
            crossorigin="anonymous"></script>

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
            integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>

    <link href="https://fonts.googleapis.com/css?family=Nunito:400,300i,800&display=swap" rel="stylesheet"/>
    <link href="/assets/style.css" rel="stylesheet"/>
    <title>ruivieira.dev - Serving models with Seldon</title>
    <script type="application/javascript">
        var doNotTrack = false;
        if (!doNotTrack) {
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function () {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                    m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
            ga('create', 'UA-10507665-2', 'auto');

            ga('send', 'pageview');
        }
    </script>
</head>
<body>

<div id="content">
    <h1 id="serving-models-with-seldon">Serving models with Seldon</h1>
<p>Deploying machine learning models in production comes with several requirements.<br />
We must manage the model lifecycle. We need reproducibility and typically use containerised workflows.</p>
<p><a href="https://github.com/SeldonIO/seldon-core">Seldon</a> is a tool which aims at providing a production workflow for machine learning models, allowing to build model serving containers which expose well-defined APIs.</p>
<p>In this post, I'll show how to create a simple model and how to deploy it with Seldon. The model is a customer segmentation one. The goal is to classify a customer according to a segment (0, 1 or 2), according to its age, income, whether they engaged with previous campaigns and the campaign type.</p>
<p>Once we train the model, we deploy it with Seldon in a container orchestration<br />
platform such as <a href="https://kubernetes.io/">Kubernetes</a> and <a href="https://www.openshift.com/">OpenShift</a>.</p>
<h2 id="create-data">Create data</h2>
<p>We use the Python's <a href="https://scikit-learn.org/stable/"><code>scikit-learn</code></a> to train our model.<br />
However, we must first simulate some data to train it.<br />
We start by simulating the users age (<span class="math inline">\(a\)</span>) and income (<span class="math inline">\(c\)</span>). We assume income is correlated with age.</p>
<p><span class="math display">\[c|a \sim \mathcal{N}\left(a + 20, 100\right)  \\\\
a|k \sim \mathcal{U}\left(A_k, B_k\right),\quad A=\left\lbrace16, 25, 50, 61\right\rbrace,B=\left\lbrace24, 49, 60, 90\right\rbrace  \\\\
k \sim \mathcal{M}\left(4, \left\lbrace 0.15, 0.4, 0.2, 0.25\right\rbrace\right)
\]</span></p>
<p><img src="./images/seldon_segments.png" alt="" /></p>
<p>Let's assume we have eight distinct events (<span class="math inline">\(e=\left(0, 1, \dots, 7\right)\)</span>). We sample them from a multinomial<br />
distribution and also assume that two different age bands have different distributions, just to add some variation.</p>
<p><span class="math display">\[e = \begin{cases} \mathcal{M}\left(7, \left\lbrace 0.026, 0.195, 0.156, 0.208, 0.130, 0.205, 0.078 \right\rbrace\right) & \text{if}\ a < 50 \\\\
\mathcal{M}\left(7, \left\lbrace 0.052, 0.143, 0.169, 0.182, 0.164, 0.182, 0.104 \right\rbrace\right) & \text{if}\ a \geq 50
\end{cases}
\]</span></p>
<p><img src="./images/seldon_hist_event_income.png" alt="" /></p>
<p>The responses are calculated as <code>0</code> or <code>1</code>, representing &quot;true&quot; or &quot;false&quot;, and sampled from Bernoulli<br />
distributions, with different distributions depending on the event, again just to add some variation.</p>
<p><span class="math display">\[r = \begin{cases}
\text{Bernoulli}\left(0.6\right) & \text{if}\ e \in \left(2, 3, 4, 6\right) \\\\
\text{Bernoulli}\left(0.4\right) & \text{if}\ e \in \left(1, 5, 7\right)
\end{cases}
\]</span></p>
<p>To predict the response of a customer, we use a logistic model, with coefficients <span class="math inline">\(\beta_{age}=-0.0004\)</span> and <span class="math inline">\(\beta_{income}=0.0001\)</span>. For the customer level, we use a negative binomial model with coefficients <span class="math inline">\(\beta_{age}=-0.0233\)</span> and <span class="math inline">\(\beta_{income}=0.0054\)</span>.<br />
This results in the following distribution of customer levels:</p>
<p><img src="./images/seldon_level.png" alt="" /></p>
<p>Finally, we create the response according to negative binomial model with coefficients <span class="math inline">\(\beta_{level}=0.1862\)</span> and <span class="math inline">\(\beta_{response}=0.2076\)</span>. We get the following segments, stratified by age and income:</p>
<p><img src="./images/seldon_segments.png" alt="" /></p>
<h2 id="train-model">Train model</h2>
<p>Now that we have our simulated data, we can train a model.<br />
Generally, it is straightforward to train model data when in <code>pandas</code> data frame format.<br />
Let's proceed with creating a data frame with the data we've just generated:</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">import</span> <span style="color:#555">pandas</span> <span style="color:#000;font-weight:bold">as</span> <span style="color:#555">pd</span>

data <span style="color:#000;font-weight:bold">=</span> { <span style="color:#d14">&#39;age&#39;</span>: age, <span style="color:#d14">&#39;income&#39;</span>: income,
         <span style="color:#d14">&#39;class&#39;</span>: _class, <span style="color:#d14">&#39;response&#39;</span>: response,
         <span style="color:#d14">&#39;segment&#39;</span>: segment, <span style="color:#d14">&#39;events&#39;</span>: events }

df <span style="color:#000;font-weight:bold">=</span> pd<span style="color:#000;font-weight:bold">.</span>DataFrame(data)
</pre><p>We now create the training and testing datasets. The first thing is to define the classifier's <code>inputs</code> and <code>outputs</code> and then splitting each of them into training and testing. Here I have used a split of 60%/40% for training and testing respectively.</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">from</span> <span style="color:#555">sklearn.model_selection</span> <span style="color:#000;font-weight:bold">import</span> train_test_split

cols <span style="color:#000;font-weight:bold">=</span> [<span style="color:#d14">&#39;age&#39;</span>, <span style="color:#d14">&#39;income&#39;</span>, <span style="color:#d14">&#39;response&#39;</span>, <span style="color:#d14">&#39;events&#39;</span>]
inputs <span style="color:#000;font-weight:bold">=</span> df[cols]
outputs <span style="color:#000;font-weight:bold">=</span> df[<span style="color:#d14">&#39;segment&#39;</span>]

<span style="color:#998;font-style:italic"># split dataset</span>
X_train, X_test, y_train, y_test <span style="color:#000;font-weight:bold">=</span> \
    train_test_split(inputs,
                     outputs,
                     test_size<span style="color:#000;font-weight:bold">=</span><span style="color:#099">0.4</span>,
                     random_state<span style="color:#000;font-weight:bold">=</span><span style="color:#099">23</span>)
</pre><p>We use a Random Forest classifier as the underlying algorithm for our model.<br />
These are available in <code>sciki-learn</code> with the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>RandomForestClassifier</code></a> class.<br />
However, <code>scikit-learn</code> does not support categorical variables out of the box <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.<br />
To deal with them, we build a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"><code>Pipeline</code></a>, which allows to chain multiple transformations to our data, including a categorical variable processor, such as <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html"><code>OrdinalEncoder</code></a> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.<br />
We use <a href="https://github.com/scikit-learn-contrib/sklearn-pandas"><code>DataFrameMapper</code></a> to apply the encoder to the <code>response</code> and <code>events</code> columns and leave the remaining unchanged.</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">from</span> <span style="color:#555">sklearn.ensemble</span> <span style="color:#000;font-weight:bold">import</span> RandomForestClassifier
<span style="color:#000;font-weight:bold">from</span> <span style="color:#555">sklearn</span> <span style="color:#000;font-weight:bold">import</span> preprocessing
<span style="color:#000;font-weight:bold">from</span> <span style="color:#555">sklearn.pipeline</span> <span style="color:#000;font-weight:bold">import</span> Pipeline

<span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">build_RF_pipeline</span>(inputs, outputs, rf<span style="color:#000;font-weight:bold">=</span><span style="color:#999">None</span>):
    <span style="color:#000;font-weight:bold">if</span> <span style="color:#000;font-weight:bold">not</span> rf:
        rf <span style="color:#000;font-weight:bold">=</span> RandomForestClassifier()
    pipeline <span style="color:#000;font-weight:bold">=</span> Pipeline([
        (<span style="color:#d14">&#34;mapper&#34;</span>, DataFrameMapper([
            ([<span style="color:#d14">&#39;response&#39;</span>, <span style="color:#d14">&#39;events&#39;</span>], 
				preprocessing<span style="color:#000;font-weight:bold">.</span>OrdinalEncoder()),
            ([<span style="color:#d14">&#39;age&#39;</span>, <span style="color:#d14">&#39;income&#39;</span>], <span style="color:#999">None</span>)
        ])),
        (<span style="color:#d14">&#34;classifier&#34;</span>, rf)
    ])
    pipeline<span style="color:#000;font-weight:bold">.</span>fit(inputs, outputs)
    <span style="color:#000;font-weight:bold">return</span> pipeline
</pre><p>The actual training involves a simple hyper-parameter estimation using<br />
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"><code>RandomizedSearchCV</code></a>. This method performs a type of parameter grid search but restricting the search to only the specified values. For the scope of this post, it is not<br />
necessary to perform an exhaustive hyperparameter estimation.<br />
The <code>RF_estimation</code> function returns the best-fitted model after searching with the test dataset.</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">RF_estimation</span>(inputs, outputs,
                  estimator_steps<span style="color:#000;font-weight:bold">=</span><span style="color:#099">10</span>,
                  depth_steps<span style="color:#000;font-weight:bold">=</span><span style="color:#099">10</span>,
                  min_samples_split<span style="color:#000;font-weight:bold">=</span><span style="color:#999">None</span>,
                  min_samples_leaf<span style="color:#000;font-weight:bold">=</span><span style="color:#999">None</span>):
    <span style="color:#998;font-style:italic"># hyper-parameter estimation</span>
    n_estimators <span style="color:#000;font-weight:bold">=</span> [<span style="color:#0086b3">int</span>(x) <span style="color:#000;font-weight:bold">for</span> x <span style="color:#000;font-weight:bold">in</span> np<span style="color:#000;font-weight:bold">.</span>linspace(start<span style="color:#000;font-weight:bold">=</span><span style="color:#099">50</span>,
                                                stop<span style="color:#000;font-weight:bold">=</span><span style="color:#099">100</span>,
                                                num<span style="color:#000;font-weight:bold">=</span>estimator_steps)]
    max_depth <span style="color:#000;font-weight:bold">=</span> [<span style="color:#0086b3">int</span>(x) <span style="color:#000;font-weight:bold">for</span> x <span style="color:#000;font-weight:bold">in</span> np<span style="color:#000;font-weight:bold">.</span>linspace(<span style="color:#099">3</span>, <span style="color:#099">10</span>, num<span style="color:#000;font-weight:bold">=</span>depth_steps)]
    max_depth<span style="color:#000;font-weight:bold">.</span>append(<span style="color:#999">None</span>)
    <span style="color:#000;font-weight:bold">if</span> <span style="color:#000;font-weight:bold">not</span> min_samples_split:
        min_samples_split <span style="color:#000;font-weight:bold">=</span> [<span style="color:#099">1</span>, <span style="color:#099">2</span>, <span style="color:#099">4</span>]
    <span style="color:#000;font-weight:bold">if</span> <span style="color:#000;font-weight:bold">not</span> min_samples_leaf:
        min_samples_leaf <span style="color:#000;font-weight:bold">=</span> [<span style="color:#099">1</span>, <span style="color:#099">2</span>, <span style="color:#099">4</span>]
    bootstrap <span style="color:#000;font-weight:bold">=</span> [<span style="color:#999">True</span>, <span style="color:#999">False</span>]
    random_grid <span style="color:#000;font-weight:bold">=</span> {<span style="color:#d14">&#39;n_estimators&#39;</span>: n_estimators,
                   <span style="color:#d14">&#39;max_depth&#39;</span>: max_depth,
                   <span style="color:#d14">&#39;min_samples_split&#39;</span>: min_samples_split,
                   <span style="color:#d14">&#39;min_samples_leaf&#39;</span>: min_samples_leaf,
                   <span style="color:#d14">&#39;bootstrap&#39;</span>: bootstrap}

    rf_random <span style="color:#000;font-weight:bold">=</span> RandomizedSearchCV(
                    estimator<span style="color:#000;font-weight:bold">=</span>RandomForestClassifier(),
                    param_distributions<span style="color:#000;font-weight:bold">=</span>random_grid,
                    n_iter<span style="color:#000;font-weight:bold">=</span><span style="color:#099">100</span>,
                    scoring<span style="color:#000;font-weight:bold">=</span><span style="color:#d14">&#39;neg_mean_absolute_error&#39;</span>,
                    cv<span style="color:#000;font-weight:bold">=</span><span style="color:#099">3</span>, verbose<span style="color:#000;font-weight:bold">=</span><span style="color:#099">1</span>, random_state<span style="color:#000;font-weight:bold">=</span><span style="color:#099">42</span>, n_jobs<span style="color:#000;font-weight:bold">=-</span><span style="color:#099">1</span>)
    rf_random<span style="color:#000;font-weight:bold">.</span>fit(inputs, outputs)
    best_random <span style="color:#000;font-weight:bold">=</span> rf_random<span style="color:#000;font-weight:bold">.</span>best_estimator_

    <span style="color:#000;font-weight:bold">return</span> best_random
</pre><p>After applying the parameter estimation, we take the best scoring model and calculate the MSE. Unsurprisingly (given the simple model and simulated data), we get a very good fit.</p>
<pre style="background-color:#fff">rf_predictions <span style="color:#000;font-weight:bold">=</span> random_forest_pipeline<span style="color:#000;font-weight:bold">.</span>predict(X_test)
<span style="color:#000;font-weight:bold">print</span>(f<span style="color:#d14">&#34;MSE: {random_forest_pipeline.score(X_test, y_test)*100}%&#34;</span>)
<span style="color:#998;font-style:italic"># MSE: 99.95%</span>
</pre><p>The final step is serialising the model. Serialisation is necessary since we only serve the pre-trained model.<br />
To do so, we use the <a href="https://github.com/joblib/joblib"><code>joblib</code></a> library and save the model to a <code>model.pkl</code> file.</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">import</span> <span style="color:#555">joblib</span>

<span style="color:#998;font-style:italic">#save mode in filesystem</span>
joblib<span style="color:#000;font-weight:bold">.</span>dump(random_forest_pipeline, <span style="color:#d14">&#39;model.pkl&#39;</span>)
</pre><h2 id="deploy-model">Deploy model</h2>
<p>It is important to note that we don't need the model training code included in the Seldon server. The purpose of Seldon is not to <em>train</em> models, but to <em>deploy</em> them and manage their lifecycle.<br />
This workflow means that a typical Seldon deployment would only include the prediction endpoint implementation and<br />
a serialised model. This provision is made by firstly create a <em>wrapper</em> for our model which implements the Seldon endpoints.</p>
<h3 id="simple-model">Simple model</h3>
<p>We create a Python script called <code>Model.py</code> <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.<br />
The primary prediction endpoint uses the following signature:</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">predict</span>(<span style="color:#999">self</span>, X: np<span style="color:#000;font-weight:bold">.</span>ndarray, names: Iterable[<span style="color:#0086b3">str</span>], meta: Dict <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">None</span>)
</pre><p>The wrapper is straightforward, in this example.<br />
We use the <code>joblib</code> library again, to load the serialised model <code>model.pkl</code>, and then pass through any JSON payload as inputs (<code>X</code>) to the model to get a prediction as well as using Python's default <a href="https://docs.python.org/3/library/logging.html">logging</a><br />
to provide some feedback.</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">import</span> <span style="color:#555">joblib</span>
<span style="color:#000;font-weight:bold">import</span> <span style="color:#555">logging</span>

<span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">Model</span>(<span style="color:#0086b3">object</span>):

    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>):
        logger<span style="color:#000;font-weight:bold">.</span>info(<span style="color:#d14">&#34;Initializing.&#34;</span>)
        logger<span style="color:#000;font-weight:bold">.</span>info(<span style="color:#d14">&#34;Loading model.&#34;</span>)
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>model <span style="color:#000;font-weight:bold">=</span> joblib<span style="color:#000;font-weight:bold">.</span>load(<span style="color:#d14">&#39;model.pkl&#39;</span>)

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">predict</span>(<span style="color:#999">self</span>, X, features_names):
        <span style="color:#000;font-weight:bold">return</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>model<span style="color:#000;font-weight:bold">.</span>predict_proba(X)
</pre><p>We now build the model using the <code>s2i</code> (<a href="https://github.com/openshift/source-to-image">source-to-image</a>).<br />
As the name implies, <code>s2i</code>'s allow to create a container image from source code, taking care of any necessary intermediate steps.<br />
Seldon support several types of builds (such as Python, R and Java) <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>Typically <code>s2i</code>'s rely on certain conventions (over configuration) on your application structure. A requirement when building a Seldon model using its <code>s2i</code> is to provide some specific environment variables. These are usually stored in a file located in <code>$REPO/.s2i/environment</code>. For instance, for this model we use:</p>
<pre style="background-color:#fff"><span style="color:#008080">MODEL_NAME</span><span style="color:#000;font-weight:bold">=</span><span style="color:#d14">Model</span>
<span style="color:#008080">API_TYPE</span><span style="color:#000;font-weight:bold">=</span><span style="color:#d14">REST</span>
<span style="color:#008080">SERVICE_TYPE</span><span style="color:#000;font-weight:bold">=</span><span style="color:#d14">MODEL</span>
<span style="color:#008080">PERSISTENCE</span><span style="color:#000;font-weight:bold">=</span><span style="color:#d14">0</span>
</pre><p>The <code>MODEL_NAME</code> corresponds to the script we've created previously, <code>Model.py</code> and instructs Seldon to use it as the REST endpoint provider. <code>API_TYPE</code> defines the endpoint interface. We use the REST interface, other possibilities include gRPC, for instance.</p>
<p><img src="./images/diagram.png" alt="" /></p>
<p>To build the container image using the <code>s2i</code>, assuming you want an image named <code>$NAME</code> and tagged with <code>$TAG</code>, we simply need to run:</p>
<pre style="background-color:#fff">$ s2i build <span style="color:#008080">$REPO</span> <span style="color:#d14">\
</span><span style="color:#d14"></span>  seldonio/seldon-core-s2i-python36:0.18 <span style="color:#d14">\
</span><span style="color:#d14"></span>  <span style="color:#008080">$NAME</span>:<span style="color:#008080">$TAG</span>
</pre><p>You can provide the location of your source code either by specifying a remote Git repository or by passing a local one.<br />
Once the container image builds, you can now run it using, for instance:</p>
<pre style="background-color:#fff">docker run -i --rm -p 5000:5000 <span style="color:#008080">$NAME</span>:<span style="color:#008080">$TAG</span>
</pre><p>Let's get a prediction from the model:</p>
<pre style="background-color:#fff">$ curl --header <span style="color:#d14">&#34;Content-Type: application/json&#34;</span> <span style="color:#d14">\
</span><span style="color:#d14"></span>  --request POST <span style="color:#d14">\
</span><span style="color:#d14"></span>  --data <span style="color:#d14">&#39;{&#34;data&#34;:{&#34;ndarray&#34;:[34.0, 100.0, 1, 2](34.0,-100.0,-1,-2.html)}}&#39;</span> <span style="color:#d14">\
</span><span style="color:#d14"></span>  http://localhost:5000/predict
</pre><p>This will return a prediction:</p>
<pre style="background-color:#fff">{
    <span style="color:#000080">&#34;data&#34;</span>: {
        <span style="color:#000080">&#34;names&#34;</span>: [<span style="color:#d14">&#34;t:0&#34;</span>,<span style="color:#d14">&#34;t:1&#34;</span>,<span style="color:#d14">&#34;t:2&#34;</span>],
        <span style="color:#000080">&#34;ndarray&#34;</span>: [<span style="color:#099">0.0</span>,<span style="color:#099">0.9980208571211083</span>,<span style="color:#099">0.00197914287889168</span>]<span style="color:#a61717;background-color:#e3d2d2">(</span><span style="color:#099">0.0</span>,<span style="color:#a61717;background-color:#e3d2d2">0.9980208571211083,0.00197914287889168.html)</span>},
    <span style="color:#000080">&#34;meta&#34;</span>: {}
}
</pre><p>This response corresponds to the probability of each segment (<code>0</code>, <code>1</code> and <code>2</code>), respectively.<br />
We can see that a customer with this profile is classified as a segment <code>1</code> with an associated probability of 99.8%.</p>
<h3 id="with-metrics">With metrics</h3>
<p>Seldon provides basic metrics by default, covering service, predictor and model name, version and image. However, you can directly add custom metrics. Going back to our <code>Model</code> wrapper class, we add a new method called <code>metrics</code> which returns custom metrics. The metrics are compatible with Prometheus and, therefore, the metric type should be familiar if you have dealt with Prometheus before. These include, for instance:</p>
<ul>
<li>Counters</li>
<li>Gauges</li>
<li>Timers</li>
</ul>
<p>Let's add to the wrapper:</p>
<pre style="background-color:#fff"><span style="color:#000;font-weight:bold">import</span> <span style="color:#555">joblib</span>
<span style="color:#000;font-weight:bold">import</span> <span style="color:#555">logging</span>

<span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">Model</span>(<span style="color:#0086b3">object</span>):

    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>):
        logger<span style="color:#000;font-weight:bold">.</span>info(<span style="color:#d14">&#34;Initializing.&#34;</span>)
        logger<span style="color:#000;font-weight:bold">.</span>info(<span style="color:#d14">&#34;Loading model.&#34;</span>)
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>model <span style="color:#000;font-weight:bold">=</span> joblib<span style="color:#000;font-weight:bold">.</span>load(<span style="color:#d14">&#39;model.pkl&#39;</span>)

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">predict</span>(<span style="color:#999">self</span>, X, features_names):
        <span style="color:#000;font-weight:bold">return</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>model<span style="color:#000;font-weight:bold">.</span>predict_proba(X)

    <span style="color:#998;font-style:italic"># new custom metrics endpoint</span>
    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">metrics</span>(<span style="color:#999">self</span>):
        <span style="color:#000;font-weight:bold">return</span> [
            <span style="color:#998;font-style:italic"># a counter which will increase by the given value</span>
            {<span style="color:#d14">&#34;type&#34;</span>: <span style="color:#d14">&#34;COUNTER&#34;</span>, <span style="color:#d14">&#34;key&#34;</span>: <span style="color:#d14">&#34;mycounter&#34;</span>, <span style="color:#d14">&#34;value&#34;</span>: <span style="color:#099">1</span>},
             <span style="color:#998;font-style:italic"># a gauge which will be set to given value</span>
            {<span style="color:#d14">&#34;type&#34;</span>: <span style="color:#d14">&#34;GAUGE&#34;</span>, <span style="color:#d14">&#34;key&#34;</span>: <span style="color:#d14">&#34;mygauge&#34;</span>, <span style="color:#d14">&#34;value&#34;</span>: <span style="color:#099">10</span>},
            <span style="color:#998;font-style:italic"># a timer which will add sum and count metrics - assumed millisecs</span>
            {<span style="color:#d14">&#34;type&#34;</span>: <span style="color:#d14">&#34;TIMER&#34;</span>, <span style="color:#d14">&#34;key&#34;</span>: <span style="color:#d14">&#34;mytimer&#34;</span>, <span style="color:#d14">&#34;value&#34;</span>: <span style="color:#099">1.1</span>},
        ]
</pre><p>If we now request a new prediction, as previously, we can see the custom metrics included in the model's response.</p>
<pre style="background-color:#fff">{
    <span style="color:#000080">&#34;data&#34;</span>: {
        <span style="color:#000080">&#34;names&#34;</span>: [<span style="color:#d14">&#34;t:0&#34;</span>,<span style="color:#d14">&#34;t:1&#34;</span>,<span style="color:#d14">&#34;t:2&#34;</span>],
        <span style="color:#000080">&#34;ndarray&#34;</span>:[<span style="color:#099">0.0</span>,<span style="color:#099">0.9980208571211083</span>,<span style="color:#099">0.00197914287889168</span>]<span style="color:#a61717;background-color:#e3d2d2">(</span><span style="color:#099">0.0</span>,<span style="color:#a61717;background-color:#e3d2d2">0.9980208571211083,0.00197914287889168.html)</span>},
    <span style="color:#000080">&#34;meta&#34;</span>: {
        <span style="color:#000080">&#34;metrics&#34;</span>: [
            {<span style="color:#000080">&#34;key&#34;</span>:<span style="color:#d14">&#34;mycounter&#34;</span>,<span style="color:#000080">&#34;type&#34;</span>:<span style="color:#d14">&#34;COUNTER&#34;</span>,<span style="color:#000080">&#34;value&#34;</span>:<span style="color:#099">1</span>},
            {<span style="color:#000080">&#34;key&#34;</span>:<span style="color:#d14">&#34;mygauge&#34;</span>,<span style="color:#000080">&#34;type&#34;</span>:<span style="color:#d14">&#34;GAUGE&#34;</span>,<span style="color:#000080">&#34;value&#34;</span>:<span style="color:#099">10</span>},
            {<span style="color:#000080">&#34;key&#34;</span>:<span style="color:#d14">&#34;mytimer&#34;</span>,<span style="color:#000080">&#34;type&#34;</span>:<span style="color:#d14">&#34;TIMER&#34;</span>,<span style="color:#000080">&#34;value&#34;</span>:<span style="color:#099">1.1</span>}]
    }
}
</pre><p>These values are available via the Prometheus endpoint.</p>
<p>The model can also be easily deployed in a container platform, for instance, OpenShift. Assuming you are logged to a cluster and your image is a registry accessible by OpenShift, you can simply deploy it using:</p>
<pre style="background-color:#fff">$ oc new-app <span style="color:#008080">$NAME</span>:<span style="color:#008080">$TAG</span>
</pre><p>I hope this was useful to you.<br />
Happy coding!</p>
<div class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn:1" role="doc-endnote">
<p>As of the time of writing. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Other encoders are available in <code>scikit-learn</code>. I recommend you experiment with some of them. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>You can use any file name, as long as it's consistent with <code>.s2i/environment</code>, which we'll look at soon. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>More information can be found <a href="https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/s2i.html">here</a>. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

    <div class="footer">
        <span class="cc-symbol">&#127341;</span> 2020 CC BY Rui Vieira
    </div>
</div>

<div id="sidebar">
    <a href="/">home</a>
    
        <h2>Contents</h2>
        <ul>
            
                <li class="heading-2"><a href="#create-data">Create data</a></li>
            
                <li class="heading-2"><a href="#train-model">Train model</a></li>
            
                <li class="heading-2"><a href="#deploy-model">Deploy model</a></li>
            
                <li class="heading-3"><a href="#simple-model">Simple model</a></li>
            
                <li class="heading-3"><a href="#with-metrics">With metrics</a></li>
            
        </ul>
    
    
        <h2>Backlinks</h2>

        <ul>
            
                <li><a href="index.html">index</a><sup>&#5833</sup></li>
            
            <li><a href="/content.html">content</a><sup>&#5833</sup></li>

        </ul>
    
    <div class="footer">
        modified 1609759622
    </div>

</div>

</body>