<!DOCTYPE html>
<head>
        <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="48x48" href="/favicons/favicon.ico">

        <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">

        
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>

        
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
                onload="renderMathInElement(document.body);"></script>

        <link href="https://fonts.googleapis.com/css?family=Nunito:400,300i,800&display=swap" rel="stylesheet" />
        <style>
                @font-face {
                        font-family: JuliaMono-Regular;
                        src: url("https://cdn.jsdelivr.net/gh/cormullion/juliamono/webfonts/JuliaMono-Regular.woff2");
                }
                body {
                        font-family: Nunito;
                        font-size: 13pt;
                        color: #1b2d45;
                }
                #content {
                        max-width: 40rem;
                        padding: 2rem;
                        margin: auto;
                }
                #sidebar {
                   position: absolute;
                        top: 0;
                        left: 0;
                        max-width: 16rem;
                        margin-left: 3rem;
                        margin-top: 3rem;
                }
                h1, h2, h3, h4, h5, h6 {
                        color: #00214d;
                }
                h1 {
                        font-size: 200%;
                }

                h2 {
                        font-size: 167%;
                }
                h3 {
                        font-size: 133%;
                        font-weight: normal;
                }
                pre {
                        background-color: #eee !important;
                        overflow-x: scroll;
                        font-family: JuliaMono-Regular, monospace;
                        font-size: 75%;
                        padding: 1rem;
                }
                code {
                        background-color: #eee !important;
                        font-family: JuliaMono-Regular, monospace;
                        font-size: 75%;
                }
                pre > code {
                    font-size: 100%;
                }
                img {
                        max-width: 100%;
                        margin-top: 1rem;
                        margin-bottom: 1rem;
                }
                .katex { font-size: 1em !important;}
                .footer {
                        margin-top: 3rem;
                        font-size: 0.75rem;
                        color: #ccc;
                }
                .cc-symbol {
                        font-size: 1rem;
                }
                a, a:visited {
                         
                         
                        color: #ff5470;
                        padding: 1px;
                        border-radius: 2px;
                        text-decoration: none;
                }
                a.footnote-ref {
                    font-size: 0.9rem;
                }
                a.footnote-ref::before {
                    content: "[";
                }
                a.footnote-ref::after {
                    content: "]";
                }

                a:hover {
                        background-color: #ff5470;
                        color: #fff;
                }
                a[href^="https://"],
                a[href^="http://"] {
                        text-decoration: underline;
                }

                a[href^="https://"]:after,
                a[href^="http://"]:after {
                        content: "\2609";
                        text-decoration: none !important;
                }
        </style>
        <title>ruivieira.dev - Introduction to Isolation Forests</title>
    <script type="application/javascript">
        var doNotTrack = false;
        if (!doNotTrack) {
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-10507665-2', 'auto');

            ga('send', 'pageview');
        }
    </script>
</head>
<body>

<div id="sidebar">
        
            <h2>Contents</h2>
            <ul>
            
                <li><a href="#isolation-trees">Isolation Trees</a></li>
            
                <li><a href="#parameters">Parameters</a></li>
            
            </ul>
        
        
                <h2>Backlinks</h2>

                <ul>
                        
                                <li><a href="index.html">index</a><sup>&#5833</sup></li>
                        
                    <li><a href="/content.html">content</a><sup>&#5833</sup></li>

                </ul>
        
    <div class="footer">
        modified 1608143888
    </div>

</div>

<div id="content">
    <h1 id="introduction-to-isolation-forests">Introduction to Isolation Forests</h1>
<p><em>Isolation Forests</em> (IFs), presented in Liu<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> et. al (2012), are a popular algorithm used for outlier classification. In a very simplified way, the method consists of building an ensemble of<br />
<em>Isolation Trees</em> (ITs) for a given data set and observations are deemed anomalies if they have short adjusted average path lengths on the ITs.</p>
<p>ITs, which will be covered shortly, have several properties in common with a fundamental data structure: the <a href="https://en.wikipedia.org/wiki/Binary_search_tree">Binary Search Tree</a> (BSTs). In a very simplified way, BSTs are a special instance of tree structures where keys are kept in such an order that a node search is performed by iteratively (or recursively) choosing a left or right branch based on a quantitative comparison (<em>e.g.</em> lesser or greater). Node insertion is performed by doing a tree search, using the method described previously, until reaching an <em>external node</em>, where the new node will be inserted. This allows for efficient node searches since, on average, half the tree will not be visited. To illustrate this assume the values <span class="math inline">\(x=[1, 10, 2, 4, 3, 5, 26, 9, 7, 54]\)</span> and the respective insertion on a BST. The intermediate steps would then be as shown below.</p>
<p><img src="./images/isolationforests/bst_steps.png" alt="" /></p>
<p>One of the properties of BSTs is that, with randomly generated data, the path between the root node and the outliers will typically be shorter. We can see from the illustration below that, with our example data, the path length for (say) 7 is twice the length than for the suspicious value of 54. This property will play an important role in the IF algorithm, as we will see further on.</p>
<p><img src="./images/isolationforests/bst_path_length.png" alt="" /></p>
<h2 id="isolation-trees">Isolation Trees</h2>
<p>Since ITs are the fundamental component of IFs, we will start by describing their building process. We start by defining <span class="math inline">\(t\)</span> as the number of trees in the IF, <span class="math inline">\(\mathcal{D}\)</span> as the training data (contained in an <span class="math inline">\(n\)</span>-dimensional feature space, <span class="math inline">\(\mathcal{D} \subset \mathbb{R}^n\)</span>) and <span class="math inline">\(\psi\)</span> as the subsampling size. The building of a IT consists then in recursively partitioning the data <span class="math inline">\(\mathcal{D}\)</span> by sampling (without replacement) a subsample <span class="math inline">\(\mathcal{D}^{\prime}\)</span> of size <span class="math inline">\(\psi\)</span>. We then build an isolation tree <span class="math inline">\(\mathcal{T}^{\prime}\)</span> with this subsample (in order to later add it to the isolation forest <span class="math inline">\(\mathcal{F}\)</span>) and the process is repeated <span class="math inline">\(t\)</span> times.</p>
<p>To build an isolation tree <span class="math inline">\(\mathcal{T}^{\prime}\)</span> from the subsample we proceed as follows: if the data subsample <span class="math inline">\(\mathcal{D}^{\prime}\)</span> is indivisible, a tree is returned containing a single <em>external node</em> corresponding to the feature dimensions, <span class="math inline">\(n\)</span>.  If it can be divided, a series of steps must be performed. Namely, if we consider <span class="math inline">\(Q = \lbrace q_1,\dots,q_n\rbrace\)</span> as the list of features in <span class="math inline">\(\mathcal{D}^{\prime}\)</span>, we select a random feature <span class="math inline">\(q \in Q\)</span> and a random <em>split point</em> <span class="math inline">\(p\)</span> such that</p>
<p><span class="math display">\[\min(q) < p < \max(q), \qquad q \in Q.
\]</span></p>
<p>Based on the cut-off point <span class="math inline">\(p\)</span>, we filter the features into a BST’s left and right nodes according to</p>
<p><span class="math display">\[\mathcal{D}_l := \lbrace \mathcal{D}^{\prime} : q \in Q,  q<p\rbrace \\
\mathcal{D}_r := \lbrace \mathcal{D}^{\prime} : q \in Q,  q \geq p\rbrace,
\]</span></p>
<p>and return an <em>internal node</em> having an isolation tree with left and right nodes as respectively <span class="math inline">\(\mathcal{D}_l\)</span> and <span class="math inline">\(\mathcal{D}_r\)</span>.</p>
<p>To illustrate this (and the general method of identifying anomalies in a two dimensional feature space, <span class="math inline">\(x\in\mathbb{R}^2\)</span>) we will look at some simulated data and its processing. We start by simulating two clusters of data from a multivariate normal distribution, one centred in <span class="math inline">\(x_a=[-10, 10]\)</span> and another centred in <span class="math inline">\(x_b=[10, 10]\)</span>, with a variance of <span class="math inline">\(\Sigma=\text{diag}(2, 2)\)</span>, that is</p>
<p><span class="math display">\[X_a \sim \mathcal{N}\left([-10, -10], \text{diag}(2, 2)\right) \\
X_b \sim \mathcal{N}\left([10, 10], \text{diag}(2, 2)\right).
\]</span></p>
<p>The particular realisation of this simulation looks like this:</p>
<p><img src="./images/isolationforests/data.png" alt="" /></p>
<p>Below we illustrate the building of a <em>single</em> IT (given the data), illustrating the feature split point <span class="math inline">\(p\)</span> and respective division of the feature list into <em>left</em> or <em>right</em> IT nodes. The process is conducted recursively until the feature list is no longer divisible. As mentioned previously, this process, the creation of an IT, is repeated <span class="math inline">\(t\)</span> times in order to create the IF.</p>
<p> 
  <video width="100%" autoplay>
    <source src="./images/isolationforests/split.mp4" type="video/mp4">
  </video> 
</p>
<p>In order to perform anomaly detection (<em>e.g.</em> observation scoring) we will then use the IT equivalent of the BST unsuccessful search heuristics. An external node termination in an IT is equivalent to a BST unsuccessful search. Given an observation <span class="math inline">\(x\)</span>, our goal is then to calculate the score for this observation, given our defined subsampling size, that is, <span class="math inline">\(s(x,\psi)\)</span>.</p>
<p>This technique amounts to partitioning the feature space randomly until feature points are “isolated”. Intuitively, points in high density regions will need more partitioning steps, whereas anomalies (by definition away from high density regions) will need fewer splits. Since the building of the ITs is performed in a randomised fashion and using a subsample of the data, this density predictor can be average over a number of ITs, the <em>Isolation Forest</em>.</p>
<p>Intuitively, this could be done by calculating the average path length for our <span class="math inline">\(\mathcal{T}n, n=1,\dots,t\)</span> ITs, <span class="math inline">\(\overline{h}(x)\)</span>.<br />
However, as pointed in Liu<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> <em>et. al</em> (2012), a problem with calculating this is that maximum possible height of each <span class="math inline">\(\mathcal{T}_n\)</span> grows as <span class="math inline">\(\mathcal{O}(\log(\psi))\)</span>. To compare <span class="math inline">\(h(x)\)</span> given different subsampling sizes, a normalisation factor, <span class="math inline">\(c(\psi)\)</span> must be established. This can be calculated by</p>
<p><span class="math display">\[c(\psi) = \begin{cases}
2H(\psi-1)-2\frac{\psi-1}{n},\text{if}\ \psi >2,\\
1, \text{if}\ \psi=2,\\
0, \text{otherwise}, 
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(H(i)\)</span> is the harmonic number estimated by <span class="math inline">\(H(i)\approx\log(i) + e\)</span>.</p>
<p>Denoting <span class="math inline">\(h_{max}\)</span> as the tree height limit and e as the <em>current path length</em>, initialised as <span class="math inline">\(e=0\)</span> we can then calculate <span class="math inline">\(h(x)\)</span> recursively as:</p>
<p><span class="math display">\[h(x,\mathcal{T},h_{max},e) = \begin{cases}
h(x,\mathcal{T}_{n,left},h_{max},e+1) \text{if}\ x_a < q_{\mathcal{T}} \\
h(x,\mathcal{T}_{n,right},h_{max},e+1) \text{if}\ x_a \geq q_{\mathcal{T}} \\
e+c(\mathcal{T_{n,s}}) \text{if}\ \mathcal{T} \text{is a terminal node or}\ e \geq h_{max}.
\end{cases}
\]</span></p>
<p>Given these quantities we can then, finally, calculate the anomaly score, <span class="math inline">\(s\)</span> as</p>
<p><span class="math display">\[s(x,\psi) = 2^{-\frac{\text{E}[h(x)]}{c(\psi)}}
\]</span></p>
<p>with <span class="math inline">\(\text{E}[h(x)]\)</span> being the average <span class="math inline">\(h(x)\)</span> for a collection of ITs.</p>
<h2 id="parameters">Parameters</h2>
<p>As mentioned in Liu<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> <em>et. al</em> (2012), the empirical subsampling size <span class="math inline">\(\psi=2^8\)</span> is typically enough to perform anomaly detection in a wide range of data. Regarding the number of trees, <span class="math inline">\(t\)</span> no considerable accuracy gain is usually observed with <span class="math inline">\(t>100\)</span>. In the plots below, we can see the score calculation for two point in our data, namely an outlier (<span class="math inline">\(x_o=[3.10, -12.69])\)</span> and a normal observation (<span class="math inline">\(x_n=[8.65, 9.71]\)</span>) with a varying number of trees and <span class="math inline">\(\psi=2^8\)</span> (<em>left</em>) and a varying subsample size and <span class="math inline">\(t=100\)</span> (<em>right</em>). We can see that the score value stabilised quite early on when using <span class="math inline">\(\psi=2^8\)</span> and that very low subsampling sizes can lead to problems when classifying anomalies.</p>
<p><img src="./images/isolationforests/avg_score.png" alt="" /></p>
<p>Now that we know how to implement an IF algorithm and calculate an anomaly score, we will try to visualise the anomaly score distribution in the vicinity of the simulated data. To do so, we simply create a two dimensional lattice enclosing our data an iteratively calculate <span class="math inline">\(s(\cdot, \psi)\)</span>. The result is show below:</p>
<p><img src="./images/isolationforests/score_field.png" alt="" /></p>
<p>The above steps fully define a naive isolation forest algorithm, which when applied to the previously simulated data, result in 88% of the anomalies being correctly identified.</p>
<p><img src="./images/isolationforests/detection.png" alt="" /></p>
<p>Thanks for reading! If you have any questions or comments, please let me know on <a href="https://mastodon.social/@ruivieira">Mastodon</a> or <a href="https://twitter.com/ruimvieira">Twitter</a>.</p>
<div class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn:1" role="doc-endnote">
<p>Liu, F. T., Ting, K. M., &amp; Zhou, Z. H. (2012). <em>Isolation-Based Anomaly Detection.</em> ACM Transactions on Knowledge Discovery from Data, 6(1), 1–39. https://doi.org/10.1145/2133360.2133363 <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

    <div class="footer">
        <span class="cc-symbol">&#127341;</span> 2020 CC BY Rui Vieira
    </div>
</div>

</body>
</html>